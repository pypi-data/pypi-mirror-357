Metadata-Version: 2.4
Name: deep-brief
Version: 0.1.0
Summary: A video analysis application for presentation feedback
Author-email: Michael Borck <michael@example.com>
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Education
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.11
Requires-Dist: ffmpeg-python>=0.2.0
Requires-Dist: gradio>=4.8.0
Requires-Dist: jinja2>=3.1.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: openai-whisper>=20231117
Requires-Dist: opencv-python>=4.8.0
Requires-Dist: pandas>=2.1.0
Requires-Dist: pillow>=10.1.0
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: pydantic>=2.5.0
Requires-Dist: pytesseract>=0.3.10
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pyyaml>=6.0.1
Requires-Dist: rich>=13.7.0
Requires-Dist: spacy>=3.7.0
Requires-Dist: torch>=2.2.0
Requires-Dist: torchvision>=0.17.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: transformers>=4.36.0
Requires-Dist: typer>=0.9.0
Requires-Dist: weasyprint>=60.0
Provides-Extra: build
Requires-Dist: build>=1.0.0; extra == 'build'
Requires-Dist: twine>=4.0.0; extra == 'build'
Provides-Extra: dev
Requires-Dist: basedpyright>=1.8.0; extra == 'dev'
Requires-Dist: pre-commit>=3.5.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'dev'
Requires-Dist: pytest-cov>=4.1.0; extra == 'dev'
Requires-Dist: pytest>=7.4.0; extra == 'dev'
Requires-Dist: ruff>=0.1.6; extra == 'dev'
Provides-Extra: gpu
Requires-Dist: torch>=2.2.0; extra == 'gpu'
Requires-Dist: torchvision>=0.17.0; extra == 'gpu'
Description-Content-Type: text/markdown

# DeepBrief

A video analysis application that helps students, educators, and professionals analyze presentations by combining speech transcription, visual analysis, and AI-powered feedback.

## Features

- **Video Processing**: Support for MP4, MOV, AVI, and WebM formats
- **Speech Analysis**: Automatic transcription with speaking rate and filler word detection
- **Visual Analysis**: Scene detection with frame captioning and quality assessment
- **AI Feedback**: Actionable insights and recommendations for improvement
- **Professional Reports**: Interactive HTML and structured JSON outputs

## Installation

### Prerequisites

- Python 3.11 or higher
- ffmpeg (for video processing)

### Install with uv (recommended)

```bash
# Install uv if you haven't already
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repository
git clone https://github.com/michael-borck/deep-brief.git
cd deep-brief

# Create virtual environment and install
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .
```

### Install Development Dependencies

```bash
uv pip install -e ".[dev]"
```

## Quick Start

```bash
# Run the web interface
deep-brief

# Or use Python module
python -m deep_brief.interface.gradio_app
```

## Development

This project uses modern Python tooling:

- **uv** for fast package management
- **ruff** for formatting and linting
- **basedpyright** for type checking
- **pytest** for testing

### Running Tests

```bash
pytest -v
```

### Code Quality

```bash
# Format and lint
ruff format .
ruff check .

# Type checking
basedpyright

# Run all checks
ruff format . && ruff check . && basedpyright && pytest -v
```

## License

MIT License - see LICENSE file for details.

## Contributing

Contributions are welcome! Please read the development guidelines in CLAUDE.md.