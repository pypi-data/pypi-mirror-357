{"version":3,"file":"static/chunks/react-syntax-highlighter_languages_refractor_etlua.b552e8aa637c7596.js","mappings":"AGAA,YAAY,EACXA,IAAI,CAAC,gBAAkB,CAAIA,IAAI,CAAC,gBAAkB,EAAK,EAAE,EAAEC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAE7E,KAAK,CACJ,SAASC,CAAM,CAAEC,CAAwB,CAAEC,CAAmB,CAAE,CHFvE,IAAAC,CAAA,CAAAD,CAAgC,QAChCE,CAAA,CAAAF,CAAA,iBAIAG,CAAA,CAAAC,CAAA,MAGAA,CAAA,CAFAA,CAAA,CAAAC,QAAA,CAAAJ,CAAA,EACAG,CAAG,CAAAC,QAAA,CAAAH,CAAA,EAEHE,CADAA,CAAA,CAsBAA,CAAA,EArBAE,SAAA,CAAAH,KAAA,EACAI,SAAA,EACAC,OAAA,kBACOC,KAAA,eACP,CACA,gBACAD,OAAA,WACAE,MAAA,CAAAN,CAAA,CAAAE,SAAA,CAAAK,GAAA,CACA,CACA,CACAP,CAAA,CAAAQ,KAAA,CAAAC,GAAA,4BAAAC,CAAA,EAEAV,CAAA,CAAAE,SAAA,sBAAAS,iBAAA,CACAD,CAAA,CACA,wBAEK,CACL,EACAV,CAAA,CAAAQ,KAAA,CAAAC,GAAA,2BAAAC,CAAA,EACKV,CAAA,CAAAE,SAAA,sBAAAU,oBAAA,CAAAF,CAAA,UACF,EACH,CA5BA,CAAAG,OAAA,CAAAd,CAAA,CACAA,CAAA,CAAAe,WAAA,SACAf,CAAA,CAAAgB,OAAA,IA0BA,gBAAArB,CAAA,EC1BA,SAAAa,CAAA,CAAAP,CAAA,EACAA,CAAA,CAAAE,SAAA,CAAAK,GAAA,EACAS,OAAA,0CAEAC,MAAA,EACAb,OAAA,qFACA,CACKc,MAAA,IACL,CACAC,MAAA,gHACA,CACAC,OAAA,0HACoC,CACpCC,QAAA,4BACAC,QAAA,0CAEA,CAEAlB,OAAA,sBACAmB,UAAA,IACA,CACA,CACAC,WAAA,uBACA,EA1BA,CAAAX,OAAA,CAAAN,CAAA,CACAA,CAAA,CAAAO,WAAA,OACAP,CAAA,CAAAQ,OAAA,IAwBA,gBAAArB,CAAA,ECvBA,SAAG+B,CAAA,CAAAzB,CAAA,GACH,SAAAA,CAAA,EAQA,SAAA0B,CAAA,CAAAC,CAAA,CAAAC,CAAA,EACA,YAAAD,CAAA,CAAAE,WAAA,GAAAD,CAAA,OACA,MACA,CAAAE,gBAAA,CAAA9B,CAAA,CAAAE,SAAA,0BACAS,iBAAA,EAYAoB,KAAA,UAAArB,CAAA,CAAAiB,CAAA,CAAAK,CAAA,CAAAC,CAAA,EACA,GAAAvB,CAAA,CAAAiB,QAAA,GAAAA,CAAA,EAGA,IAAAO,CAAA,CAAAxB,CAAA,CAAAwB,UAAA,IACAxB,CAAA,CAAAyB,IAAA,CAAAzB,CAAA,CAAAyB,IAAA,CAAAC,OAAA,CAAAJ,CAAA,UAAAK,CAAA,EACA,sBAAAJ,CAAA,GAAAA,CAAA,CAAAI,CAAA,EACA,OAAAA,CAAA,KAEA,IACAC,CAAA,CADAC,CAAA,CAAAL,CAAA,CAAAM,MAAA,CAGA9B,EACA,GADAA,CAAA,CAAAyB,IAAA,CAAAM,OAAA,CAAAH,CAAA,CAAAZ,CAAA,CAAAC,CAAA,CAAAY,CAAA,IAGc,EAAAA,CAAA,QAEdL,CAAA,CAAAK,CAAA,EAAAF,CAAA,CACWC,CAAA,CACX,EACA5B,CAAA,CAAAgC,OAAA,CAAA1C,CAAA,CAAAE,SAAA,CAAAyC,MAAA,CAjBA,CAkBO,CACP,CACA/B,oBAAA,EAOAmB,KAAA,UAAArB,CAAA,CAAAiB,CAAA,EACA,GAAAjB,CAAA,CAAAiB,QAAA,GAAAA,CAAA,EAAAjB,CAAA,CAAAwB,UAAA,EAGAxB,CAAA,CAAAgC,OAAA,CAAA1C,CAAA,CAAAE,SAAA,CAAAyB,CAAA,MACAiB,CAAA,GACAC,CAAA,CAAAC,MAAA,CAAAD,IAAA,CAAAnC,CAAA,CAAAwB,UAAA,EAkDAa,CAAA,CAAArC,CAAA,CAAAsC,MAAA,EArDA,SAIAD,CAA4B,CAAAC,CAAA,EAC5B,QAAAT,CAAA,GAEA,CAFA,CAAAS,CAAA,CAAAR,MAAA,GAEAI,CAAAA,CAAA,EAAAC,CAAA,CAAAL,MAAA,EAFAD,CAAA,IAKA,IAAAU,CAAA,CAAAD,CAAA,CAAAT,CAAA,KAEA,iBAAAU,CAAA,EACAA,CAAA,CAAAC,OAAA,mBAAAD,CAAA,CAAAC,OAAA,CACA,CACA,IAAAC,CAAA,CAAAN,CAAA,CAAAD,CAAA,EACAQ,CAAA,CAAA1C,CAAA,CAAAwB,UAAA,CAAAiB,CAAA,EACAE,CAAA,kBAAAJ,CAAA,CAAAA,CAAA,CAAAA,CAAA,CAAAC,OAAA,CACAZ,CAAA,CAAAZ,CAAA,CAAAC,CAAA,CAAAwB,CAAA,EACAvB,CAAA,CAAAyB,CAAA,CAAAZ,OAAA,CAAAH,CAAA,KACAV,CAAA,MACA,EAAAgB,CAAA,KACAU,CAAA,CAAAD,CAAA,CAAAE,SAAA,GAAA3B,CAAA,EACA4B,CAAA,KAAAxD,CAAA,CAAAyD,KAAA,CACA9B,CAAA,CACA3B,CAAA,CAAA0D,QAAA,CAAAN,CAAA,CAAA1C,CAAA,CAAAgC,OAAA,EACA,YAAAf,CAAA,CACAyB,CAAA,CACA,CACAO,CAAA,CAAAN,CAAA,CAAAE,SAAA,CAAA3B,CAAA,CAAAU,CAAA,CAAAE,MAAA,EACAoB,CAAA,IACAN,CAAA,EACAM,CAAA,CAAAnE,IAAA,CAAAoE,KAAA,CAAAD,CAAA,CAAAb,CAAA,EAAAO,CAAA,IAEAM,CAAA,CAAAnE,IAAA,CAAA+D,CAAA,EACAG,CAAA,EACAC,CAAA,CAAAnE,IAAA,CAAAoE,KAAA,CAAAD,CAAA,CAAAb,CAAA,EAAAY,CAAA,IAEA,iBAAAV,CAAA,CACoBD,CAAA,CAAAc,MAAA,CAAAD,KAAA,CAAAb,CAAA,EAAAT,CAAA,IAAAwB,MAAA,CAAAH,CAAA,GAEpBX,CAAA,CAAAC,OAAA,CAAAU,CAAA,CAEgB,CAChB,KACAX,CAAA,CAAAC,OAAA,EAGAH,CAAA,CAAAE,CAAA,CAAAC,OAAA,EAEA,OACAF,CAAA,CACA,CAEA,CACK,CACF,EACH,CAAAhD,CAAA,GAtHA,CAAAa,OAAA,CAAAY,CAAA,CACAA,CAAA,CAAAX,WAAA,oBACAW,CAAA,CAAAV,OAAA,IAoHA","sources":["webpack://_N_E/./node_modules/refractor/lang/etlua.js","webpack://_N_E/./node_modules/refractor/lang/lua.js","webpack://_N_E/./node_modules/refractor/lang/markup-templating.js","webpack://_N_E/<anon>"],"sourcesContent":["'use strict'\nvar refractorLua = require('./lua.js')\nvar refractorMarkupTemplating = require('./markup-templating.js')\nmodule.exports = etlua\netlua.displayName = 'etlua'\netlua.aliases = []\nfunction etlua(Prism) {\n  Prism.register(refractorLua)\n  Prism.register(refractorMarkupTemplating)\n  ;(function (Prism) {\n    Prism.languages.etlua = {\n      delimiter: {\n        pattern: /^<%[-=]?|-?%>$/,\n        alias: 'punctuation'\n      },\n      'language-lua': {\n        pattern: /[\\s\\S]+/,\n        inside: Prism.languages.lua\n      }\n    }\n    Prism.hooks.add('before-tokenize', function (env) {\n      var pattern = /<%[\\s\\S]+?%>/g\n      Prism.languages['markup-templating'].buildPlaceholders(\n        env,\n        'etlua',\n        pattern\n      )\n    })\n    Prism.hooks.add('after-tokenize', function (env) {\n      Prism.languages['markup-templating'].tokenizePlaceholders(env, 'etlua')\n    })\n  })(Prism)\n}\n","'use strict'\n\nmodule.exports = lua\nlua.displayName = 'lua'\nlua.aliases = []\nfunction lua(Prism) {\n  Prism.languages.lua = {\n    comment: /^#!.+|--(?:\\[(=*)\\[[\\s\\S]*?\\]\\1\\]|.*)/m,\n    // \\z may be used to skip the following space\n    string: {\n      pattern:\n        /([\"'])(?:(?!\\1)[^\\\\\\r\\n]|\\\\z(?:\\r\\n|\\s)|\\\\(?:\\r\\n|[^z]))*\\1|\\[(=*)\\[[\\s\\S]*?\\]\\2\\]/,\n      greedy: true\n    },\n    number:\n      /\\b0x[a-f\\d]+(?:\\.[a-f\\d]*)?(?:p[+-]?\\d+)?\\b|\\b\\d+(?:\\.\\B|(?:\\.\\d*)?(?:e[+-]?\\d+)?\\b)|\\B\\.\\d+(?:e[+-]?\\d+)?\\b/i,\n    keyword:\n      /\\b(?:and|break|do|else|elseif|end|false|for|function|goto|if|in|local|nil|not|or|repeat|return|then|true|until|while)\\b/,\n    function: /(?!\\d)\\w+(?=\\s*(?:[({]))/,\n    operator: [\n      /[-+*%^&|#]|\\/\\/?|<[<=]?|>[>=]?|[=~]=?/,\n      {\n        // Match \"..\" but don't break \"...\"\n        pattern: /(^|[^.])\\.\\.(?!\\.)/,\n        lookbehind: true\n      }\n    ],\n    punctuation: /[\\[\\](){},;]|\\.+|:+/\n  }\n}\n","'use strict'\n\nmodule.exports = markupTemplating\nmarkupTemplating.displayName = 'markupTemplating'\nmarkupTemplating.aliases = []\nfunction markupTemplating(Prism) {\n  ;(function (Prism) {\n    /**\n     * Returns the placeholder for the given language id and index.\n     *\n     * @param {string} language\n     * @param {string|number} index\n     * @returns {string}\n     */\n    function getPlaceholder(language, index) {\n      return '___' + language.toUpperCase() + index + '___'\n    }\n    Object.defineProperties((Prism.languages['markup-templating'] = {}), {\n      buildPlaceholders: {\n        /**\n         * Tokenize all inline templating expressions matching `placeholderPattern`.\n         *\n         * If `replaceFilter` is provided, only matches of `placeholderPattern` for which `replaceFilter` returns\n         * `true` will be replaced.\n         *\n         * @param {object} env The environment of the `before-tokenize` hook.\n         * @param {string} language The language id.\n         * @param {RegExp} placeholderPattern The matches of this pattern will be replaced by placeholders.\n         * @param {(match: string) => boolean} [replaceFilter]\n         */\n        value: function (env, language, placeholderPattern, replaceFilter) {\n          if (env.language !== language) {\n            return\n          }\n          var tokenStack = (env.tokenStack = [])\n          env.code = env.code.replace(placeholderPattern, function (match) {\n            if (typeof replaceFilter === 'function' && !replaceFilter(match)) {\n              return match\n            }\n            var i = tokenStack.length\n            var placeholder // Check for existing strings\n            while (\n              env.code.indexOf((placeholder = getPlaceholder(language, i))) !==\n              -1\n            ) {\n              ++i\n            } // Create a sparse array\n            tokenStack[i] = match\n            return placeholder\n          }) // Switch the grammar to markup\n          env.grammar = Prism.languages.markup\n        }\n      },\n      tokenizePlaceholders: {\n        /**\n         * Replace placeholders with proper tokens after tokenizing.\n         *\n         * @param {object} env The environment of the `after-tokenize` hook.\n         * @param {string} language The language id.\n         */\n        value: function (env, language) {\n          if (env.language !== language || !env.tokenStack) {\n            return\n          } // Switch the grammar back\n          env.grammar = Prism.languages[language]\n          var j = 0\n          var keys = Object.keys(env.tokenStack)\n          function walkTokens(tokens) {\n            for (var i = 0; i < tokens.length; i++) {\n              // all placeholders are replaced already\n              if (j >= keys.length) {\n                break\n              }\n              var token = tokens[i]\n              if (\n                typeof token === 'string' ||\n                (token.content && typeof token.content === 'string')\n              ) {\n                var k = keys[j]\n                var t = env.tokenStack[k]\n                var s = typeof token === 'string' ? token : token.content\n                var placeholder = getPlaceholder(language, k)\n                var index = s.indexOf(placeholder)\n                if (index > -1) {\n                  ++j\n                  var before = s.substring(0, index)\n                  var middle = new Prism.Token(\n                    language,\n                    Prism.tokenize(t, env.grammar),\n                    'language-' + language,\n                    t\n                  )\n                  var after = s.substring(index + placeholder.length)\n                  var replacement = []\n                  if (before) {\n                    replacement.push.apply(replacement, walkTokens([before]))\n                  }\n                  replacement.push(middle)\n                  if (after) {\n                    replacement.push.apply(replacement, walkTokens([after]))\n                  }\n                  if (typeof token === 'string') {\n                    tokens.splice.apply(tokens, [i, 1].concat(replacement))\n                  } else {\n                    token.content = replacement\n                  }\n                }\n              } else if (\n                token.content\n                /* && typeof token.content !== 'string' */\n              ) {\n                walkTokens(token.content)\n              }\n            }\n            return tokens\n          }\n          walkTokens(env.tokens)\n        }\n      }\n    })\n  })(Prism)\n}\n","\"use strict\";\n(self[\"webpackChunk_N_E\"] = self[\"webpackChunk_N_E\"] || []).push([[8126,8119,3047],{\n\n/***/ 66055:\n/***/ (function(module, __unused_webpack_exports, __webpack_require__) {\n\n\nvar refractorLua = __webpack_require__(59803)\nvar refractorMarkupTemplating = __webpack_require__(93205)\nmodule.exports = etlua\netlua.displayName = 'etlua'\netlua.aliases = []\nfunction etlua(Prism) {\n  Prism.register(refractorLua)\n  Prism.register(refractorMarkupTemplating)\n  ;(function (Prism) {\n    Prism.languages.etlua = {\n      delimiter: {\n        pattern: /^<%[-=]?|-?%>$/,\n        alias: 'punctuation'\n      },\n      'language-lua': {\n        pattern: /[\\s\\S]+/,\n        inside: Prism.languages.lua\n      }\n    }\n    Prism.hooks.add('before-tokenize', function (env) {\n      var pattern = /<%[\\s\\S]+?%>/g\n      Prism.languages['markup-templating'].buildPlaceholders(\n        env,\n        'etlua',\n        pattern\n      )\n    })\n    Prism.hooks.add('after-tokenize', function (env) {\n      Prism.languages['markup-templating'].tokenizePlaceholders(env, 'etlua')\n    })\n  })(Prism)\n}\n\n\n/***/ }),\n\n/***/ 59803:\n/***/ (function(module) {\n\n\n\nmodule.exports = lua\nlua.displayName = 'lua'\nlua.aliases = []\nfunction lua(Prism) {\n  Prism.languages.lua = {\n    comment: /^#!.+|--(?:\\[(=*)\\[[\\s\\S]*?\\]\\1\\]|.*)/m,\n    // \\z may be used to skip the following space\n    string: {\n      pattern:\n        /([\"'])(?:(?!\\1)[^\\\\\\r\\n]|\\\\z(?:\\r\\n|\\s)|\\\\(?:\\r\\n|[^z]))*\\1|\\[(=*)\\[[\\s\\S]*?\\]\\2\\]/,\n      greedy: true\n    },\n    number:\n      /\\b0x[a-f\\d]+(?:\\.[a-f\\d]*)?(?:p[+-]?\\d+)?\\b|\\b\\d+(?:\\.\\B|(?:\\.\\d*)?(?:e[+-]?\\d+)?\\b)|\\B\\.\\d+(?:e[+-]?\\d+)?\\b/i,\n    keyword:\n      /\\b(?:and|break|do|else|elseif|end|false|for|function|goto|if|in|local|nil|not|or|repeat|return|then|true|until|while)\\b/,\n    function: /(?!\\d)\\w+(?=\\s*(?:[({]))/,\n    operator: [\n      /[-+*%^&|#]|\\/\\/?|<[<=]?|>[>=]?|[=~]=?/,\n      {\n        // Match \"..\" but don't break \"...\"\n        pattern: /(^|[^.])\\.\\.(?!\\.)/,\n        lookbehind: true\n      }\n    ],\n    punctuation: /[\\[\\](){},;]|\\.+|:+/\n  }\n}\n\n\n/***/ }),\n\n/***/ 93205:\n/***/ (function(module) {\n\n\n\nmodule.exports = markupTemplating\nmarkupTemplating.displayName = 'markupTemplating'\nmarkupTemplating.aliases = []\nfunction markupTemplating(Prism) {\n  ;(function (Prism) {\n    /**\n     * Returns the placeholder for the given language id and index.\n     *\n     * @param {string} language\n     * @param {string|number} index\n     * @returns {string}\n     */\n    function getPlaceholder(language, index) {\n      return '___' + language.toUpperCase() + index + '___'\n    }\n    Object.defineProperties((Prism.languages['markup-templating'] = {}), {\n      buildPlaceholders: {\n        /**\n         * Tokenize all inline templating expressions matching `placeholderPattern`.\n         *\n         * If `replaceFilter` is provided, only matches of `placeholderPattern` for which `replaceFilter` returns\n         * `true` will be replaced.\n         *\n         * @param {object} env The environment of the `before-tokenize` hook.\n         * @param {string} language The language id.\n         * @param {RegExp} placeholderPattern The matches of this pattern will be replaced by placeholders.\n         * @param {(match: string) => boolean} [replaceFilter]\n         */\n        value: function (env, language, placeholderPattern, replaceFilter) {\n          if (env.language !== language) {\n            return\n          }\n          var tokenStack = (env.tokenStack = [])\n          env.code = env.code.replace(placeholderPattern, function (match) {\n            if (typeof replaceFilter === 'function' && !replaceFilter(match)) {\n              return match\n            }\n            var i = tokenStack.length\n            var placeholder // Check for existing strings\n            while (\n              env.code.indexOf((placeholder = getPlaceholder(language, i))) !==\n              -1\n            ) {\n              ++i\n            } // Create a sparse array\n            tokenStack[i] = match\n            return placeholder\n          }) // Switch the grammar to markup\n          env.grammar = Prism.languages.markup\n        }\n      },\n      tokenizePlaceholders: {\n        /**\n         * Replace placeholders with proper tokens after tokenizing.\n         *\n         * @param {object} env The environment of the `after-tokenize` hook.\n         * @param {string} language The language id.\n         */\n        value: function (env, language) {\n          if (env.language !== language || !env.tokenStack) {\n            return\n          } // Switch the grammar back\n          env.grammar = Prism.languages[language]\n          var j = 0\n          var keys = Object.keys(env.tokenStack)\n          function walkTokens(tokens) {\n            for (var i = 0; i < tokens.length; i++) {\n              // all placeholders are replaced already\n              if (j >= keys.length) {\n                break\n              }\n              var token = tokens[i]\n              if (\n                typeof token === 'string' ||\n                (token.content && typeof token.content === 'string')\n              ) {\n                var k = keys[j]\n                var t = env.tokenStack[k]\n                var s = typeof token === 'string' ? token : token.content\n                var placeholder = getPlaceholder(language, k)\n                var index = s.indexOf(placeholder)\n                if (index > -1) {\n                  ++j\n                  var before = s.substring(0, index)\n                  var middle = new Prism.Token(\n                    language,\n                    Prism.tokenize(t, env.grammar),\n                    'language-' + language,\n                    t\n                  )\n                  var after = s.substring(index + placeholder.length)\n                  var replacement = []\n                  if (before) {\n                    replacement.push.apply(replacement, walkTokens([before]))\n                  }\n                  replacement.push(middle)\n                  if (after) {\n                    replacement.push.apply(replacement, walkTokens([after]))\n                  }\n                  if (typeof token === 'string') {\n                    tokens.splice.apply(tokens, [i, 1].concat(replacement))\n                  } else {\n                    token.content = replacement\n                  }\n                }\n              } else if (\n                token.content\n                /* && typeof token.content !== 'string' */\n              ) {\n                walkTokens(token.content)\n              }\n            }\n            return tokens\n          }\n          walkTokens(env.tokens)\n        }\n      }\n    })\n  })(Prism)\n}\n\n\n/***/ })\n\n}]);"],"names":["self","push","module","__unused_webpack_exports","__webpack_require__","refractorLua","refractorMarkupTemplating","etlua","Prism","register","languages","delimiter","pattern","alias","inside","lua","hooks","add","env","buildPlaceholders","tokenizePlaceholders","exports","displayName","aliases","comment","string","greedy","number","keyword","function","operator","lookbehind","punctuation","markupTemplating","getPlaceholder","language","index","toUpperCase","defineProperties","value","placeholderPattern","replaceFilter","tokenStack","code","replace","match","placeholder","i","length","indexOf","grammar","markup","j","keys","Object","walkTokens","tokens","token","content","k","t","s","before","substring","middle","Token","tokenize","after","replacement","apply","splice","concat"],"sourceRoot":""}