[base]
package = kinetix
env_name = kinetix-pixels-discrete kinetix-symbolic-discrete
policy_name = PixelsPolicy
rnn_name = Recurrent

[env]
num_envs = 2048

[train]
total_timesteps = 100_000_000
checkpoint_interval = 200
num_envs = 1
num_workers = 1
env_batch_size = 1
update_epochs = 8
batch_size = 131072
minibatch_size = 4096
learning_rate = 0.0003
gamma = 0.995
gae_lambda = 0.9
ent_coef = 0.01

[sweep]
method = protein
name = sweep

[sweep.metric]
goal = maximize
name = GoalR 
min = 0
max = None

[sweep.train.total_timesteps]
distribution = log_normal
min = 5e6
max = 1e9
mean = 1e7
scale = auto

[sweep.train.batch_size]
distribution = uniform_pow2
min = 32768
max = 131072
mean = 65536
scale = auto

[sweep.train.minibatch_size]
distribution = uniform_pow2
min = 1024
max = 32768
mean = 8192
scale = auto
