[base]
package = ocean
env_name = puffer_snake
policy_name = Snake
#policy_name = Policy
rnn_name = Recurrent

[env]
num_envs = 4
width = 640
height = 360
num_snakes = 256
num_food = 4096
vision = 5
leave_corpse_on_death = True
reward_food = 0.1
reward_corpse = 0.1
reward_death = -1.0

[vec]
num_envs = 16

[train]
total_timesteps = 500_000_000
adam_beta1 = 0.6762060389098516
adam_beta2 = 0.9
adam_eps = 0.000002764249390410885
bptt_horizon = 64
clip_coef = 0.7379459916127813
ent_coef = 0.010507292602201058
gae_lambda = 0.6006253996849398
gamma = 0.9997067226101388
learning_rate = 0.016779905178021273
max_grad_norm = 0.6504710763256233
minibatch_size = 32768
prio_alpha = 0.6082618023318664
prio_beta0 = 0.447524297405661
vf_clip_coef = 2.830994746057568
vf_coef = 3.9655925817980053
vtrace_c_clip = 0
vtrace_rho_clip = 0.9285200248552337

[sweep.env.reward_food]
distribution = uniform
min = 0.0
max = 1.0
mean = 0.0
scale = auto

[sweep.env.reward_death]
distribution = uniform
min = -1.0
max = 0.0
mean = 0.0
scale = auto

[sweep.train.total_timesteps]
distribution = log_normal
min = 5e7
max = 2e8
mean = 1e8
scale = auto
