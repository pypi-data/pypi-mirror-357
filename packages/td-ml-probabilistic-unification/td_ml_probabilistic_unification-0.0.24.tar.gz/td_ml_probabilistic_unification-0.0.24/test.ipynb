{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurbaksh.sharma/Desktop/td_code/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.td_ml_probabilistic_unification.data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytd\n",
    "# client = pytd.Client(database='test_dilyan')\n",
    "\n",
    "# or, hard-code your API key, endpoint, and/or query engine:\n",
    "client=pytd.Client(apikey=key, \n",
    "            endpoint='https://api.treasuredata.com', \n",
    "            database='test_dilyan', \n",
    "            default_engine='presto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=client.query(\"select * from prob_final_blocking_table_user_master\", engine='presto')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns=data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "# from .data_loader import TDConnector\n",
    "import uuid\n",
    "\n",
    "# os.system(f\"{sys.executable} -m pip install fancyimpute==0.7.0\")\n",
    "# os.system(f\"{sys.executable} -m pip install strsim==0.0.3\")\n",
    "# os.system(f\"{sys.executable} -m pip install networkx==2.5\")\n",
    "# os.system(f\"{sys.executable} -m pip install scipy==1.6.2\")\n",
    "# #os.system(f\"{sys.executable} -m pip install pandiet==0.1.6\")\n",
    "# os.system(f\"{sys.executable} -m pip install fuzzywuzzy==0.18.0\")\n",
    "# #os.system(f\"{sys.executable} -m pip install memory_profiler==0.60.0\")\n",
    "# os.system(f\"{sys.executable} -m pip install python-Levenshtein==0.21.1\")\n",
    "\n",
    "\n",
    "# #####----Defining Variables-------#####\n",
    "# TD_SINK_DATABASE=os.environ.get('TD_SINK_DATABASE')\n",
    "# TD_API_KEY=os.environ.get('TD_API_KEY')\n",
    "# TD_API_SERVER=os.environ.get('TD_API_SERVER')\n",
    "\n",
    "# id_col=os.environ.get('id_col')\n",
    "# cluster_col_name=os.environ.get('cluster_col_name')\n",
    "# convergence_threshold=float(os.environ.get('convergence_threshold'))\n",
    "# cluster_threshold=float(os.environ.get('cluster_threshold'))\n",
    "# string_type=os.environ.get('string_type')\n",
    "# fill_missing=os.environ.get('fill_missing')\n",
    "# feature_dict=json.loads(os.environ.get('feature_dict'))\n",
    "# blocking_table=os.environ.get('blocking_table')\n",
    "# output_table=os.environ.get('output_table')\n",
    "\n",
    "# record_limit=int(os.environ.get('record_limit'))\n",
    "# lower_limit=int(os.environ.get('lower_limit'))\n",
    "# upper_limit=int(os.environ.get('upper_limit'))\n",
    "# range_index=os.environ.get('range_index')\n",
    "# paralelism = os.environ.get('paralelism')\n",
    "\n",
    "# input_table=blocking_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# You can override these by setting os.environ beforehand or fall back to these values\n",
    "\n",
    "id_col = os.environ.get('id_col', 'persistent_id')\n",
    "cluster_col_name = os.environ.get('cluster_col_name', 'prob_id')\n",
    "convergence_threshold = float(os.environ.get('convergence_threshold', 0.01))\n",
    "cluster_threshold = float(os.environ.get('cluster_threshold', 0.65))\n",
    "string_type = os.environ.get('string_type', 'jarowinkler')\n",
    "fill_missing = os.environ.get('fill_missing', 'True').lower() == 'true'\n",
    "blocking_table = os.environ.get('blocking_table', 'prob_final_blocking_table_user_master')\n",
    "output_table = os.environ.get('output_table', 'prob_final_user_master')\n",
    "\n",
    "record_limit = int(os.environ.get('record_limit', 100000))\n",
    "lower_limit = int(os.environ.get('lower_limit', 0))\n",
    "upper_limit = int(os.environ.get('upper_limit', 0))  # set appropriately\n",
    "range_index = os.environ.get('range_index', '0')\n",
    "paralelism = os.environ.get('paralelism', '1')\n",
    "\n",
    "# Handle feature_dict (this should be passed in as a JSON string in the environment)\n",
    "feature_dict_json = os.environ.get('feature_dict', '''\n",
    "[\n",
    "    {\n",
    "        \"name\": \"phone_key\",\n",
    "        \"type\": \"string\",\n",
    "        \"weight\": 0.35,\n",
    "        \"final_approval\": \"no\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"email_key\",\n",
    "        \"type\": \"email\",\n",
    "        \"weight\": 0.35,\n",
    "        \"final_approval\": \"no\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"address_key\",\n",
    "        \"type\": \"string\",\n",
    "        \"weight\": 0.30,\n",
    "        \"final_approval\": \"no\"\n",
    "    }\n",
    "]\n",
    "''')\n",
    "feature_dict = json.loads(feature_dict_json)\n",
    "\n",
    "\n",
    "\n",
    "feature_cols=\"block_key, \" + id_col\n",
    "for feature in feature_dict:\n",
    "    name=feature['name']\n",
    "    feature_cols=feature_cols +  \",\"  + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.td_ml_probabilistic_unification.get_similarity import *\n",
    "from src.td_ml_probabilistic_unification.get_cluster import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New parameters\n",
    "clustering_method = os.environ.get('clustering_method', 'safe')\n",
    "min_coverage = float(os.environ.get('min_coverage', '0.5'))\n",
    "min_cluster_size = int(os.environ.get('min_cluster_size', '2'))\n",
    "\n",
    "def validate_feature_weights(feature_dict):\n",
    "    \"\"\"\n",
    "    Validate and normalize feature weights to ensure they sum to 1.0.\n",
    "    \n",
    "    Args:\n",
    "        feature_dict: List of feature dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        Validated feature dictionary with normalized weights\n",
    "    \"\"\"\n",
    "    total_weight = sum(float(feature['weight']) for feature in feature_dict)\n",
    "    \n",
    "    if abs(total_weight - 1.0) > 0.01:  # Allow small tolerance\n",
    "        print(f\"Warning: Feature weights sum to {total_weight}, normalizing to 1.0\")\n",
    "        \n",
    "        # Normalize weights\n",
    "        for feature in feature_dict:\n",
    "            feature['weight'] = float(feature['weight']) / total_weight\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "def apply_quality_filters(df_clusters, sim_data, id_col, cluster_col_name, \n",
    "                         min_cluster_size=2, min_avg_similarity=None):\n",
    "    \"\"\"\n",
    "    Apply quality filters to remove low-quality clusters.\n",
    "    \n",
    "    Args:\n",
    "        df_clusters: DataFrame with cluster assignments\n",
    "        sim_data: Original similarity data\n",
    "        id_col: ID column name\n",
    "        cluster_col_name: Cluster column name\n",
    "        min_cluster_size: Minimum number of records in cluster\n",
    "        min_avg_similarity: Minimum average similarity in cluster\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    if min_avg_similarity is None:\n",
    "        min_avg_similarity = cluster_threshold\n",
    "    \n",
    "    # Count cluster sizes\n",
    "    cluster_sizes = df_clusters[cluster_col_name].value_counts()\n",
    "    valid_clusters = cluster_sizes[cluster_sizes >= min_cluster_size].index\n",
    "    \n",
    "    # Filter by cluster size\n",
    "    df_filtered = df_clusters[df_clusters[cluster_col_name].isin(valid_clusters)].copy()\n",
    "    \n",
    "    # Filter by average similarity if specified\n",
    "    if min_avg_similarity > 0:\n",
    "        df_filtered = df_filtered[\n",
    "            df_filtered['avg_cluster_similarity'] >= min_avg_similarity\n",
    "        ].copy()\n",
    "    \n",
    "    # Add quality metrics\n",
    "    df_filtered['cluster_size'] = df_filtered[cluster_col_name].map(cluster_sizes)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate feature configuration\n",
    "normalized_feature_dict = validate_feature_weights(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'phone_key',\n",
       "  'type': 'string',\n",
       "  'weight': 0.35,\n",
       "  'final_approval': 'no'},\n",
       " {'name': 'email_key',\n",
       "  'type': 'email',\n",
       "  'weight': 0.35,\n",
       "  'final_approval': 'no'},\n",
       " {'name': 'address_key',\n",
       "  'type': 'string',\n",
       "  'weight': 0.3,\n",
       "  'final_approval': 'no'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-24 18:30:03,793 - INFO - Calculating similarities for 3654 pairs\n",
      "2025-06-24 18:30:04,549 - INFO - Similarity calculation completed - mean score: 0.966\n",
      "Generated 3654 record pairs\n",
      "Pairs above threshold (0.65): 3650\n",
      "Average feature coverage: 0.73\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "# Simple logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "sim_data=pd.merge(dup_data,dup_data,on='block_key',suffixes=('_1','_2')).drop_duplicates()\n",
    "\n",
    "#--- Dropping one of duplicate pairs e.g id_1=A and id_2= B ==> there will be two combinations A-B and B-A but we only need any one of them. so dropping one of them here\n",
    "sim_data=sim_data[sim_data[id_col+'_1']>sim_data[id_col+'_2']]\n",
    "\n",
    "# Calculate similarities with improved missing value handling\n",
    "sim_data, sim_feat_list, col_names, weights = get_similarities(\n",
    "    sim_data, \n",
    "    normalized_feature_dict, \n",
    "    string_type, \n",
    "    min_coverage=min_coverage\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(sim_data)} record pairs\")\n",
    "print(f\"Pairs above threshold ({cluster_threshold}): {len(sim_data[sim_data['score'] >= cluster_threshold])}\")\n",
    "print(f\"Average feature coverage: {sim_data['feature_coverage'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid pairs after filtering: 3650\n",
      "2025-06-24 18:30:05,010 - INFO - Starting clustering with method 'safe', threshold 0.65\n",
      "2025-06-24 18:30:05,149 - INFO - Clustering successful with method: safe\n",
      "2025-06-24 18:30:09,358 - INFO - Clustering completed: 3432 clusters, 6927 records\n",
      "Generated 3432 clusters\n",
      "Records in clusters: 6927\n",
      "Clusters after quality filtering: 3432\n",
      "Records after quality filtering: 6927\n",
      "Final output statistics:\n",
      "- Number of clusters: 3432\n",
      "- Number of records: 7058\n",
      "- Average cluster size: 2.1\n",
      "- Average cluster similarity: 0.967\n",
      "- Minimum cluster similarity: 0.742\n"
     ]
    }
   ],
   "source": [
    "# Filter pairs that don't meet minimum requirements\n",
    "valid_pairs = sim_data[\n",
    "    (sim_data['score'] >= cluster_threshold) & \n",
    "    (sim_data['feature_coverage'] >= min_coverage)\n",
    "]\n",
    "\n",
    "print(f\"Valid pairs after filtering: {len(valid_pairs)}\")\n",
    "\n",
    "if len(valid_pairs) == 0:\n",
    "    print(\"No valid pairs found. Adjusting parameters...\")\n",
    "    # Relax coverage requirement\n",
    "    relaxed_coverage = min_coverage * 0.7\n",
    "    valid_pairs = sim_data[\n",
    "        (sim_data['score'] >= cluster_threshold * 0.9) & \n",
    "        (sim_data['feature_coverage'] >= relaxed_coverage)\n",
    "    ]\n",
    "    print(f\"Valid pairs with relaxed criteria: {len(valid_pairs)}\")\n",
    "\n",
    "# Perform clustering with improved method\n",
    "df_clusters = clusters(\n",
    "    sim_data, \n",
    "    id_col, \n",
    "    cluster_col_name, \n",
    "    cluster_threshold, \n",
    "    convergence_threshold, \n",
    "    col_names, \n",
    "    fill_missing, \n",
    "    clustering_method=clustering_method,\n",
    "    min_coverage=min_coverage\n",
    ")\n",
    "\n",
    "print(f\"Generated {df_clusters[cluster_col_name].nunique()} clusters\")\n",
    "print(f\"Records in clusters: {len(df_clusters)}\")\n",
    "\n",
    "# Apply quality filters\n",
    "df_filtered = apply_quality_filters(\n",
    "    df_clusters, \n",
    "    sim_data, \n",
    "    id_col, \n",
    "    cluster_col_name, \n",
    "    min_cluster_size=min_cluster_size,\n",
    "    min_avg_similarity=cluster_threshold\n",
    ")\n",
    "\n",
    "print(f\"Clusters after quality filtering: {df_filtered[cluster_col_name].nunique()}\")\n",
    "print(f\"Records after quality filtering: {len(df_filtered)}\")\n",
    "\n",
    "# Only keep clusters with multiple records (remove singletons)\n",
    "cluster_counts = df_filtered[cluster_col_name].value_counts()\n",
    "multi_record_clusters = cluster_counts[cluster_counts >= min_cluster_size].index\n",
    "final_df = df_filtered[df_filtered[cluster_col_name].isin(multi_record_clusters)].copy()\n",
    "\n",
    "if len(final_df) == 0:\n",
    "    print(\"No clusters found after filtering. Creating empty result.\")\n",
    "    # Create empty DataFrame with correct structure\n",
    "    final_df = pd.DataFrame(columns=[id_col, cluster_col_name, 'avg_cluster_similarity', 'cluster_size'])\n",
    "    for col in col_names:\n",
    "        final_df[col] = []\n",
    "else:\n",
    "    # Replace cluster ids with UUIDs\n",
    "    unique_cluster_ids = final_df[cluster_col_name].unique()\n",
    "    cluster_uuid_mapping = {cluster_id: str(uuid.uuid4()) for cluster_id in unique_cluster_ids}\n",
    "    final_df[cluster_col_name] = final_df[cluster_col_name].map(cluster_uuid_mapping)\n",
    "\n",
    "    # Merge with original data\n",
    "    final_df = final_df.merge(dup_data, how='left', on=[id_col]).drop('block_key', axis=1).drop_duplicates()\n",
    "\n",
    "    # Add range index prefix to cluster IDs\n",
    "    final_df[cluster_col_name] = str(range_index) + '_' + final_df[cluster_col_name].astype('str')\n",
    "\n",
    "    # Add quality metrics to output\n",
    "    print(f\"Final output statistics:\")\n",
    "    print(f\"- Number of clusters: {final_df[cluster_col_name].nunique()}\")\n",
    "    print(f\"- Number of records: {len(final_df)}\")\n",
    "    print(f\"- Average cluster size: {final_df['cluster_size'].mean():.1f}\")\n",
    "    print(f\"- Average cluster similarity: {final_df['avg_cluster_similarity'].mean():.3f}\")\n",
    "    print(f\"- Minimum cluster similarity: {final_df['avg_cluster_similarity'].min():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_id</th>\n",
       "      <th>persistent_id</th>\n",
       "      <th>avg_cluster_similarity</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>email_key</th>\n",
       "      <th>phone_key</th>\n",
       "      <th>address_key</th>\n",
       "      <th>rnk</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_ca3f5908-b4b3-480b-858c-7e1bb13802a3</td>\n",
       "      <td>5ntDTml1Am7x</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>2</td>\n",
       "      <td>VIRGINIA-R|-TREVINO-|VTREVINO279@GMAIL.COM</td>\n",
       "      <td>VIRGINIA-R|-TREVINO-|6237643404</td>\n",
       "      <td>None</td>\n",
       "      <td>4751</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_ca3f5908-b4b3-480b-858c-7e1bb13802a3</td>\n",
       "      <td>L7HbkTiOKTXx</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>2</td>\n",
       "      <td>VIRGINIA-R|TREVINO|VTREVINO279@GMAIL.COM</td>\n",
       "      <td>VIRGINIA-R|TREVINO|6237643404</td>\n",
       "      <td>None</td>\n",
       "      <td>4751</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_98c19a54-dcbd-4422-93e4-02c7507db1be</td>\n",
       "      <td>zWvszRvZZuDx</td>\n",
       "      <td>0.977041</td>\n",
       "      <td>2</td>\n",
       "      <td>ARTHUR|RIDOLFI|ART.RIDOLFI@GMAIL.COM</td>\n",
       "      <td>ARTHUR|RIDOLFI|2032615581</td>\n",
       "      <td>None</td>\n",
       "      <td>1356</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_98c19a54-dcbd-4422-93e4-02c7507db1be</td>\n",
       "      <td>4x1gCiNz-DTx</td>\n",
       "      <td>0.977041</td>\n",
       "      <td>2</td>\n",
       "      <td>ARTHUR|RIDOLFIL|ART.RIDOLFI@GMAIL.COM</td>\n",
       "      <td>ARTHUR|RIDOLFIL|2032615581</td>\n",
       "      <td>None</td>\n",
       "      <td>1356</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_bf766d94-d513-451d-80ca-5f4e3fe60fd2</td>\n",
       "      <td>ZtCGEsXusu_x</td>\n",
       "      <td>0.999244</td>\n",
       "      <td>2</td>\n",
       "      <td>JERI|MOORE|MOOREJERI@GMAIL.CO</td>\n",
       "      <td>JERI|MOORE|5599449651</td>\n",
       "      <td>None</td>\n",
       "      <td>2959</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>0_e77c2370-c0ee-4564-9fa5-ceb7fede8d7b</td>\n",
       "      <td>I0Tyeqt3CyTx</td>\n",
       "      <td>0.985338</td>\n",
       "      <td>2</td>\n",
       "      <td>CHERYL|GRANT|GRAMMIEMATEO@GMAIL.COM</td>\n",
       "      <td>CHERYL|GRANT|8055268693</td>\n",
       "      <td>CHERYL|GRANT|1237 HAROLD AVE|93065</td>\n",
       "      <td>1512</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>0_e77c049d-8d61-4e82-8686-9e0b4a67c4d7</td>\n",
       "      <td>TGrNHaXdnOrx</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>2</td>\n",
       "      <td>NASEEM|DOUCHAND|DOUCHAND.51@GMAIL.COM</td>\n",
       "      <td>NASEEM|DOUCHAND|3058787671</td>\n",
       "      <td>None</td>\n",
       "      <td>2813</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7055</th>\n",
       "      <td>0_e77c049d-8d61-4e82-8686-9e0b4a67c4d7</td>\n",
       "      <td>3P60h5BovRbx</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>2</td>\n",
       "      <td>NASEEM|DOUCHAND-|DOUCHAND.51@GMAIL.COM</td>\n",
       "      <td>NASEEM|DOUCHAND-|3058787671</td>\n",
       "      <td>None</td>\n",
       "      <td>2813</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056</th>\n",
       "      <td>0_9b1abe36-cde0-439b-a9da-05109cfabb66</td>\n",
       "      <td>OCVRFWXq2Cjx</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>2</td>\n",
       "      <td>TINA|GARTLAND|TINAG803@GMAIL.COM</td>\n",
       "      <td>TINA|GARTLAND|4104994168</td>\n",
       "      <td>TINA|GARTLAND|803 S SHARP ST|21230</td>\n",
       "      <td>2999</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>0_9b1abe36-cde0-439b-a9da-05109cfabb66</td>\n",
       "      <td>UbVnoR-ltzvx</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>2</td>\n",
       "      <td>TINA|GARTLANA|TINAG803@GMAIL.COM</td>\n",
       "      <td>TINA|GARTLANA|4104994168</td>\n",
       "      <td>TINA|GARTLANA|803 S SHARP ST|21230</td>\n",
       "      <td>2999</td>\n",
       "      <td>1749656326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7058 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prob_id persistent_id  \\\n",
       "0     0_ca3f5908-b4b3-480b-858c-7e1bb13802a3  5ntDTml1Am7x   \n",
       "1     0_ca3f5908-b4b3-480b-858c-7e1bb13802a3  L7HbkTiOKTXx   \n",
       "2     0_98c19a54-dcbd-4422-93e4-02c7507db1be  zWvszRvZZuDx   \n",
       "3     0_98c19a54-dcbd-4422-93e4-02c7507db1be  4x1gCiNz-DTx   \n",
       "4     0_bf766d94-d513-451d-80ca-5f4e3fe60fd2  ZtCGEsXusu_x   \n",
       "...                                      ...           ...   \n",
       "7053  0_e77c2370-c0ee-4564-9fa5-ceb7fede8d7b  I0Tyeqt3CyTx   \n",
       "7054  0_e77c049d-8d61-4e82-8686-9e0b4a67c4d7  TGrNHaXdnOrx   \n",
       "7055  0_e77c049d-8d61-4e82-8686-9e0b4a67c4d7  3P60h5BovRbx   \n",
       "7056  0_9b1abe36-cde0-439b-a9da-05109cfabb66  OCVRFWXq2Cjx   \n",
       "7057  0_9b1abe36-cde0-439b-a9da-05109cfabb66  UbVnoR-ltzvx   \n",
       "\n",
       "      avg_cluster_similarity  cluster_size  \\\n",
       "0                   0.970000             2   \n",
       "1                   0.970000             2   \n",
       "2                   0.977041             2   \n",
       "3                   0.977041             2   \n",
       "4                   0.999244             2   \n",
       "...                      ...           ...   \n",
       "7053                0.985338             2   \n",
       "7054                0.980000             2   \n",
       "7055                0.980000             2   \n",
       "7056                0.964029             2   \n",
       "7057                0.964029             2   \n",
       "\n",
       "                                       email_key  \\\n",
       "0     VIRGINIA-R|-TREVINO-|VTREVINO279@GMAIL.COM   \n",
       "1       VIRGINIA-R|TREVINO|VTREVINO279@GMAIL.COM   \n",
       "2           ARTHUR|RIDOLFI|ART.RIDOLFI@GMAIL.COM   \n",
       "3          ARTHUR|RIDOLFIL|ART.RIDOLFI@GMAIL.COM   \n",
       "4                  JERI|MOORE|MOOREJERI@GMAIL.CO   \n",
       "...                                          ...   \n",
       "7053         CHERYL|GRANT|GRAMMIEMATEO@GMAIL.COM   \n",
       "7054       NASEEM|DOUCHAND|DOUCHAND.51@GMAIL.COM   \n",
       "7055      NASEEM|DOUCHAND-|DOUCHAND.51@GMAIL.COM   \n",
       "7056            TINA|GARTLAND|TINAG803@GMAIL.COM   \n",
       "7057            TINA|GARTLANA|TINAG803@GMAIL.COM   \n",
       "\n",
       "                            phone_key                         address_key  \\\n",
       "0     VIRGINIA-R|-TREVINO-|6237643404                                None   \n",
       "1       VIRGINIA-R|TREVINO|6237643404                                None   \n",
       "2           ARTHUR|RIDOLFI|2032615581                                None   \n",
       "3          ARTHUR|RIDOLFIL|2032615581                                None   \n",
       "4               JERI|MOORE|5599449651                                None   \n",
       "...                               ...                                 ...   \n",
       "7053          CHERYL|GRANT|8055268693  CHERYL|GRANT|1237 HAROLD AVE|93065   \n",
       "7054       NASEEM|DOUCHAND|3058787671                                None   \n",
       "7055      NASEEM|DOUCHAND-|3058787671                                None   \n",
       "7056         TINA|GARTLAND|4104994168  TINA|GARTLAND|803 S SHARP ST|21230   \n",
       "7057         TINA|GARTLANA|4104994168  TINA|GARTLANA|803 S SHARP ST|21230   \n",
       "\n",
       "       rnk        time  \n",
       "0     4751  1749656326  \n",
       "1     4751  1749656326  \n",
       "2     1356  1749656326  \n",
       "3     1356  1749656326  \n",
       "4     2959  1749656326  \n",
       "...    ...         ...  \n",
       "7053  1512  1749656326  \n",
       "7054  2813  1749656326  \n",
       "7055  2813  1749656326  \n",
       "7056  2999  1749656326  \n",
       "7057  2999  1749656326  \n",
       "\n",
       "[7058 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
