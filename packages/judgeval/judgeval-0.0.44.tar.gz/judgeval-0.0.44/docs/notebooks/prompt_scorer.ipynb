{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "In this notebook, we cover how to implement a `PromptScorer`. To guide our example, let's imagine we have a customer support chatbot and want to evaluate whether its responses are polite/positive.\n",
    "\n",
    "`PromptScorers` are powerful LLM-based scorers that are analogous to [LLM Judges](https://arxiv.org/abs/2306.05685). You can use Judgment to create custom LLM judges that are best suited to your specific evaluation case! Before you try implementing an LLM judge, you should check if any ready-made Judgment scorers already fit your evaluation needs.\n",
    "\n",
    "With that, let's break down the `PromptScorer` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"./judgeval\")  # root of judgeval\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from judgeval.judgment_client import JudgmentClient\n",
    "from judgeval.data import Example\n",
    "from judgeval.judges import TogetherJudge\n",
    "from judgeval.scorers import PromptScorer\n",
    "import nest_asyncio\n",
    "\n",
    "# This allows us to run async code in notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "qwen = TogetherJudge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building our custom prompt scorer**\n",
    "\n",
    "Every prompt scorer that inherits from the `PromptScorer` class must implement the `build_measure_prompt()` class method. This method takes an `Example` and creates a prompt for the LLM judge based on the data. The only constraint is that the prompt must dictate that the judge produce a JSON in its answer with two fields: `score` and `reason`. These can be used in our `check_success()` method later!\n",
    "\n",
    "Since we're trying to evaluate the sentiment of our chatbot's responses, let's have our judge examine a question and the answer produced by our chatbot. Then the judge will determine whether the chatbot's response was positive or negative.\n",
    "\n",
    "Lastly, we must implment the `check_success()` class method. This method determines whether a single `Example` is successful if treated as a test case. In our case, we want our chatbot to respond with neutral or positive sentiment (never negative!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentScorer(PromptScorer):\n",
    "    \"\"\"\n",
    "    Detects negative sentiment (angry, sad, upset, etc.) in a response\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name=\"Sentiment Scorer\", \n",
    "        threshold=0.5, \n",
    "        model=qwen, \n",
    "        include_reason=True, \n",
    "        async_mode=True, \n",
    "        strict_mode=False, \n",
    "        verbose_mode=False\n",
    "        ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            threshold=threshold,\n",
    "            model=model,\n",
    "            include_reason=include_reason,\n",
    "            async_mode=async_mode,\n",
    "            strict_mode=strict_mode,\n",
    "            verbose_mode=verbose_mode,\n",
    "        )\n",
    "        self.score = 0.0\n",
    "\n",
    "    def build_measure_prompt(self, example: Example):\n",
    "        SYSTEM_ROLE = (\n",
    "            'You are a great judge of emotional intelligence. You understand the feelings ' \n",
    "            'and intentions of others. You will be tasked with judging whether the following '\n",
    "            'response is negative (sad, angry, upset) or not. After deciding whether the '\n",
    "            'response is negative or not, you will be asked to provide a brief, 1 sentence-long reason for your decision.'\n",
    "            'You should score the response based on a 1 to 5 scale, where 1 is not negative and '\n",
    "            '5 is very negative. Please end your response in the following JSON format: {\"score\": <score>, \"reason\": <reason>}'\n",
    "                  )\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_ROLE},\n",
    "            {\"role\": \"user\", \"content\": f\"Response: {example.actual_output}\\n\\nYour judgment: \"}\n",
    "        ] \n",
    "\n",
    "    def success_check(self):\n",
    "        POSITIVITY_THRESHOLD = 3  # we want all model responses to be somewhat positive in tone\n",
    "        return self.score <= POSITIVITY_THRESHOLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying out our scorer**\n",
    "\n",
    "That's it! We can now run our prompt scorer on some examples and see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example = Example(\n",
    "    input=\"What's the store return policy?\",\n",
    "    actual_output=\"Our return policy is wonderful! You may return any item within 30 days of purchase for a full refund.\",\n",
    ")\n",
    "\n",
    "scorer = SentimentScorer()\n",
    "\n",
    "client = JudgmentClient()\n",
    "results = client.run_evaluation(\n",
    "    [pos_example],\n",
    "    [scorer],\n",
    "    model=\"QWEN\"\n",
    ") \n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn**\n",
    "\n",
    "Now that we've seen how to implement a prompt scorer, try adapting it to your use case! Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
