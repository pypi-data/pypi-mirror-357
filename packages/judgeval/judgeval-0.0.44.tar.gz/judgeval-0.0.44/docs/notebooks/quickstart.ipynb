{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a walkthrough of how to use the basic functionalities from the `Judgeval` library.\n",
    "First, let's set up our client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized JudgmentClient, welcome back Joseph Camyre!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/alexshan/Desktop/judgment_labs/judgeval/\")  # root of judgeval\n",
    "\n",
    "# We need to ensure that our environment variables are set up with our Judgment API key.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from judgeval.judgment_client import JudgmentClient\n",
    "\n",
    "client = JudgmentClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up our first experiment for evaluation!**\n",
    "\n",
    "Before jumping into all the different kinds of evaluations we can run on `Judgeval`, let's read a toy example:\n",
    "\n",
    "Imagine we're building a customer support bot for a clothing company. We might have a RAG system set up to help the bot answer questions that require examining policies, such as the return policy. We would therefore be interested in measuring whether our bot's answers are consistent with our policies.\n",
    "\n",
    "Let's use `Judgeval` to test whether our bot is working as intended. First, we'll set up an `Example`, which represents a single case that we would like to evaluate our system (bot) on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from judgeval.data import Example \n",
    "\n",
    "return_policy_example = Example(\n",
    "    # User query\n",
    "    input=\"What if I bought the wrong color or size?\",\n",
    "    # Fill this in with the output of your system\n",
    "    actual_output=(\"You can return the item within 30 days of purchase for a full refund.\" \n",
    "                   \"You do not need to present your receipt.\"),\n",
    "    retrieval_context=[\n",
    "        \"Customers may return items for a full refund within 30 days of purchase.\", \n",
    "        \"To return an item, customers must have the purchase receipt in physical or digital form.\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine whether the `actual_output` of our bot is consistent with our policies (the `retrieval_context`), we can use Judgment's `Faithfulness` scorer to execute an evaluation.\n",
    "\n",
    "In this case, we want to make sure that everything that our bot says is factually consistent with our retrieved documents. We can do this by setting the `threshold` of the `JudgmentScorer` to 1.0, meaning that 100% of the claims within `actual_output` do NOT contradict the retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexshan/Library/Python/3.9/lib/python/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'faithfulness'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScoringResult(success=False, scorers_data=[{'name': 'Faithfulness', 'threshold': 1.0, 'success': False, 'score': 0.5, 'reason': 'The score is 0.50 because the actual output incorrectly states that you do not need to present your receipt to return the item, which contradicts the retrieval context that explicitly requires a purchase receipt in physical or digital form for returns.', 'strict_mode': False, 'evaluation_model': 'gpt-4.1', 'error': None, 'evaluation_cost': None, 'verbose_logs': 'Claims:\\n[\\n    {\\'claim\\': \\'You can return the item within 30 days of purchase for a full refund.\\', \\'quote\\': \\'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.\\'},\\n    {\\'claim\\': \\'You do not need to present your receipt to return the item.\\', \\'quote\\': \\'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.\\'}\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The claim that you can return the item within 30 days of purchase for a full refund is supported by the retrieval context. Quote: \\'Customers may return items for a full refund within 30 days of purchase.\\'\"\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The claim that you do not need to present your receipt to return the item is contradicted by the retrieval context. Quote: \\'To return an item, customers must have the purchase receipt in physical or digital form.\\'\"\\n    }\\n]', 'additional_metadata': {'claims': [{'claim': 'You can return the item within 30 days of purchase for a full refund.', 'quote': 'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.'}, {'claim': 'You do not need to present your receipt to return the item.', 'quote': 'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.'}], 'verdicts': [{'verdict': 'yes', 'reason': \"The claim that you can return the item within 30 days of purchase for a full refund is supported by the retrieval context. Quote: 'Customers may return items for a full refund within 30 days of purchase.'\"}, {'verdict': 'no', 'reason': \"The claim that you do not need to present your receipt to return the item is contradicted by the retrieval context. Quote: 'To return an item, customers must have the purchase receipt in physical or digital form.'\"}]}}], input='What if I bought the wrong color or size?', actual_output='You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.', expected_output=None, context=None, retrieval_context=['Customers may return items for a full refund within 30 days of purchase.', 'To return an item, customers must have the purchase receipt in physical or digital form.'], judgment_api_key='')]\n"
     ]
    }
   ],
   "source": [
    "from judgeval.scorers import JudgmentScorer\n",
    "from judgeval.constants import JudgmentMetric\n",
    "from judgeval.evaluation_run import EvaluationRun\n",
    "\n",
    "\n",
    "faithfulness = JudgmentScorer(\n",
    "    threshold=1.0,  # Performance bar for a passing score, if running a test.\n",
    "    score_type=JudgmentMetric.FAITHFULNESS\n",
    ")\n",
    "\n",
    "# Set up our evaluation with our Scorer, and choose GPT4o as our judge LLM.\n",
    "eval = EvaluationRun(\n",
    "    examples=[return_policy_example],\n",
    "    scorers=[faithfulness],\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "results = client.run_eval(eval)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! We've executed our first `Judgeval` evaluation. If we're just interested in measuring the score of an evaluation, this guide is complete. \n",
    "\n",
    "However, we might want to do some more analysis to see exactly why the evaluation score is 0.5 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the `ScoringResult` that we received by running our evaluation!\n",
    "\n",
    "Our evaluation has failed, meaning that when treating the `Example` as a unit test, our bot did not produce an answer that was 100% factually consistent with the retrieved documents. Let's dig into what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess? False\n",
      "Score: 0.5 (50.0%)\n",
      "Reasoning: The score is 0.50 because the actual output incorrectly states that you do not need to present your receipt to return the item, which contradicts the retrieval context that explicitly requires a purchase receipt in physical or digital form for returns.\n"
     ]
    }
   ],
   "source": [
    "result = results[0]\n",
    "print(f\"Sucess? {result.success}\")\n",
    "\n",
    "score = result.scorers_data[0].get('score')\n",
    "print(f\"Score: {score} ({score * 100}%)\")\n",
    "print(f\"Reasoning: {result.scorers_data[0].get('reason')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! It seems that our bot did indeed hallucinate that customers do not need to present their receipts for returning items. Let's inspect the `result` for even more detail into how `Judgeval`'s scorer found this contradiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Metadata: {'claims': [{'claim': 'You can return the item within 30 days of purchase for a full refund.', 'quote': 'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.'}, {'claim': 'You do not need to present your receipt to return the item.', 'quote': 'You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.'}], 'verdicts': [{'verdict': 'yes', 'reason': \"The claim that you can return the item within 30 days of purchase for a full refund is supported by the retrieval context. Quote: 'Customers may return items for a full refund within 30 days of purchase.'\"}, {'verdict': 'no', 'reason': \"The claim that you do not need to present your receipt to return the item is contradicted by the retrieval context. Quote: 'To return an item, customers must have the purchase receipt in physical or digital form.'\"}]}\n"
     ]
    }
   ],
   "source": [
    "metadata = result.scorers_data[0].get('additional_metadata')\n",
    "\n",
    "print(f\"Additional Metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{   \n",
    "    \"claims\": [\n",
    "        {\n",
    "            \"claim\": \"You can return the item within 30 days of purchase for a full refund.\",\n",
    "            \"quote\": \"You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.\"\n",
    "        },\n",
    "        {\n",
    "            \"claim\": \"You do not need to present your receipt to return the item.\",\n",
    "            \"quote\": \"You can return the item within 30 days of purchase for a full refund.You do not need to present your receipt.\"\n",
    "        }\n",
    "    ],\n",
    "    \"verdicts\": [\n",
    "        {\n",
    "            \"verdict\": \"yes\",\n",
    "            \"reason\": \"The claim that you can return the item within 30 days of purchase for a full refund is supported by the retrieval context. Quote: 'Customers may return items for a full refund within 30 days of purchase.'\"\n",
    "        },\n",
    "        {\n",
    "            \"verdict\": \"no\",\n",
    "            \"reason\": \"The claim that you do not need to present your receipt to return the item is contradicted by the retrieval context. Quote: 'To return an item, customers must have the purchase receipt in physical or digital form.'\"\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know exactly what our bot hallucinated! Using this information, we can fix our bot's response and hopefully, we will get a perfect score the next time we run an evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
