stage: # set stage via CLI
root:  # path of wai-formatted dataset

gpus: 0
cpus: 10
mem: 20
scenes_per_job: 20
conda_env: # pass the name of our conda environment
nodelist: h100-ai-p5en48xlarge-[0-10]

stages:
  conversion:
    script: conversion/scannetppv2.py
    config: conversion/scannetppv2.yaml
    scenes_per_job: 100 # fast
  undistortion:
    script: undistort.py
    config: undistortion/scannetppv2.yaml
  rendering:
    script: run_rendering.py
    config: rendering.yaml
    gpus: 1
  semantic_mapping:
    script: run_semantic_mapping.py
    config: semantic_mapping.yaml
    gpus: 1
  metric3dv2:
    script: run_metric3dv2.py
    config: metric3dv2/default.yaml
    scenes_per_job: 5 # slow
  mast3r:
    script: run_mast3r.py
    config: mast3r/default.yaml
    gpus: 1
  metric_alignment_mast3r:
    script: metric_alignemnt/metric_alignment_mast3r.py
    config: metric_alignment/mast3r.yaml
    gpus: 1
  covisibility:
    script: covisibility.py
    config: covisibility/covisibility_gt_depth.yaml
    gpus: 1
  covisibility_pred: # since some scenes do not contain GT meshes
    script: covisibility.py
    config: covisibility/covisibility_pred_depth.yaml
    gpus: 1
  copy_to_s3:
    script: run_copy_to_s3.py
    config: data_transfer/to_s3_default.yaml
