stage: # set stage via CLI
root: # path of wai-formatted dataset

gpus: 0
cpus: 10
mem: 20
scenes_per_job: 2
conda_env:  # pass the name of our conda environment
nodelist: h100-ai-p5en48xlarge-[0-10]

dry_run_filter: [0, 5] # for dry-run

stages:
  conversion:
    script: conversion/scannetppv2.py
    config: conversion/scannetppv2.yaml
    scenes_per_job: 200 # fast
  undistortion:
    script: undistort.py
    config: undistortion/scannetppv2.yaml
  rendering:
    script: run_rendering.py
    config: rendering.yaml
    gpus: 1
  semantic_mapping:
    script: run_semantic_mapping.py
    config: semantic_mapping.yaml
    gpus: 1
  metric3dv2:
    script: run_metric3dv2.py
    config: metric3dv2/default.yaml
    gpus: 1
  mast3r:
    script: run_mast3r.py
    config: mast3r/default.yaml
    gpus: 1
  metric_alignment_mast3r:
    script: metric_alignment/metric_alignment_mast3r.py
    config: metric_alignment/mast3r.yaml
    gpus: 1
  covisibility:
    script: covisibility.py
    config: covisibility/covisibility_gt_depth.yaml
    gpus: 1
  covisibility_pred: # since some scenes do not contain GT meshes
    script: covisibility.py
    config: covisibility/covisibility_pred_depth.yaml
    gpus: 1