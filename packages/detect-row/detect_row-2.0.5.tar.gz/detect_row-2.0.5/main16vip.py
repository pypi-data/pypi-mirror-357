import cv2
import numpy as np
from PIL import Image
import os
from scipy import signal
from scipy.ndimage import gaussian_filter1d
from typing import Tuple, List, Optional

class AutoTableSplitter:
    def __init__(self, input_path: str):
        """
        Khá»Ÿi táº¡o AutoTableSplitter
        
        Args:
            input_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file áº£nh báº£ng
        """
        self.input_path = input_path
        self.img = None
        self.gray = None
        self.height = 0
        self.width = 0
        
    def load_image(self) -> None:
        """Táº£i vÃ  chuáº©n bá»‹ áº£nh"""
        self.img = cv2.imread(self.input_path)
        if self.img is None:
            raise ValueError(f"KhÃ´ng thá»ƒ Ä‘á»c áº£nh tá»« {self.input_path}")
        
        self.height, self.width = self.img.shape[:2]
        self.gray = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)
        print(f"ğŸ“ KÃ­ch thÆ°á»›c áº£nh: {self.width} x {self.height}")
        
    def preprocess_image(self) -> np.ndarray:
        """
        Tiá»n xá»­ lÃ½ áº£nh Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
        
        Returns:
            np.ndarray: áº¢nh nhá»‹ phÃ¢n Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
        """
        # LÃ m má»‹n Ä‘á»ƒ giáº£m noise
        blurred = cv2.GaussianBlur(self.gray, (3, 3), 0)
        
        # TÄƒng Ä‘á»™ tÆ°Æ¡ng pháº£n
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(blurred)
        
        # Threshold adaptive Ä‘á»ƒ xá»­ lÃ½ Ã¡nh sÃ¡ng khÃ´ng Ä‘á»u
        binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY_INV, 15, 2)
        
        return binary
    
    def detect_vertical_lines_hough(self, binary: np.ndarray) -> List[int]:
        """
        PhÃ¡t hiá»‡n Ä‘Æ°á»ng tháº³ng dá»c báº±ng Hough Transform
        
        Args:
            binary (np.ndarray): áº¢nh nhá»‹ phÃ¢n
            
        Returns:
            List[int]: Danh sÃ¡ch vá»‹ trÃ­ x cá»§a cÃ¡c Ä‘Æ°á»ng tháº³ng dá»c
        """
        # PhÃ¡t hiá»‡n edges
        edges = cv2.Canny(binary, 50, 150, apertureSize=3)
        
        # Hough Line Transform - chá»‰ tÃ¬m Ä‘Æ°á»ng tháº³ng dá»c
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=int(self.height*0.3))
        
        vertical_lines = []
        if lines is not None:
            for rho, theta in lines[:, 0]:
                # Chá»‰ láº¥y Ä‘Æ°á»ng tháº³ng gáº§n dá»c (theta gáº§n 0 hoáº·c Ï€)
                if abs(theta) < 0.1 or abs(theta - np.pi) < 0.1:
                    x = int(rho / np.cos(theta)) if abs(np.cos(theta)) > 0.01 else None
                    if x is not None and 10 < x < self.width - 10:
                        vertical_lines.append(x)
        
        return sorted(list(set(vertical_lines)))
    
    def analyze_vertical_projection(self, binary: np.ndarray) -> Tuple[List[int], np.ndarray]:
        """
        PhÃ¢n tÃ­ch projection dá»c vá»›i nhiá»u ká»¹ thuáº­t
        
        Args:
            binary (np.ndarray): áº¢nh nhá»‹ phÃ¢n
            
        Returns:
            Tuple[List[int], np.ndarray]: (danh sÃ¡ch vá»‹ trÃ­ peaks, projection smoothed)
        """
        # TÃ­nh projection cÆ¡ báº£n
        projection = np.sum(binary, axis=0)
        
        # LÃ m má»‹n báº±ng Gaussian filter
        smoothed = gaussian_filter1d(projection, sigma=2)
        
        # TÃ¬m peaks vá»›i scipy
        # TÃ­nh dynamic threshold
        median_val = np.median(smoothed)
        mad = np.median(np.abs(smoothed - median_val))  # Median Absolute Deviation
        threshold = median_val + 2 * mad
        
        # TÃ¬m peaks
        peaks, properties = signal.find_peaks(smoothed, 
                                            height=threshold,
                                            distance=max(20, self.width//20),
                                            prominence=mad)
        
        return peaks.tolist(), smoothed
    
    def detect_morphological_lines(self, binary: np.ndarray) -> List[int]:
        """
        PhÃ¡t hiá»‡n Ä‘Æ°á»ng káº» báº±ng morphological operations
        
        Args:
            binary (np.ndarray): áº¢nh nhá»‹ phÃ¢n
            
        Returns:
            List[int]: Danh sÃ¡ch vá»‹ trÃ­ x cá»§a cÃ¡c Ä‘Æ°á»ng káº» dá»c
        """
        # Táº¡o kernel dá»c Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘Æ°á»ng káº» dá»c
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, self.height//10))
        
        # Morphological operations
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
        
        # TÃ¬m contours cá»§a Ä‘Æ°á»ng káº» dá»c
        contours, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        line_positions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            # Äiá»u kiá»‡n: Ä‘Æ°á»ng káº» dá»c (cao, háº¹p)
            if h > self.height * 0.5 and w <= 10:
                line_positions.append(x + w//2)
        
        return sorted(line_positions)
    
    def find_text_regions(self, binary: np.ndarray) -> List[int]:
        """
        TÃ¬m vÃ¹ng text Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cá»™t
        
        Args:
            binary (np.ndarray): áº¢nh nhá»‹ phÃ¢n
            
        Returns:
            List[int]: Danh sÃ¡ch vá»‹ trÃ­ gaps giá»¯a cÃ¡c vÃ¹ng text
        """
        # Táº¡o kernel ngang Ä‘á»ƒ nhÃ³m text
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (self.width//50, 1))
        
        # Dilate Ä‘á»ƒ nhÃ³m text thÃ nh blocks
        dilated = cv2.dilate(binary, horizontal_kernel, iterations=2)
        
        # TÃ¬m contours cá»§a text blocks
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        text_regions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            if w > 30 and h > 10:  # Filter noise
                text_regions.append((x, x + w))
        
        # NhÃ³m text regions thÃ nh columns
        text_regions.sort()
        
        # TÃ¬m gaps giá»¯a cÃ¡c text regions
        gaps = []
        if len(text_regions) > 1:
            for i in range(len(text_regions) - 1):
                gap_start = text_regions[i][1]
                gap_end = text_regions[i + 1][0]
                if gap_end - gap_start > 10:  # Significant gap
                    gaps.append((gap_start + gap_end) // 2)
        
        return gaps
    
    def combine_detections(self, hough_lines: List[int], projection_peaks: List[int], 
                          morph_lines: List[int], text_gaps: List[int]) -> List[int]:
        """
        Káº¿t há»£p káº¿t quáº£ tá»« cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau
        
        Args:
            hough_lines: Káº¿t quáº£ tá»« Hough Transform
            projection_peaks: Káº¿t quáº£ tá»« vertical projection
            morph_lines: Káº¿t quáº£ tá»« morphological operations
            text_gaps: Káº¿t quáº£ tá»« text region analysis
            
        Returns:
            List[int]: Danh sÃ¡ch vá»‹ trÃ­ cá»™t Ä‘Ã£ Ä‘Æ°á»£c cluster
        """
        print(f"ğŸ” Hough lines: {hough_lines}")
        print(f"ğŸ” Projection peaks: {projection_peaks}")
        print(f"ğŸ” Morphological lines: {morph_lines}")
        print(f"ğŸ” Text gaps: {text_gaps}")
        
        # Tá»•ng há»£p táº¥t cáº£ candidates
        all_candidates = []
        
        # ThÃªm vá»›i trá»ng sá»‘ khÃ¡c nhau
        for line in hough_lines:
            all_candidates.extend([line] * 3)  # Trá»ng sá»‘ cao
        
        for peak in projection_peaks:
            all_candidates.extend([peak] * 2)  # Trá»ng sá»‘ trung bÃ¬nh
            
        for line in morph_lines:
            all_candidates.extend([line] * 2)  # Trá»ng sá»‘ trung bÃ¬nh
            
        for gap in text_gaps:
            all_candidates.append(gap)  # Trá»ng sá»‘ tháº¥p
        
        if not all_candidates:
            return self.fallback_column_detection()
        
        # Cluster cÃ¡c candidates gáº§n nhau
        all_candidates.sort()
        clusters = []
        current_cluster = [all_candidates[0]]
        
        for candidate in all_candidates[1:]:
            if candidate - current_cluster[-1] <= 15:  # Trong cÃ¹ng cluster
                current_cluster.append(candidate)
            else:
                # TÃ­nh trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a cluster
                cluster_center = int(np.mean(current_cluster))
                clusters.append(cluster_center)
                current_cluster = [candidate]
        
        # ThÃªm cluster cuá»‘i
        if current_cluster:
            cluster_center = int(np.mean(current_cluster))
            clusters.append(cluster_center)
        
        # Lá»c cÃ¡c cluster á»Ÿ biÃªn
        clusters = [c for c in clusters if 20 < c < self.width - 20]
        
        return sorted(clusters)
    
    def fallback_column_detection(self) -> List[int]:
        """
        PhÆ°Æ¡ng phÃ¡p dá»± phÃ²ng - tráº£ vá» lá»—i khi khÃ´ng detect Ä‘Æ°á»£c
        
        Raises:
            RuntimeError: Khi khÃ´ng thá»ƒ phÃ¡t hiá»‡n cáº¥u trÃºc báº£ng
        """
        raise RuntimeError(
            "âŒ KhÃ´ng thá»ƒ phÃ¡t hiá»‡n cáº¥u trÃºc báº£ng tá»± Ä‘á»™ng!\n"
            "ğŸ” CÃ¡c nguyÃªn nhÃ¢n cÃ³ thá»ƒ:\n"
            "   - áº¢nh khÃ´ng rÃµ nÃ©t hoáº·c bá»‹ má»\n"
            "   - ÄÆ°á»ng káº» báº£ng khÃ´ng rÃµ rÃ ng\n"
            "   - Äá»‹nh dáº¡ng báº£ng khÃ´ng chuáº©n\n"
            "   - Äá»™ tÆ°Æ¡ng pháº£n tháº¥p\n"
            "ğŸ’¡ Gá»£i Ã½ kháº¯c phá»¥c:\n"
            "   - Chá»¥p láº¡i áº£nh vá»›i Ä‘á»™ phÃ¢n giáº£i cao hÆ¡n\n"
            "   - Äáº£m báº£o áº£nh cÃ³ Ä‘Æ°á»ng káº» rÃµ rÃ ng\n"
            "   - TÄƒng Ä‘á»™ tÆ°Æ¡ng pháº£n cá»§a áº£nh\n"
            "   - Kiá»ƒm tra Ä‘á»‹nh dáº¡ng báº£ng cÃ³ Ä‘Ãºng 4 cá»™t khÃ´ng"
        )
    
    def refine_column_positions(self, candidates: List[int]) -> List[int]:
        """
        Tinh chá»‰nh vá»‹ trÃ­ cá»™t Ä‘á»ƒ cÃ³ 3 cá»™t chÃ­nh xÃ¡c
        
        Args:
            candidates: Danh sÃ¡ch cÃ¡c vá»‹ trÃ­ cá»™t candidate
            
        Returns:
            List[int]: Danh sÃ¡ch 3 vá»‹ trÃ­ cá»™t cuá»‘i cÃ¹ng
            
        Raises:
            RuntimeError: Khi khÃ´ng Ä‘á»§ cá»™t Ä‘á»ƒ táº¡o báº£ng 4 cá»™t
        """
        if len(candidates) == 0:
            raise RuntimeError(
                "âŒ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c báº¥t ká»³ cá»™t nÃ o!\n"
                "ğŸ” Vui lÃ²ng kiá»ƒm tra:\n"
                "   - áº¢nh cÃ³ Ä‘Æ°á»ng káº» dá»c rÃµ rÃ ng khÃ´ng?\n"
                "   - Cháº¥t lÆ°á»£ng áº£nh cÃ³ Ä‘á»§ tá»‘t khÃ´ng?\n"
                "   - Báº£ng cÃ³ Ä‘Ãºng Ä‘á»‹nh dáº¡ng 4 cá»™t khÃ´ng?"
            )
        
        if len(candidates) == 1:
            raise RuntimeError(
                "âŒ Chá»‰ phÃ¡t hiá»‡n Ä‘Æ°á»£c 1 cá»™t!\n"
                f"ğŸ” Vá»‹ trÃ­ phÃ¡t hiá»‡n: {candidates[0]}\n"
                "ğŸ’¡ Cáº§n Ã­t nháº¥t 2 Ä‘Æ°á»ng káº» Ä‘á»ƒ táº¡o 3 cá»™t.\n"
                "   Vui lÃ²ng kiá»ƒm tra láº¡i áº£nh báº£ng."
            )
        
        if len(candidates) == 2:
            raise RuntimeError(
                "âŒ Chá»‰ phÃ¡t hiá»‡n Ä‘Æ°á»£c 2 cá»™t!\n"
                f"ğŸ” Vá»‹ trÃ­ phÃ¡t hiá»‡n: {candidates}\n"
                "ğŸ’¡ Cáº§n Ã­t nháº¥t 3 Ä‘Æ°á»ng káº» Ä‘á»ƒ táº¡o 4 cá»™t báº£ng.\n"
                "   Vui lÃ²ng kiá»ƒm tra láº¡i cháº¥t lÆ°á»£ng áº£nh."
            )
        
        if len(candidates) == 3:
            return candidates
        else:
            # Náº¿u cÃ³ nhiá»u hÆ¡n 3, chá»n 3 vá»‹ trÃ­ tá»‘i Æ°u
            print(f"ğŸ” PhÃ¡t hiá»‡n {len(candidates)} cá»™t, Ä‘ang chá»n 3 vá»‹ trÃ­ tá»‘i Æ°u...")
            
            # Æ¯u tiÃªn chá»n nhá»¯ng vá»‹ trÃ­ táº¡o ra 4 pháº§n cÃ¢n Ä‘á»‘i
            best_score = float('inf')
            best_positions = candidates[:3]
            
            # Thá»­ táº¥t cáº£ tá»• há»£p 3 vá»‹ trÃ­
            from itertools import combinations
            for combo in combinations(candidates, 3):
                combo = sorted(combo)
                
                # TÃ­nh Ä‘á»™ cÃ¢n Ä‘á»‘i cá»§a 4 pháº§n
                sections = [
                    combo[0],                    # Pháº§n 1
                    combo[1] - combo[0],         # Pháº§n 2  
                    combo[2] - combo[1],         # Pháº§n 3
                    self.width - combo[2]        # Pháº§n 4
                ]
                
                # TÃ­nh coefficient of variation (CV)
                mean_section = np.mean(sections)
                std_section = np.std(sections)
                cv = std_section / mean_section if mean_section > 0 else float('inf')
                
                if cv < best_score:
                    best_score = cv
                    best_positions = combo
            
            print(f"ğŸ¯ Chá»n vá»‹ trÃ­ tá»‘i Æ°u: {best_positions} (CV: {best_score:.3f})")
            return list(best_positions)
    
    def visualize_detection(self, column_positions: List[int], save_path: str = "debug_detection.png") -> None:
        """
        Váº½ áº£nh debug Ä‘á»ƒ kiá»ƒm tra káº¿t quáº£
        
        Args:
            column_positions: Danh sÃ¡ch vá»‹ trÃ­ cá»™t
            save_path: ÄÆ°á»ng dáº«n lÆ°u áº£nh debug
        """
        debug_img = self.img.copy()
        
        # Váº½ cÃ¡c Ä‘Æ°á»ng cá»™t
        for i, pos in enumerate(column_positions):
            color = [(0, 255, 0), (255, 0, 0), (0, 0, 255)][i % 3]
            cv2.line(debug_img, (pos, 0), (pos, self.height), color, 3)
            cv2.putText(debug_img, f"Col {i+1}: {pos}", 
                       (pos + 5, 30 + i*25), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.7, color, 2)
        
        # Hiá»ƒn thá»‹ 4 pháº§n Ä‘Æ°á»£c táº¡o
        sections = [column_positions[0], 
                   column_positions[1] - column_positions[0],
                   column_positions[2] - column_positions[1], 
                   self.width - column_positions[2]]
        
        cv2.putText(debug_img, f"Sections: {sections}", 
                   (10, self.height - 20), cv2.FONT_HERSHEY_SIMPLEX, 
                   0.6, (255, 255, 255), 2)
        
        cv2.imwrite(save_path, debug_img)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u áº£nh debug: {save_path}")
    
    def split_table(self, output_dir: str = "output") -> Tuple[str, str, List[int], np.ndarray, np.ndarray]:
        """
        Thá»±c hiá»‡n tÃ¡ch báº£ng tá»± Ä‘á»™ng
        
        Args:
            output_dir (str): ThÆ° má»¥c lÆ°u káº¿t quáº£. Máº·c Ä‘á»‹nh lÃ  "output"
            
        Returns:
            Tuple[str, str, List[int], np.ndarray, np.ndarray]: 
                - ÄÆ°á»ng dáº«n áº£nh 1 (STT + Há» vÃ  TÃªn + Äá»“ng Ã½)
                - ÄÆ°á»ng dáº«n áº£nh 2 (STT + Há» vÃ  TÃªn + KhÃ´ng Ä‘á»“ng Ã½) 
                - Danh sÃ¡ch vá»‹ trÃ­ cá»™t phÃ¡t hiá»‡n Ä‘Æ°á»£c
                - áº¢nh 1 dÆ°á»›i dáº¡ng numpy array (BGR)
                - áº¢nh 2 dÆ°á»›i dáº¡ng numpy array (BGR)
        """
        # Táº£i vÃ  xá»­ lÃ½ áº£nh
        self.load_image()
        binary = self.preprocess_image()
        
        # Ãp dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p detection
        hough_lines = self.detect_vertical_lines_hough(binary)
        projection_peaks, _ = self.analyze_vertical_projection(binary)
        morph_lines = self.detect_morphological_lines(binary)
        text_gaps = self.find_text_regions(binary)
        
        # Káº¿t há»£p káº¿t quáº£
        candidates = self.combine_detections(hough_lines, projection_peaks, 
                                           morph_lines, text_gaps)
        
        # Tinh chá»‰nh Ä‘á»ƒ cÃ³ Ä‘Ãºng 3 vá»‹ trÃ­ cá»™t
        column_positions = self.refine_column_positions(candidates)
        
        print(f"âœ… Vá»‹ trÃ­ cá»™t cuá»‘i cÃ¹ng: {column_positions}")
        
        # Visualize káº¿t quáº£
        debug_path = os.path.join(output_dir, "debug_detection.png")
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        self.visualize_detection(column_positions, debug_path)
        
        # Chuyá»ƒn Ä‘á»•i sang PIL Ä‘á»ƒ xá»­ lÃ½
        img_rgb = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(img_rgb)
        
        # Táº¡o áº£nh 1: STT + Há» vÃ  TÃªn + Äá»“ng Ã½ (3 cá»™t Ä‘áº§u)
        img1_pil = pil_img.crop((0, 0, column_positions[2], self.height))
        
        # Táº¡o áº£nh 2: STT + Há» vÃ  TÃªn + KhÃ´ng Ä‘á»“ng Ã½
        # GhÃ©p cá»™t 1,2 vá»›i cá»™t 4
        img2_left = pil_img.crop((0, 0, column_positions[1], self.height))  # STT + Há» vÃ  TÃªn
        img2_right = pil_img.crop((column_positions[2], 0, self.width, self.height))  # KhÃ´ng Ä‘á»“ng Ã½
        
        # GhÃ©p hai pháº§n
        img2_width = column_positions[1] + (self.width - column_positions[2])
        img2_pil = Image.new('RGB', (img2_width, self.height), 'white')
        img2_pil.paste(img2_left, (0, 0))
        img2_pil.paste(img2_right, (column_positions[1], 0))
        
        # LÆ°u káº¿t quáº£
        output1_path = os.path.join(output_dir, "table_dong_y.png")
        output2_path = os.path.join(output_dir, "table_khong_dong_y.png")
        
        img1_pil.save(output1_path, quality=95, optimize=True)
        img2_pil.save(output2_path, quality=95, optimize=True)
        
        # Chuyá»ƒn Ä‘á»•i sang numpy arrays (BGR format cho OpenCV)
        img1_numpy = cv2.cvtColor(np.array(img1_pil), cv2.COLOR_RGB2BGR)
        img2_numpy = cv2.cvtColor(np.array(img2_pil), cv2.COLOR_RGB2BGR)
        
        print(f"âœ… ÄÃ£ táº¡o áº£nh 1 (STT + Há» vÃ  TÃªn + Äá»“ng Ã½): {output1_path}")
        print(f"âœ… ÄÃ£ táº¡o áº£nh 2 (STT + Há» vÃ  TÃªn + KhÃ´ng Ä‘á»“ng Ã½): {output2_path}")
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c áº£nh 1: {img1_numpy.shape}")
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c áº£nh 2: {img2_numpy.shape}")
        
        return output1_path, output2_path, column_positions, img1_numpy, img2_numpy

def main():
    """HÃ m chÃ­nh Ä‘á»ƒ demo"""
    print("ğŸš€ Auto Table Splitter - PhiÃªn báº£n chuáº©n hÃ³a")
    print("=" * 60)
    
    # ÄÆ°á»ng dáº«n áº£nh input
    input_path = "table_01_cropped.jpg"  # Thay Ä‘á»•i tÃªn file theo áº£nh cá»§a báº¡n
    
    if not os.path.exists(input_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {input_path}")
        print("ğŸ’¡ Vui lÃ²ng Ä‘áº·t file áº£nh báº£ng vÃ o thÆ° má»¥c")
        return
    
    try:
        # Khá»Ÿi táº¡o vÃ  cháº¡y
        splitter = AutoTableSplitter(input_path)
        
        # Gá»i hÃ m split_table vá»›i thÆ° má»¥c output tÃ¹y chá»‰nh
        output1_path, output2_path, positions, img1_np, img2_np = splitter.split_table("my_output")
        
        print("\nğŸ‰ HoÃ n thÃ nh!")
        print(f"ğŸ“Š Vá»‹ trÃ­ cá»™t phÃ¡t hiá»‡n: {positions}")
        print(f"ğŸ“ áº¢nh 1: {output1_path}")
        print(f"ğŸ“ áº¢nh 2: {output2_path}")
        print(f"ğŸ” áº¢nh debug: my_output/debug_detection.png")
        print(f"ğŸ“Š Shape áº£nh 1 (numpy): {img1_np.shape}")
        print(f"ğŸ“Š Shape áº£nh 2 (numpy): {img2_np.shape}")
        
        # VÃ­ dá»¥ sá»­ dá»¥ng numpy arrays
        print(f"ğŸ¯ CÃ³ thá»ƒ sá»­ dá»¥ng img1_np vÃ  img2_np cho xá»­ lÃ½ tiáº¿p theo...")
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()