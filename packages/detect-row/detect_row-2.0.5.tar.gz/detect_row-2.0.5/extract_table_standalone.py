#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tr√≠ch xu·∫•t b·∫£ng v√† rows - Phi√™n b·∫£n Standalone
=============================================

Script ƒë·ªôc l·∫≠p kh√¥ng ph·ª• thu·ªôc v√†o package detect_row
Ch·ªâ s·ª≠ d·ª•ng: opencv-python, numpy, scikit-learn, matplotlib

T√≠nh nƒÉng:
1. Ph√°t hi·ªán b·∫£ng b·∫±ng contour analysis
2. Tr√≠ch xu·∫•t rows v·ªõi HoughLines + DBSCAN clustering  
3. Lo·∫°i b·ªè header th√¥ng minh
4. Ph√¢n t√≠ch text density
5. Visualization v√† b√°o c√°o chi ti·∫øt

S·ª≠ d·ª•ng: python extract_table_standalone.py
"""

import os
import cv2
import numpy as np
import json
from datetime import datetime
from typing import List, Tuple, Dict, Any
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN

def ensure_dir(path: str):
    """T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥"""
    os.makedirs(path, exist_ok=True)
    print(f"üìÅ Created directory: {path}")

def preprocess_image(image: np.ndarray) -> np.ndarray:
    """
    Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ ph√°t hi·ªán b·∫£ng t·ªët h∆°n
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o
    
    Returns:
        np.ndarray: ·∫¢nh ƒë√£ x·ª≠ l√Ω
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # L√†m m·ªù ƒë·ªÉ gi·∫£m noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Adaptive threshold ƒë·ªÉ tƒÉng c∆∞·ªùng ƒë∆∞·ªùng vi·ªÅn
    binary = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    return binary

def detect_tables(image: np.ndarray, min_area: int = 50000) -> List[Tuple[int, int, int, int]]:
    """
    Ph√°t hi·ªán b·∫£ng trong ·∫£nh b·∫±ng contour analysis
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o
        min_area: Di·ªán t√≠ch t·ªëi thi·ªÉu c·ªßa b·∫£ng
    
    Returns:
        List[Tuple]: Danh s√°ch bounding boxes c·ªßa b·∫£ng (x, y, w, h)
    """
    # Ti·ªÅn x·ª≠ l√Ω
    processed = preprocess_image(image)
    
    # T·∫°o kernel ƒë·ªÉ k·∫øt n·ªëi c√°c ƒë∆∞·ªùng k·∫ª
    kernel_horizontal = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
    kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
    
    # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª ngang v√† d·ªçc
    horizontal_lines = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel_horizontal)
    vertical_lines = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel_vertical)
    
    # K·∫øt h·ª£p ƒë∆∞·ªùng k·∫ª ngang v√† d·ªçc
    table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)
    
    # Dilate ƒë·ªÉ k·∫øt n·ªëi c√°c th√†nh ph·∫ßn
    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    table_mask = cv2.dilate(table_mask, kernel_dilate, iterations=2)
    
    # T√¨m contours
    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    table_boxes = []
    
    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        print(f"Contour {i}: di·ªán t√≠ch = {area:.0f} pixel")
        
        if area > min_area:
            x, y, w, h = cv2.boundingRect(contour)
            
            # Ki·ªÉm tra t·ª∑ l·ªá khung h√¨nh h·ª£p l√Ω cho b·∫£ng
            aspect_ratio = w / h
            if 0.3 < aspect_ratio < 5.0:  # B·∫£ng kh√¥ng qu√° d√†i ho·∫∑c qu√° cao
                table_boxes.append((x, y, w, h))
                print(f"ƒê√£ th√™m b·∫£ng {len(table_boxes)}: ({x}, {y}, {w}, {h})")
    
    print(f"ƒê√£ ph√°t hi·ªán {len(table_boxes)} b·∫£ng")
    return table_boxes

def extract_table_images(image: np.ndarray, table_boxes: List[Tuple[int, int, int, int]], 
                        output_dir: str, margin: int = 5) -> List[str]:
    """
    Tr√≠ch xu·∫•t ·∫£nh b·∫£ng t·ª´ ·∫£nh g·ªëc
    
    Args:
        image: ·∫¢nh g·ªëc
        table_boxes: Danh s√°ch bounding boxes
        output_dir: Th∆∞ m·ª•c l∆∞u
        margin: Margin xung quanh b·∫£ng
    
    Returns:
        List[str]: Danh s√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh b·∫£ng ƒë√£ l∆∞u
    """
    table_files = []
    
    for i, (x, y, w, h) in enumerate(table_boxes):
        # Th√™m margin
        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(image.shape[1], x + w + margin)
        y2 = min(image.shape[0], y + h + margin)
        
        # Tr√≠ch xu·∫•t b·∫£ng
        table_image = image[y1:y2, x1:x2]
        
        # L∆∞u ·∫£nh
        filename = f"table_{i}.jpg"
        filepath = os.path.join(output_dir, filename)
        cv2.imwrite(filepath, table_image)
        table_files.append(filepath)
        
        print(f"ƒê√£ l∆∞u b·∫£ng {i} v√†o {filepath}")
    
    return table_files

def advanced_line_detection(image: np.ndarray, min_line_length: int = 50) -> List[List[int]]:
    """
    Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª ngang n√¢ng cao v·ªõi HoughLinesP
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o (grayscale)
        min_line_length: ƒê·ªô d√†i t·ªëi thi·ªÉu c·ªßa ƒë∆∞·ªùng k·∫ª
    
    Returns:
        List[List[int]]: Danh s√°ch c√°c ƒë∆∞·ªùng k·∫ª ngang [x1, y1, x2, y2]
    """
    # Canny edge detection
    edges = cv2.Canny(image, 50, 150, apertureSize=3)
    
    # HoughLinesP ƒë·ªÉ ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª
    lines = cv2.HoughLinesP(
        edges, 
        rho=1, 
        theta=np.pi/180, 
        threshold=100,
        minLineLength=min_line_length,
        maxLineGap=10
    )
    
    horizontal_lines = []
    
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i ƒë∆∞·ªùng ngang kh√¥ng (g√≥c nh·ªè)
            if abs(y2 - y1) <= 5:  # ƒê·ªô l·ªách d·ªçc nh·ªè
                horizontal_lines.append([x1, y1, x2, y2])
    
    print(f"üîç Ph√°t hi·ªán {len(horizontal_lines)} ƒë∆∞·ªùng k·∫ª ngang b·∫±ng HoughLines")
    return horizontal_lines

def cluster_horizontal_lines(lines: List[List[int]], eps: int = 10) -> List[int]:
    """
    Gom nh√≥m c√°c ƒë∆∞·ªùng k·∫ª ngang th√†nh c√°c nh√≥m theo t·ªça ƒë·ªô y
    
    Args:
        lines: Danh s√°ch ƒë∆∞·ªùng k·∫ª ngang
        eps: Kho·∫£ng c√°ch t·ªëi ƒëa ƒë·ªÉ gom nh√≥m
    
    Returns:
        List[int]: Danh s√°ch t·ªça ƒë·ªô y ƒë·∫°i di·ªán cho t·ª´ng nh√≥m
    """
    if not lines:
        return []
    
    # L·∫•y t·ªça ƒë·ªô y trung b√¨nh c·ªßa m·ªói ƒë∆∞·ªùng k·∫ª
    y_coords = []
    for line in lines:
        x1, y1, x2, y2 = line
        y_avg = (y1 + y2) // 2
        y_coords.append([y_avg])
    
    # S·ª≠ d·ª•ng DBSCAN ƒë·ªÉ gom nh√≥m
    if len(y_coords) > 1:
        clustering = DBSCAN(eps=eps, min_samples=1).fit(y_coords)
        labels = clustering.labels_
        
        # T√≠nh t·ªça ƒë·ªô y trung b√¨nh cho m·ªói cluster
        unique_labels = set(labels)
        clustered_lines = []
        
        for label in unique_labels:
            if label != -1:  # B·ªè qua noise
                cluster_points = [y_coords[i][0] for i in range(len(labels)) if labels[i] == label]
                avg_y = int(np.mean(cluster_points))
                clustered_lines.append(avg_y)
        
        clustered_lines.sort()
        print(f"üìä Gom nh√≥m th√†nh {len(clustered_lines)} ƒë∆∞·ªùng k·∫ª ch√≠nh")
        return clustered_lines
    else:
        return [y_coords[0][0]] if y_coords else []

def analyze_table_structure(image: np.ndarray) -> Dict[str, Any]:
    """
    Ph√¢n t√≠ch c·∫•u tr√∫c b·∫£ng n√¢ng cao
    
    Args:
        image: ·∫¢nh b·∫£ng
    
    Returns:
        Dict: Th√¥ng tin c·∫•u tr√∫c b·∫£ng
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    height, width = gray.shape
    
    # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª ngang
    horizontal_lines = advanced_line_detection(gray, min_line_length=width//4)
    
    # Gom nh√≥m ƒë∆∞·ªùng k·∫ª
    clustered_y = cluster_horizontal_lines(horizontal_lines, eps=15)
    
    # Th√™m vi·ªÅn tr√™n v√† d∆∞·ªõi n·∫øu c·∫ßn
    if not clustered_y or clustered_y[0] > 20:
        clustered_y.insert(0, 0)
    if not clustered_y or clustered_y[-1] < height - 20:
        clustered_y.append(height)
    
    # Ph√¢n t√≠ch rows
    rows_info = []
    for i in range(len(clustered_y) - 1):
        y1 = clustered_y[i]
        y2 = clustered_y[i + 1]
        row_height = y2 - y1
        
        # Ph√¢n t√≠ch n·ªôi dung row
        row_region = gray[y1:y2, :]
        
        # T√≠nh m·∫≠t ƒë·ªô pixel t·ªëi (text)
        _, binary = cv2.threshold(row_region, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        text_density = np.sum(binary == 255) / binary.size
        
        # Ph√¢n t√≠ch horizontal projection
        h_projection = np.sum(binary, axis=1)
        has_strong_text = np.max(h_projection) > width * 10  # Ng∆∞·ª°ng text m·∫°nh
        
        row_info = {
            "index": i,
            "y1": y1,
            "y2": y2,
            "height": row_height,
            "text_density": text_density,
            "has_strong_text": has_strong_text,
            "is_likely_header": i == 0 and (text_density > 0.05 or row_height > 50)
        }
        rows_info.append(row_info)
    
    structure = {
        "total_rows": len(rows_info),
        "rows": rows_info,
        "horizontal_lines": horizontal_lines,
        "clustered_lines": clustered_y,
        "table_height": height,
        "table_width": width
    }
    
    return structure

def extract_rows_advanced(image: np.ndarray, structure: Dict[str, Any], skip_header: bool = True) -> List[Dict[str, Any]]:
    """
    Tr√≠ch xu·∫•t rows v·ªõi ph∆∞∆°ng ph√°p n√¢ng cao
    
    Args:
        image: ·∫¢nh b·∫£ng g·ªëc
        structure: C·∫•u tr√∫c b·∫£ng ƒë√£ ph√¢n t√≠ch  
        skip_header: C√≥ b·ªè qua header kh√¥ng
    
    Returns:
        List[Dict]: Danh s√°ch th√¥ng tin rows ƒë√£ tr√≠ch xu·∫•t
    """
    extracted_rows = []
    
    for row_info in structure["rows"]:
        i = row_info["index"]
        y1 = row_info["y1"]
        y2 = row_info["y2"]
        
        # Quy·∫øt ƒë·ªãnh c√≥ tr√≠ch xu·∫•t row n√†y kh√¥ng
        should_extract = True
        skip_reason = ""
        
        # B·ªè qua header n·∫øu c·∫ßn
        if skip_header and row_info.get("is_likely_header", False):
            should_extract = False
            skip_reason = "Header row"
        
        # B·ªè qua row qu√° th·∫•p
        if row_info["height"] < 20:
            should_extract = False
            skip_reason = "Too small"
        
        # B·ªè qua row kh√¥ng c√≥ text
        if row_info["text_density"] < 0.005:
            should_extract = False
            skip_reason = "No text content"
        
        if should_extract:
            # Tr√≠ch xu·∫•t row v·ªõi margin nh·ªè
            margin = 2
            y1_adj = max(0, y1 + margin)
            y2_adj = min(image.shape[0], y2 - margin)
            
            row_image = image[y1_adj:y2_adj, :]
            
            # L∆∞u th√¥ng tin row ƒë√£ tr√≠ch xu·∫•t
            extracted_info = {
                "original_index": i,
                "extracted_index": len(extracted_rows),
                "y1": y1_adj,
                "y2": y2_adj,
                "height": y2_adj - y1_adj,
                "text_density": row_info["text_density"],
                "has_strong_text": row_info["has_strong_text"],
                "row_image": row_image,
                "skip_reason": None
            }
            extracted_rows.append(extracted_info)
            
            print(f"‚úÖ Tr√≠ch xu·∫•t Row {len(extracted_rows)}: y={y1_adj}-{y2_adj} (h={y2_adj - y1_adj}px) - Density: {row_info['text_density']:.3f}")
        else:
            print(f"‚è≠Ô∏è B·ªè qua Row {i}: {skip_reason} - y={y1}-{y2} (h={row_info['height']}px)")
    
    return extracted_rows

def save_extracted_rows(rows: List[Dict[str, Any]], output_dir: str, table_name: str) -> List[str]:
    """
    L∆∞u c√°c rows ƒë√£ tr√≠ch xu·∫•t
    
    Args:
        rows: Danh s√°ch rows ƒë√£ tr√≠ch xu·∫•t
        output_dir: Th∆∞ m·ª•c l∆∞u
        table_name: T√™n b·∫£ng
    
    Returns:
        List[str]: Danh s√°ch ƒë∆∞·ªùng d·∫´n files ƒë√£ l∆∞u
    """
    saved_files = []
    
    for row_info in rows:
        extracted_idx = row_info["extracted_index"]
        row_image = row_info["row_image"]
        
        # T·∫°o t√™n file
        filename = f"{table_name}_row_{extracted_idx:02d}.jpg"
        filepath = os.path.join(output_dir, filename)
        
        # L∆∞u ·∫£nh
        cv2.imwrite(filepath, row_image)
        saved_files.append(filepath)
        
        print(f"üíæ ƒê√£ l∆∞u: {filename}")
    
    return saved_files

def create_visualization(image: np.ndarray, structure: Dict[str, Any], output_path: str):
    """
    T·∫°o visualization cho vi·ªác ph√¢n t√≠ch b·∫£ng
    
    Args:
        image: ·∫¢nh b·∫£ng g·ªëc
        structure: C·∫•u tr√∫c ƒë√£ ph√¢n t√≠ch
        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u visualization
    """
    fig, axes = plt.subplots(1, 2, figsize=(15, 8))
    
    # ·∫¢nh g·ªëc v·ªõi ƒë∆∞·ªùng k·∫ª ƒë∆∞·ª£c ph√°t hi·ªán
    axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    axes[0].set_title('B·∫£ng g·ªëc + ƒê∆∞·ªùng k·∫ª ph√°t hi·ªán')
    
    # V·∫Ω c√°c ƒë∆∞·ªùng k·∫ª ƒë√£ gom nh√≥m
    for y in structure["clustered_lines"]:
        axes[0].axhline(y=y, color='red', linestyle='--', linewidth=2, alpha=0.7)
    
    # ƒê√°nh s·ªë rows
    for i, row in enumerate(structure["rows"]):
        y_center = (row["y1"] + row["y2"]) // 2
        axes[0].text(10, y_center, f'Row {i}', color='blue', fontsize=12, fontweight='bold')
    
    axes[0].set_xlim(0, image.shape[1])
    axes[0].set_ylim(image.shape[0], 0)
    
    # Bi·ªÉu ƒë·ªì text density
    row_indices = [r["index"] for r in structure["rows"]]
    text_densities = [r["text_density"] for r in structure["rows"]]
    
    axes[1].bar(row_indices, text_densities, alpha=0.7)
    axes[1].set_title('M·∫≠t ƒë·ªô Text theo Row')
    axes[1].set_xlabel('Row Index')
    axes[1].set_ylabel('Text Density')
    axes[1].grid(True, alpha=0.3)
    
    # ƒê√°nh d·∫•u header
    for i, row in enumerate(structure["rows"]):
        if row.get("is_likely_header", False):
            axes[1].bar(i, row["text_density"], color='red', alpha=0.8, label='Header')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"üìä ƒê√£ l∆∞u visualization: {output_path}")

def main():
    """H√†m ch√≠nh"""
    image_path = "image0524.png"
    output_base = "standalone_extraction_output"
    
    print(f"üöÄ TR√çCH XU·∫§T B·∫¢NG STANDALONE (KH√îNG PH·ª§ THU·ªòC PACKAGE)")
    print(f"üì∏ ·∫¢nh ƒë·∫ßu v√†o: {image_path}")
    print(f"üìÅ Th∆∞ m·ª•c ƒë·∫ßu ra: {output_base}")
    print(f"‚è∞ Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üîß Th∆∞ vi·ªán: OpenCV + NumPy + Scikit-learn + Matplotlib")
    
    if not os.path.exists(image_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")
        return
    
    # T·∫°o th∆∞ m·ª•c output
    ensure_dir(output_base)
    ensure_dir(f"{output_base}/tables")
    ensure_dir(f"{output_base}/rows")
    ensure_dir(f"{output_base}/analysis")
    ensure_dir(f"{output_base}/debug")
    
    # ƒê·ªçc ·∫£nh
    image = cv2.imread(image_path)
    if image is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        return
    
    # B∆∞·ªõc 1: Ph√°t hi·ªán v√† tr√≠ch xu·∫•t b·∫£ng
    print(f"\n{'='*60}")
    print("B∆Ø·ªöC 1: PH√ÅT HI·ªÜN V√Ä TR√çCH XU·∫§T B·∫¢NG")
    print(f"{'='*60}")
    
    # Ph√°t hi·ªán b·∫£ng
    table_boxes = detect_tables(image, min_area=50000)
    
    if not table_boxes:
        print("‚ùå Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c b·∫£ng n√†o!")
        return
    
    # Tr√≠ch xu·∫•t ·∫£nh b·∫£ng
    table_files = extract_table_images(image, table_boxes, f"{output_base}/tables", margin=5)
    
    print(f"‚úÖ Tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(table_files)} b·∫£ng")
    
    # B∆∞·ªõc 2: Ph√¢n t√≠ch v√† tr√≠ch xu·∫•t rows cho t·ª´ng b·∫£ng
    print(f"\n{'='*60}")
    print("B∆Ø·ªöC 2: PH√ÇN T√çCH V√Ä TR√çCH XU·∫§T ROWS")
    print(f"{'='*60}")
    
    all_results = []
    
    for i, table_file in enumerate(table_files):
        table_name = f"table_{i}"
        
        print(f"\n--- X·ª≠ l√Ω {os.path.basename(table_file)} ({i+1}/{len(table_files)}) ---")
        
        # ƒê·ªçc ·∫£nh b·∫£ng
        table_image = cv2.imread(table_file)
        if table_image is None:
            print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc {table_file}")
            continue
        
        # Ph√¢n t√≠ch c·∫•u tr√∫c b·∫£ng
        print("üîç Ph√¢n t√≠ch c·∫•u tr√∫c b·∫£ng...")
        structure = analyze_table_structure(table_image)
        
        print(f"üìä Ph√°t hi·ªán {structure['total_rows']} rows ti·ªÅm nƒÉng")
        
        # Tr√≠ch xu·∫•t rows (b·ªè qua header)
        print("‚úÇÔ∏è Tr√≠ch xu·∫•t rows...")
        extracted_rows = extract_rows_advanced(table_image, structure, skip_header=True)
        
        # L∆∞u rows
        saved_files = save_extracted_rows(extracted_rows, f"{output_base}/rows", table_name)
        
        # T·∫°o visualization
        viz_path = os.path.join(f"{output_base}/analysis", f"{table_name}_analysis.png")
        create_visualization(table_image, structure, viz_path)
        
        # L∆∞u ph√¢n t√≠ch JSON
        analysis_file = os.path.join(f"{output_base}/analysis", f"{table_name}_structure.json")
        try:
            with open(analysis_file, 'w', encoding='utf-8') as f:
                # Lo·∫°i b·ªè row_image v√† convert numpy types
                clean_structure = {}
                for k, v in structure.items():
                    if k == 'rows':
                        clean_rows_structure = []
                        for row in v:
                            clean_row_struct = {}
                            for rk, rv in row.items():
                                # Convert numpy types to Python types
                                if isinstance(rv, (bool, np.bool_)):
                                    clean_row_struct[rk] = bool(rv)
                                elif isinstance(rv, (int, np.integer)):
                                    clean_row_struct[rk] = int(rv)
                                elif isinstance(rv, (float, np.floating)):
                                    clean_row_struct[rk] = float(rv)
                                else:
                                    clean_row_struct[rk] = rv
                            clean_rows_structure.append(clean_row_struct)
                        clean_structure[k] = clean_rows_structure
                    else:
                        clean_structure[k] = v
                
                clean_rows = []
                for row in extracted_rows:
                    clean_row = {}
                    for k, v in row.items():
                        if k != 'row_image':
                            # Convert numpy types to Python types
                            if isinstance(v, (bool, np.bool_)):
                                clean_row[k] = bool(v)
                            elif isinstance(v, (int, np.integer)):
                                clean_row[k] = int(v)
                            elif isinstance(v, (float, np.floating)):
                                clean_row[k] = float(v)
                            else:
                                clean_row[k] = v
                    clean_rows.append(clean_row)
                
                analysis_data = {
                    "table_name": table_name,
                    "structure": clean_structure,
                    "extracted_rows": clean_rows,
                    "saved_files": saved_files
                }
                json.dump(analysis_data, f, indent=2, ensure_ascii=False)
                print(f"üìÑ ƒê√£ l∆∞u ph√¢n t√≠ch: {analysis_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói l∆∞u JSON: {e}, b·ªè qua...")
        
        all_results.append({
            "table_name": table_name,
            "total_rows_detected": structure['total_rows'],
            "rows_extracted": len(extracted_rows),
            "saved_files": saved_files
        })
    
    # B∆∞·ªõc 3: T·∫°o b√°o c√°o t·ªïng h·ª£p
    print(f"\n{'='*60}")
    print("B∆Ø·ªöC 3: B√ÅO C√ÅO T·ªîNG H·ª¢P")
    print(f"{'='*60}")
    
    total_tables = len(all_results)
    total_rows = sum(r["rows_extracted"] for r in all_results)
    
    summary = {
        "timestamp": datetime.now().isoformat(),
        "method": "Standalone Table Extraction",
        "libraries_used": ["opencv-python", "numpy", "scikit-learn", "matplotlib"],
        "total_tables": total_tables,
        "total_rows_extracted": total_rows,
        "results": all_results
    }
    
    # L∆∞u b√°o c√°o
    summary_file = os.path.join(output_base, "standalone_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # B√°o c√°o text
    report_file = os.path.join(output_base, "standalone_report.txt")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("B√ÅO C√ÅO TR√çCH XU·∫§T B·∫¢NG STANDALONE\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Ph∆∞∆°ng ph√°p: Standalone Table Extraction\n")
        f.write(f"Th∆∞ vi·ªán: OpenCV + NumPy + Scikit-learn + Matplotlib\n")
        f.write(f"T·ªïng s·ªë b·∫£ng: {total_tables}\n")
        f.write(f"T·ªïng s·ªë rows: {total_rows}\n\n")
        
        f.write("CHI TI·∫æT:\n")
        f.write("-" * 20 + "\n")
        for result in all_results:
            f.write(f"\nB·∫£ng: {result['table_name']}\n")
            f.write(f"  Rows ph√°t hi·ªán: {result['total_rows_detected']}\n")
            f.write(f"  Rows tr√≠ch xu·∫•t: {result['rows_extracted']}\n")
            f.write(f"  Files l∆∞u: {len(result['saved_files'])}\n")
    
    # T·ªïng k·∫øt
    print(f"üéâ HO√ÄN TH√ÄNH TR√çCH XU·∫§T STANDALONE!")
    print(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {total_tables} b·∫£ng")
    print(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t: {total_rows} rows")
    print(f"üîß Ch·ªâ s·ª≠ d·ª•ng: OpenCV + NumPy + Scikit-learn + Matplotlib")
    print(f"üìÅ K·∫øt qu·∫£ l∆∞u t·∫°i: {output_base}/")
    print(f"  üìä B·∫£ng: {output_base}/tables/")
    print(f"  üìã Rows: {output_base}/rows/")
    print(f"  üìà Ph√¢n t√≠ch: {output_base}/analysis/")
    print(f"  üêõ Debug: {output_base}/debug/")
    
    # Hi·ªÉn th·ªã danh s√°ch rows
    rows_dir = f"{output_base}/rows"
    if os.path.exists(rows_dir):
        row_files = sorted([f for f in os.listdir(rows_dir) if f.endswith('.jpg')])
        if row_files:
            print(f"\nüìã {len(row_files)} rows ƒë√£ tr√≠ch xu·∫•t:")
            for row_file in row_files:
                print(f"  - {row_file}")

if __name__ == "__main__":
    main()
