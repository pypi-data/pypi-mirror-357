# Copyright (c) 2024 Justin Davis (davisjustin302@gmail.com)
#
# MIT License
from __future__ import annotations

import io
import logging
from dataclasses import dataclass, field
from pathlib import Path
from statistics import mean, median
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from collections.abc import Callable

    from typing_extensions import Self

_log = logging.getLogger(__name__)


@dataclass
class Metric:
    raw: list[float | int] = field(repr=False)
    mean: float | int = -1.0
    median: float | int = -1.0
    min: float | int = -1.0
    max: float | int = -1.0

    def __post_init__(self: Self) -> None:
        if not self.raw:
            err_msg = "Raw data cannot be empty"
            raise ValueError(err_msg)

        self.min = min(self.raw)
        self.median = median(self.raw)
        self.max = max(self.raw)
        self.mean = mean(self.raw)


def parse_tegrastats(file: Path | str | io.TextIOBase) -> list[dict[str, str]]:
    """
    Parse a file written by Tegrastats or tegrastats.

    This a general purpose parser which does not seperate entries
    or handle types. All values are still strings in original format.

    The differences from raw entry/values are:
    1. values such as (cached 0MB) become entires: CACHED: 0MB. However
    these pieces of data are part of a two-piece entry for the memory
    subsystems, so representation in fixed format (dict[str, str])
    required a change.
    2. temperature entries such as cpu@49.01C become: CPU_TEMP: 49.01C
    This change upholds that all data generated from tegrastats has
    uppercase keys and that cpu frequencies will not clash with cpu
    temperature.

    Whether or not the file was written by the class Tegrastats
    or directly by tegrastats will be determined automatically.
    Output generated by Tegrastats (Python class) will have
    a timestamp field. The Python timestamp is present as 'timestamp'.

    Example entry (from Orin AGX 64GB):

    {
    'timestamp': '1729630462.0975535',  # optional entry
    'DATE': '10-22-2024',
    'TIME': '15:54:22',
    'RAM': '23336/62841MB',
    'LFB': '199x4MB',
    'SWAP': '0/31421MB',
    'CACHED': '0MB',
    'CPU': '[0%@2201,50%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201,0%@2201]',
    'GR3D_FREQ': '0%',
    'CPU_TEMP': '48.812C',
    'TBOARD_TEMP': '38.5C',
    'SOC2_TEMP': '44.843C',
    'TDIODE_TEMP': '38.875C',
    'SOC0_TEMP': '46.156C',
    'GPU_TEMP': '43.687C',
    'TJ_TEMP': '48.812C',
    'SOC1_TEMP': '45.656C',
    'VDD_GPU_SOC': '5191mW/5190mW',
    'VDD_CPU_CV': '1996mW/2032mW',
    'VIN_SYS_5V0': '4528mW/4539mW',
    'VDDQ_VDD2_1V8AO': '401mW/411mW'
    }

    Parameters
    ----------
    file : Path, str
        The path to the file.

    Returns
    -------
    list[dict[str, str]]
        The parsed data, each entry in the list is one line from tegrastats

    Raises
    ------
    FileNotFoundError
        If the file does not exist

    """
    lines: list[str]
    if isinstance(file, io.TextIOBase):
        lines = [str(line) for line in file.readlines()]
    else:
        file = Path(file)
        if not file.exists():
            err_msg = f"Could not find tegrastats output: {file}"
            raise FileNotFoundError(err_msg)

        with file.open("r") as f:
            lines = f.readlines()

    _log.debug(f"Parsing tegrastats output with: {len(lines)} entries")

    py_delim = "::"
    python = False
    if py_delim in lines[0]:
        python = True

    entries: list[dict[str, str]] = []
    for raw in lines:
        # make entry
        entry: dict[str, str] = {}

        # strip newline
        line = raw.strip()

        # parse out python timestamp if exists
        timestamp = None
        if python:
            timestamp, line = line.split(py_delim)
        if timestamp:
            entry["timestamp"] = timestamp

        # parse remainder of line
        data = line.split(" ")

        # first two entires are always date and time (minute resolution)
        entry["DATE"] = data[0]
        entry["TIME"] = data[1]
        data = data[2:]

        # from now on each entry is UPPERCASE value
        # additional values will start with (
        # if value is found that starts with (
        # then it will be treaded as UPPERCASE value
        # by removing the ()
        name = None
        paran = False
        for value in data:
            if name is None:
                # handle paran data
                if value[0] == "(":
                    new_value = value[1:].upper()
                    paran = True
                    name = new_value
                # handle temp data
                elif "@" in value:
                    soc, temp = value.split("@")
                    temp_name = f"{soc.upper()}_TEMP"
                    entry[temp_name] = temp
                else:
                    name = value
            else:
                if paran:
                    new_value = value[:-1]
                    paran = False
                    entry[name] = new_value
                    name = None
                else:
                    entry[name] = value
                    name = None

        # write back the entry
        entries.append(entry)

    return entries


def filter_data(
    data: list[dict[str, str]],
    timestamps: list[tuple[float, float]],
) -> tuple[
    list[dict[str, str]],
    list[tuple[tuple[float, float], list[dict[str, str]]]],
]:
    """
    Filter data based on sets of timestamps.

    The data given must have the Python timestamps
    included, i.e. have been generated by Tegrastats.

    Parameters
    ----------
    data : list[dict[str, str]]
        The data to filter, generated by Tegrastats
    timestamps : list[tuple[float, float]]
        The timestamps to filter the data by.
        Each tuple should represent the (start, stop)
        where start/stop are time.time() calls.

    Returns
    -------
    tuple[list[dict[str, str]], list[list[dict[str, str]]]]
        The unique entries within all the timestamps and
        the entries within each timestamp set.

    Raises
    ------
    KeyError
        If the timestamp data cannot be found

    """
    try:
        per_inference: list[tuple[tuple[float, float], list[dict[str, str]]]] = []
        unique_filtered: dict[str, dict[str, str]] = {}
        for start, stop in timestamps:
            inf_data: list[dict[str, str]] = []
            for tdata in data:
                raw_ts = tdata["timestamp"]
                ts = float(raw_ts)
                # iterate up while timestamp less than start
                if ts < start:
                    continue
                # found some valid data
                if start <= ts <= stop:
                    inf_data.append(tdata)
                    unique_filtered[raw_ts] = tdata
                    continue
                # if neither condition hits, then ts > stop
                break
            per_inference.append(((start, stop), inf_data))
        return list(unique_filtered.values()), per_inference
    except KeyError as e:
        err_msg = "Could not get the timestamp data, did the data get written by jetsontools.Tegrastats?"
        raise KeyError(err_msg) from e


def get_data(
    data: list[dict[str, str]],
    names: list[str],
    parsefunc: Callable[[str], float | int],
) -> dict[str, Metric]:
    """
    Parse the output from parse_tegrastats to specific output.

    Parameters
    ----------
    data : list[dict[str, str]]
        The output of parse_tegrastats
    names : list[str]
        The entries of data to get
    parsefunc: Callable[[str], T]
        The parsing function to apply to each entries values

    Returns
    -------
    dict[str, list[T]]
        The parsed values, each value is the parsed values

    """
    raw: dict[str, list[float | int]] = {}

    for name in names:
        raw[name] = []

    for entry in data:
        for name in names:
            str_value = entry[name]
            value = parsefunc(str_value)
            raw[name].append(value)

    metrics: dict[str, Metric] = {}
    for name in names:
        raw_data = raw[name]
        metrics[name] = Metric(raw=raw_data)

    return metrics


def get_powerdraw(
    data: list[dict[str, str]],
) -> dict[str, Metric]:
    """
    Parse the output from parse_tegrastats to give power draw values.

    Computes two new metrics: VDD_TOTAL and VIN_TOTAL.
    Useful for profiling overall powerdraw of a Jetson system.

    Parameters
    ----------
    data : list[dict[str, str]]
        The output of parse_tegrastats

    Returns
    -------
    dict[str, list[float]]
        The parsed values, each value is the parsed values

    """

    def parse_energy_value(value: str) -> float:
        return float(value.split("/", maxsplit=1)[0][:-2])

    names = [name for name in data[0] if "VDD" in name or "VIN" in name]
    power_data = get_data(data, names, parse_energy_value)

    # total out all the VDD/VIN data
    new_metrics: list[tuple[str, Metric]] = []
    for vtype in ["VDD", "VIN", "VDD_IN"]:
        vdata = []
        for ename, edata in power_data.items():
            if vtype not in ename:
                continue
            if vtype == "VDD" and ename == "VDD_IN":
                continue
            vdata.append(edata.raw)

        if len(vdata) == 0:
            continue

        vdata_values: list[float] = [sum(pdraw_value) for pdraw_value in zip(*vdata)]

        # add as a metric
        new_metrics.append((f"{vtype}_TOTAL", Metric(raw=vdata_values)))

    # add the metrics
    for mname, metric in new_metrics:
        power_data[mname] = metric

    return power_data
