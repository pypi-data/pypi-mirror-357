# Semantic Chunker for LangChain

A **token-aware**, **LangChain-compatible** chunker that splits text (from PDF, markdown, or plain text) into semantically coherent chunks while respecting model token limits.

---

## ğŸš€ Features

* ğŸ” **Model-Aware Token Limits**: Automatically adjusts chunking size for GPT-3.5, GPT-4, Claude, and others.
* ğŸ“„ **Multi-format Input Support**:

  * PDF via `pdfplumber`
  * Plain `.txt`
  * Markdown
  * (Extendable to `.docx` and `.html`)
* ğŸ” **Overlapping Chunks**: Smart overlap between paragraphs to preserve context.
* ğŸ§  **Smart Merging**: Merges chunks smaller than 300 tokens.
* ğŸ§© **Retriever-Ready**: Direct integration with `LangChain` retrievers via FAISS.
* ğŸ”§ **CLI Support**: Run from terminal with one command.

---

## ğŸ“¦ Installation

```bash
pip install semantic-chunker-langchain
```

> Requires Python 3.9 - 3.12

---

## ğŸ› ï¸ Usage

### ğŸ”¸ Chunk a PDF and Save to JSON/TXT

```bash
semantic-chunker sample.pdf --txt chunks.txt --json chunks.json
```

### ğŸ”¸ From Code

```python
from langchain_semantic_chunker.chunker import SemanticChunker, SimpleSemanticChunker
from langchain_semantic_chunker.extractors.pdf import extract_pdf
from langchain_semantic_chunker.outputs.formatter import write_to_txt

# Extract
docs = extract_pdf("sample.pdf")
chunker = SemanticChunker(model_name="gpt-3.5-turbo")
chunks = chunker.split_documents(docs)

# Save to file
write_to_txt(chunks, "output.txt")

# Using SimpleSemanticChunker
simple_chunker = SimpleSemanticChunker(model_name="gpt-3.5-turbo")
simple_chunks = simple_chunker.split_documents(docs)
```

### ğŸ”¸ Convert to Retriever

```python
from langchain_community.embeddings import OpenAIEmbeddings
retriever = chunker.to_retriever(chunks, embedding=OpenAIEmbeddings())
```

---

## ğŸ§ª Testing

```bash
poetry run pytest tests/
```

---

## ğŸ‘¨â€ğŸ’» Authors

* Prajwal Shivaji Mandale
* Sudhnwa Ghorpade

---

## ğŸ“œ License

This project is licensed under the MIT License.
