import os
import logging
import numpy as np
import pandas as pd
from itertools import permutations
import multiprocessing as mp
from scipy.sparse import csr_matrix
from scipy.sparse.csgraph import min_weight_full_bipartite_matching
from esat.model.sa import SA
from esat.model.batch_sa import BatchSA
from esat.metrics import q_loss
from tqdm import notebook as tqdm_nb
from tqdm import tqdm

logger = logging.getLogger(__name__)


class FactorCompare:
    """
    Compare the results between a single base solution and a collection of solutions. Used for comparing the output of
    ESAT to those generated by PMF5 and by the Simulator for comparing the output of models using synthetic data and
    known synthetic profiles.

    #TODO: Factor compare for models with a different number of factors

    Parameters
    ----------
    input_df : pd.DataFrame
        The input dataset dataframe.
    uncertainty_df : pd.DataFrame
        The uncertainty dataset dataframe.
    base_profile_df : pd.DataFrame
        The base profile (H) dataframe.
    base_contribution_df : pd.DataFrame
        The base contribution (W) dataframe.
    factors_columns: list
        The list of factor names.
    features : list
        The list of feature names.
    batch_sa : BatchSA
        A completed instance of BatchSA whose models will be evaluated against the base model.
    sa_output_file : str
        The path to a completed BatchSA save file.
    method : str
        The selection method for best mapping, correlation of 'W', 'H', 'WH', or 'all'.
    """

    def __init__(self,
                 input_df: pd.DataFrame,
                 uncertainty_df: pd.DataFrame,
                 base_profile_df: pd.DataFrame,
                 base_contribution_df: pd.DataFrame,
                 batch_sa: BatchSA,
                 sa_output_file: str = None,
                 method: str = "all",
                 ):

        self.input_df = input_df
        self.uncertainty_df = uncertainty_df
        self.base_profile_df = base_profile_df
        self.base_contribution_df = base_contribution_df
        self.base_WH = {}
        self.base_V_estimate = None

        self.base_factors = base_profile_df.columns
        self.factors = len(self.base_factors)
        self.features = input_df.columns

        self._calculate_base_wh()

        self.sa_output_file = sa_output_file
        self.batch_sa = batch_sa
        self.sa_model_dfs = {}
        self.sa_factors = None
        self.sa_Q = {}
        self._parse_sa_output()

        self.model_results = {}

        self.base_k = True
        self.factor_map = None
        self.best_model = None
        self.best_factor_r = None
        self.best_avg_r = None
        self.best_factor_r_avg = None
        self.best_contribution_r = None
        self.best_contribution_r_avg = None
        self.best_wh_r = None
        self.best_wh_r_avg = None

        self.method = method if method in ('all', 'H', 'W', 'WH') else 'all'
        # 'all': equal weight between correlation of W, H and WH, 'H': only, 'W': only, 'WH': only

    @staticmethod
    def load_pmf_output(factors: int,
                        input_df: pd.DataFrame,
                        uncertainty_df: pd.DataFrame,
                        pmf_profile_file: str,
                        pmf_contribution_file: str,
                        batch_sa: BatchSA):
        """
        Load the output of a completed PMF5 base model, specifying the profile and contribution files.

        Parameters
        ----------
        factors : int
            The number of factors used in the PMF5 models.
        input_df : pd.DataFrame
            The input dataset dataframe.
        uncertainty_df : pd.DataFrame
            The uncertainty dataset dataframe.
        pmf_profile_file : str
            The path to the PMF5 output factor profile file.
        pmf_contribution_file : str
            The path to the PMF5 output factor contribution file.
        batch_sa : BatchSA
            The completed BatchSA instance which will be compared to the PMF5 output.

        Returns
        -------
        FactorCompare
            An initialized instance of FactorCompare.

        """
        if not os.path.exists(pmf_profile_file):
            logger.error(f"No pmf profile file found at: {pmf_profile_file}")
            return
        if not os.path.exists(pmf_contribution_file):
            logger.error(f"No pmf contribution file found at: {pmf_contribution_file}")
            return

        profiles = factors + 2

        pmf_profiles = []
        pmf_profile_p = []
        pmf_profile_t = []

        column_labels = None
        features = input_df.columns

        with open(pmf_profile_file, 'r') as open_file:
            profile_strings = open_file.read()
            t = profile_strings.split('\n')
            j = 0
            for line in t:
                i = line.split('\t')
                if len(i) == profiles:
                    if i[0] == '' and i[1] == '':
                        i[0] = "run"
                        i[1] = "species"
                        column_labels = i
                        continue
                    if j < len(features):
                        pmf_profiles.append(i)
                    elif j < 2 * len(features):
                        pmf_profile_p.append(i)
                    elif j < 3 * len(features):
                        pmf_profile_t.append(i)
                    j += 1
            pmf_profiles_df = pd.DataFrame(pmf_profiles, columns=column_labels)
            pmf_profiles_df.drop('run', axis=1, inplace=True)

        df_columns = list(pmf_profiles_df.columns)

        factor_columns = df_columns[1:]
        factor_types = {}
        for f in factor_columns:
            factor_types[f] = 'float'
        pmf_profiles_df = pmf_profiles_df.astype(factor_types)

        column_row = 4
        data_start_row = 5
        dates = []
        pmf_contribution_data = []
        pmf_contribution_columns = None

        with open(pmf_contribution_file, 'r') as open_file:
            contribution_strings = open_file.read()
            rows = contribution_strings.split('\n')
            for i, row in enumerate(rows):
                if i == column_row - 1:
                    pmf_contribution_columns = row.split('\t')[2:]
                elif i >= data_start_row - 1:
                    row_cells = row.split('\t')
                    if len(row_cells) > 1:
                        dates.append(row_cells[1])
                        pmf_contribution_data.append(row_cells[2:])
        pmf_contribution_df = pd.DataFrame(pmf_contribution_data, columns=pmf_contribution_columns)
        pmf_contribution_df["Datetime"] = dates

        factor_types = {}
        for f in pmf_contribution_columns:
            factor_types[f] = 'float'
        pmf_contribution_df = pmf_contribution_df.astype(factor_types)
        fc = FactorCompare(input_df=input_df,
                           uncertainty_df=uncertainty_df,
                           base_profile_df=pmf_profiles_df,
                           base_contribution_df=pmf_contribution_df,
                           batch_sa=batch_sa
                           )
        return fc

    def _calculate_base_wh(self):
        if self.base_profile_df is not None and self.base_contribution_df is not None:
            for factor in self.base_factors:
                base_W_f = self.base_contribution_df[factor].to_numpy()
                base_H_f = self.base_profile_df[factor].to_numpy()
                base_W_f = base_W_f.reshape(len(base_W_f), 1)
                base_WH_f = np.multiply(base_W_f, base_H_f)
                self.base_WH[factor] = base_WH_f
            base_W = self.base_contribution_df[self.base_factors].to_numpy()
            base_H = self.base_profile_df[self.base_factors].to_numpy()
            self.base_V_estimate = np.matmul(base_W, base_H.T)

    def _parse_sa_output(self):
        """
        Parses the output of BatchSA for comparison.
        """
        if self.batch_sa is None:
            if not os.path.exists(self.sa_output_file):
                print(f"No sa output found at: {self.sa_output_file}")
                return
            else:
                self.batch_sa = BatchSA.load(self.sa_output_file)
        species_columns = self.features
        self.sa_factors = [f"Factor {i+1}" for i in range(self.batch_sa.factors)]
        for i, i_sa in enumerate(self.batch_sa.results):
            if i_sa is None:
                continue
            sa_h_data = i_sa.H
            sa_w_data = i_sa.W
            sa_wh_data = i_sa.WH
            sa_wh_data = sa_wh_data.reshape(sa_wh_data.shape[1], sa_wh_data.shape[0])

            sa_h_df = pd.DataFrame(sa_h_data, columns=species_columns, index=self.sa_factors)
            sa_w_df = pd.DataFrame(sa_w_data, columns=self.sa_factors)
            sa_wh_df = pd.DataFrame(sa_wh_data.T, columns=species_columns)

            sa_wh_e = {}
            for factor in self.sa_factors:
                sa_H_f = sa_h_df.loc[factor].to_numpy()
                sa_W_f = sa_w_df[factor].to_numpy()
                sa_W_f = sa_W_f.reshape(len(sa_W_f), 1)
                sa_WH_f = np.multiply(sa_W_f, sa_H_f)
                sa_wh_e[factor] = sa_WH_f

            self.sa_model_dfs[i] = {"WH": sa_wh_df, "W": sa_w_df, "H": sa_h_df, 'WH-element': sa_wh_e}
            self.sa_Q[i] = i_sa.Qtrue

    def compare(self, verbose: bool = True):
        """
        Run the model comparison.

        Parameters
        ----------
        verbose : bool
            Display the results of the comparison.
        """
        correlation_results = {}
        contribution_results = {}
        wh_results = {}

        for m in range(len(self.sa_model_dfs)):
            correlation_results[m] = {}
            contribution_results[m] = {}
            wh_results[m] = {}

        correlation_count = len(self.base_factors) * len(self.sa_model_dfs) * len(self.sa_factors)
        pbar = tqdm(total=correlation_count, desc="Calculating correlation between base and model factors")
        for i in self.base_factors:
            base_i = self.base_profile_df[i].astype(float)
            base_contribution_i = self.base_contribution_df[i].astype(float)
            base_wh = self.base_WH[i].flatten()
            for m in range(len(self.sa_model_dfs)):
                model_m = self.sa_model_dfs[m]["H"]
                model_contribution_m = self.sa_model_dfs[m]["W"]
                model_wh = self.sa_model_dfs[m]["WH-element"]
                for j in self.sa_factors:
                    model_j = model_m.loc[j].astype(float)
                    r2 = self.calculate_correlation(factor1=base_i, factor2=model_j)
                    correlation_results[m][f"base-{i}_esat-{j}"] = r2
                    model_contribution_j = model_contribution_m[j].astype(float)
                    r2_2 = self.calculate_correlation(factor1=base_contribution_i, factor2=model_contribution_j)
                    contribution_results[m][f"base-{i}_esat-{j}"] = r2_2
                    model_wh_f = model_wh[j].astype(float).flatten()
                    r2_3 = self.calculate_correlation(base_wh, model_wh_f)
                    wh_results[m][f"base-{i}_esat-{j}"] = r2_3
                    pbar.update()
        pbar.close()
        best_r = 0.0
        best_perm = None
        best_model = None
        best_factor_r = None
        best_contribution_r = None
        best_contribution_r_avg = None
        best_factor_r_avg = None
        best_wh_r = None
        best_wh_r_avg = None

        pool = mp.Pool(processes=os.cpu_count()-1)

        if len(self.base_factors) >= len(self.sa_factors):
            prime_list = self.base_factors
            r = len(self.sa_factors)
            base_k = True
        else:
            prime_list = self.sa_factors
            r = len(self.base_factors)
            base_k = False
        self.base_k = base_k

        permutations_n = len(list(permutations(prime_list, r=r)))

        pbar = tqdm(total=permutations_n*len(self.sa_model_dfs),
                    desc="Calculating average correlation for all permutations for Model: 1")
        for m in range(len(self.sa_model_dfs)):
            # Each Model
            permutation_results = {}
            model_contribution_results = {}
            factor_contribution_results = {}
            best_model_r = 0.0
            factor_permutations = []

            for factor_i, factor in enumerate(list(permutations(prime_list, r=r))):
                factor_permutations.append(factor)
                if factor_i == permutations_n - 1:
                    pool_inputs = [(factor, correlation_results[m], contribution_results[m], wh_results[m], base_k)
                                   for factor in factor_permutations]
                    for pool_results in pool.starmap(self.combine_factors, pool_inputs):
                        pbar.update()
                        factor, r_avg, r_values, c_r_avg, c_r_values, wh_r_avg, wh_r_values = pool_results
                        permutation_results[factor] = (r_avg, r_values)
                        model_contribution_results[factor] = (c_r_avg, c_r_values)
                        factor_contribution_results[factor] = (wh_r_avg, wh_r_values)

                        if self.method == "all":
                            model_avg_r = (r_avg + c_r_avg + wh_r_avg) / 3.0
                        elif self.method == "W":
                            model_avg_r = c_r_avg
                        elif self.method == "H":
                            model_avg_r = r_avg
                        elif self.method == "WH":
                            model_avg_r = wh_r_avg

                        if model_avg_r > best_r:
                            best_r = model_avg_r
                            best_perm = factor
                            best_model = m
                            best_factor_r = r_values
                            best_factor_r_avg = r_avg
                            best_contribution_r = c_r_values
                            best_contribution_r_avg = c_r_avg
                            best_wh_r = wh_r_values
                            best_wh_r_avg = wh_r_avg
                        if model_avg_r > best_model_r:
                            best_model_r = model_avg_r
                            best_model_results = {
                                'best_factor_r': r_values,
                                'best_avg_r': model_avg_r,
                                'best_factor_r_avg': r_avg,
                                'best_contribution_r': c_r_values,
                                'best_contribution_r_avg': c_r_avg,
                                'best_wh_r': wh_r_values,
                                'best_wh_r_avg': wh_r_avg,
                                'factor_map': list(factor)
                            }
                            self.model_results[m] = best_model_results
                    factor_permutations = []
            pbar.set_description(f"Calculating average correlation for all permutations for Model: {1+m}")
        pbar.close()
        pool.close()

        self.best_model = best_model
        self.best_factor_r = best_factor_r
        self.best_avg_r = best_r
        self.best_factor_r_avg = best_factor_r_avg
        self.best_contribution_r = best_contribution_r
        self.best_contribution_r_avg = best_contribution_r_avg
        self.best_wh_r = best_wh_r
        self.best_wh_r_avg = best_wh_r_avg
        self.factor_map = list(best_perm)
        if verbose:
            self.print_results()

    def print_results(self, model: int = None):
        """
        Print the results of the comparison, defaulting to the model with the highest correlation mapping unless model
        is specified.

        Parameters
        ----------
        model : int
            The model index for printing the results of a specific model.

        """
        base_Q = q_loss(V=self.input_df.to_numpy(),
                        U=self.input_df.to_numpy(),
                        W=self.base_contribution_df[self.base_factors].to_numpy(),
                        H=self.base_profile_df[self.base_factors].to_numpy().T
                        )
        if model is None:
            model = self.best_model
        logger.info(f"R2 - Model: {model+1}, Best permutations: {self.model_results[model]['factor_map']}, "
                    f"Average R2: {self.model_results[model]['best_avg_r']}, \n"
                    f"Profile R2 Avg: {self.model_results[model]['best_factor_r_avg']}, "
                    f"Contribution R2 Avg: {self.model_results[model]['best_contribution_r_avg']}, "
                    f"WH R2 Avg: {self.model_results[model]['best_wh_r_avg']}\n"
                    f"Profile R2: {self.model_results[model]['best_factor_r']}, \n"
                    f"Contribution R2: {self.model_results[model]['best_contribution_r']}, \n"
                    f"WH R2: {self.model_results[model]['best_wh_r']}"
                    )
        logger.info(f"Base Q(true): {base_Q}, SA Model {model+1} Q(true): {self.sa_Q[model]}")

    @staticmethod
    def calculate_correlation(factor1, factor2):
        """
        Calculates the correlation between two factors.
        """
        f1 = factor1.astype(float)
        f2 = factor2.astype(float)
        corr_matrix = np.corrcoef(f2, f1)
        corr = corr_matrix[0, 1]
        r_sq = corr ** 2
        return r_sq

    def combine_factors(self, factors, model_correlation, model_contributions, factor_contributions,
                        base_k: bool = False):
        """
        Combine the results from parallelized calculations.
        """
        r_values = []
        r_values_2 = []
        r_values_3 = []
        if base_k:
            for i, f in enumerate(factors):
                r2 = model_correlation[f"base-{f}_esat-{self.sa_factors[i]}"]
                r2_2 = model_contributions[f"base-{f}_esat-{self.sa_factors[i]}"]
                r2_3 = factor_contributions[f"base-{f}_esat-{self.sa_factors[i]}"]
                r_values.append(r2)
                r_values_2.append(r2_2)
                r_values_3.append(r2_3)
        else:
            for i, f in enumerate(factors):
                r2 = model_correlation[f"base-{self.base_factors[i]}_esat-{f}"]
                r2_2 = model_contributions[f"base-{self.base_factors[i]}_esat-{f}"]
                r2_3 = factor_contributions[f"base-{self.base_factors[i]}_esat-{f}"]
                r_values.append(r2)
                r_values_2.append(r2_2)
                r_values_3.append(r2_3)
        r_avg = np.mean(r_values)
        r_avg_2 = np.mean(r_values_2)
        r_avg_3 = np.mean(r_values_3)
        return factors, r_avg, r_values, r_avg_2, r_values_2, r_avg_3, r_values_3


class FactorCompareV2:
    """
    Comparing factors between a base model and a list of other models, providing a mapping between the base model and
    each model in the models list.

    Parameters
    ----------
    base_model : BaseModel
        The base model to compare against.
    models : list
        A list of models to compare against the base model.

    """

    def __init__(self, base_model: SA, models: list, in_notebook: bool = False):
        self.base_model = base_model
        self.models = models
        self.factors = base_model.factors

        self.correlation_data = {}
        self.factor_map = None

        self.calculate_correlation_matrix(in_notebook=in_notebook)

    def calculate_correlation_matrix(self, in_notebook: bool = False):
        """
        Correlation matrices are calculated between a reference base model and a collection of separate models
        (independent or perturbed). The correlation metrics used for comparison are implemented as defined in the
        publication https://doi.org/10.1021/es800085t.

        Parameters
        ----------
        in_notebook : bool
            If True, the function will display a progress bar formatted for Jupyter notebooks.

        """
        base_mean_W = np.mean(self.base_model.W, axis=0)[0]
        base_mass_matrix = (base_mean_W * self.base_model.H) / np.sum(base_mean_W * self.base_model.H)
        n = 1 / self.base_model.W[:, 0].shape[0]

        pbar = tqdm(range(int(len(self.models))), desc="Calculating correlation between base and model factors",
                           leave=False)
        if in_notebook:
            pbar = tqdm_nb.tqdm(range(int(len(self.models))), desc="Calculating correlation between base and model factors",
                           leave=False)
        for i in pbar:
            i_results = {
                "corr": [],
                "corr_mapping": [],
                "all_corr": [],
                "raae": [],
                "raae_mapping": [],
                "all_raae": [],
                "emc": [],
                "emc_mapping": [],
                "all_emc": []
            }

            i_model = self.models[i]
            i_mean_W = np.mean(i_model.W, axis=0)[0]
            i_mass_matrix = (i_mean_W * i_model.H) / np.sum(i_mean_W * i_model.H)

            for j in range(self.factors):
                j_W = self.base_model.W[:, j]  # Base model W column j (factor contribution)
                j_H = self.base_model.H[j]  # Base model H row j (factor profile)

                # Tacking results of equation 4
                j_r2 = 0.0
                r2_best = -1
                all_corr = []

                # Tracking results of equation 5
                j_raae = float("inf")
                raae_best = -1
                all_raae = []

                # Tracking results of equation 7
                j_emc = 0.0
                best_emc = -1
                all_emc = []

                for k in range(self.factors):
                    k_W = i_model.W[:, k]  # Perturbed model i, W column j (perturbed factor contribution j)
                    jk_r2 = FactorCompare.calculate_correlation(factor1=j_W.flatten(),
                                                                factor2=k_W.flatten())  # Equation 4
                    jk_raae = (np.sum(np.abs(k_W - j_W)) * n) / (np.sum(j_W) * n)  # Equation 5
                    jk_emc = FactorCompare.calculate_correlation(factor1=base_mass_matrix[j],
                                                                 factor2=i_mass_matrix[k])  # Equation 7

                    if jk_r2 > j_r2:
                        r2_best = k
                        j_r2 = jk_r2
                    if jk_raae < j_raae:
                        j_raae = jk_raae
                        raae_best = k
                    if jk_emc > j_emc:
                        j_emc = jk_emc
                        best_emc = k
                    all_corr.append(jk_r2)
                    all_raae.append(jk_raae)
                    all_emc.append(jk_emc)
                i_results["corr"].append(j_r2)
                i_results["corr_mapping"].append(r2_best)
                i_results["all_corr"].append(all_corr)
                i_results["raae"].append(j_raae)
                i_results["raae_mapping"].append(raae_best)
                i_results["all_raae"].append(all_raae)
                i_results["emc"].append(j_emc)
                i_results["emc_mapping"].append(best_emc)
                i_results["all_emc"].append(all_emc)
            self.correlation_data[i] = i_results

    def determine_map(self, method: str = "raae"):
        """
        Determine the factor mapping between the base model and a collection of models.

        Parameters
        ----------
        method : str
            Correlation method to use, options include: "corr", "raae", "emc".
        """
        batch_mapping = {}
        batch_values = {}
        for i, p_model in self.correlation_data.items():
            mapping_values = [-1 for i in range(self.factors)]
            if method == "raae":
                optimal_indices = np.array(p_model["all_raae"]).argmin(axis=0)
                mapping_matrix = np.array(p_model["all_raae"])
                maximize = False
            elif method == "emc":
                optimal_indices = np.array(p_model["all_emc"]).argmax(axis=0)
                mapping_matrix = np.array(p_model["all_emc"])
                maximize = True
            else:
                optimal_indices = np.array(p_model["all_corr"]).argmax(axis=0)
                mapping_matrix = np.array(p_model["all_corr"])
                maximize = True

            # Step 1, all optimal value indices are unique and no other values need to be checked.
            if (np.unique(optimal_indices, return_counts=True)[1].max() == 1):
                model_mapping = optimal_indices
            else:
                m_bi_matrix = csr_matrix(mapping_matrix)
                model_mapping = list(min_weight_full_bipartite_matching(m_bi_matrix, maximize=maximize))
            optimal_index_tuples = list(zip(list(range(self.factors)), model_mapping))
            for j, oi in enumerate(optimal_index_tuples):
                ele_values = mapping_matrix[oi]
                mapping_values[j] = np.round(ele_values, 4)

            batch_mapping[i] = optimal_indices
            batch_values[i] = mapping_values
        return batch_mapping, batch_values