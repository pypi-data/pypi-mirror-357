# Obz AI üîç: Explainable AI, Model Monitoring, and Outlier Detection for Computer Vision Systems

Obz AI is a powerful Python package designed to bring explainability, continuous monitoring, and advanced outlier detection to AI-powered computer vision systems. With support for the latest deep learning architectures -- including vision transformers (ViT) and convolutional neural networks (CNN) -- Obz AI enables ML practitioners and data scientists to ensure transparency, reliability, and trustworthiness in their vision models.

Obz AI offers seamless integration, allowing you to use its robust features as a standalone tool or connect effortlessly to the dashboard for real-time model monitoring, data visualization, and configuration. Track your machine learning models, visualize image data, generate XAI (Explainable AI) heatmaps, and perform anomaly detection.

For more details, demo, and full documentation, visit [Obz.AI](https://obz.ai/).

## Key Features

- **Data Inspector Module**: Automatically extracts features and detects outliers, data drifts, or other anomalies in image datasets using advanced statistical and machine learning methods ‚Äî improving data quality and model robustness.
- **XAI Module**:  Generates state-of-the-art explainability heatmaps for computer vision models, including Saliency Maps, Attention Maps, CDAM, and more. Provides quantitative evaluation tools such as fidelity and compactness for model interpretability and explainability.
- **Obz Client**: Effortlessly log and monitor your models, inputs, outputs, and XAI explanations to the Obz AI server (cloud or on-prem) for comprehensive oversight and user-friendly visualization.

Obz AI is the all-in-one solution for anyone building, deploying, or monitoring computer vision models -- empowering explainable, reliable, and secure AI applications.
