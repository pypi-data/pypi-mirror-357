"""Helper functions for processing and manipulating response content and environment.

This module contains utility functions designed to assist in the handling and
modification of response content generated by the language model, as well as
functions for managing the execution environment. These functions are crucial
for maintaining the integrity and usability of the responses and ensuring proper
setup for subprocess execution across different operating systems.
"""

# Import standard library modules that are always available
import base64
import io
import json
import logging
import os
import platform
import re
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Tuple, Union

try:
    from PIL import Image
    from pillow_heif import register_heif_opener

    # Register HEIF opener with Pillow
    register_heif_opener()
    HEIF_SUPPORT = True
except ImportError:
    # PIL and pillow_heif are optional dependencies
    Image = None  # type: ignore
    HEIF_SUPPORT = False

from local_operator.types import ResponseJsonSchema

# Configure logging (optional, but helpful for debugging)
# Use sys.stdout to ensure logs appear if running as a GUI app without a console
# Note: BasicConfig should ideally be called only once at application entry point.
# If called elsewhere, it might not reconfigure. Consider moving this to main app setup.
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s", stream=sys.stdout
)
logger = logging.getLogger(__name__)


# --- Response Cleaning ---


def remove_think_tags(response_content: str) -> str:
    """
    Remove the content enclosed within <think> and </think> tags from the response content.

    Args:
        response_content (str): The original response content potentially containing <think> tags.

    Returns:
        str: The response content with <think> and </think> tags and their content removed.
    """
    # This function is designed to remove *all* think tags, not just initial ones.
    # For initial think tag extraction, a more specific function like
    # _extract_initial_think_tags should be used if only the first one is desired.
    # This version will remove all occurrences.

    # Regex to find <think>...</think> or <thinking>...</thinking>
    # It's non-greedy (.*?) to handle multiple tags correctly.
    # re.DOTALL allows '.' to match newlines, in case think tags span multiple lines.
    response_content = re.sub(r"<think>.*?</think>", "", response_content, flags=re.DOTALL)
    response_content = re.sub(r"<thinking>.*?</thinking>", "", response_content, flags=re.DOTALL)
    # Consolidate multiple spaces into one and strip leading/trailing whitespace
    response_content = re.sub(r" +", " ", response_content)
    return response_content.strip()


def clean_plain_text_response(response_content: str) -> str:
    """
    Clean plain text responses like reflection and planning by removing code blocks and
    standalone JSON.

    Args:
        response_content (str): The original plain text response potentially containing
                               code blocks or JSON objects.

    Returns:
        str: The cleaned response with code blocks and standalone JSON removed.
    """
    # Check if the entire content is a JSON object
    if response_content.strip().startswith("{") and response_content.strip().endswith("}"):
        try:
            json.loads(response_content.strip())
            # If it parses as valid JSON, remove it completely
            return ""
        except json.JSONDecodeError:
            # Not valid JSON, keep the content
            pass

    # Remove code blocks
    lines = response_content.split("\n")
    cleaned_lines = []
    in_code_block = False
    code_block_start_index = -1

    for i, line in enumerate(lines):
        if line.strip().startswith("```"):
            if not in_code_block:
                in_code_block = True
                code_block_start_index = i
            else:
                in_code_block = False
                # Add an empty line if there's content before and after the code block
                if code_block_start_index > 0 and i < len(lines) - 1:
                    cleaned_lines.append("")
            continue
        if not in_code_block:
            cleaned_lines.append(line.rstrip())

    cleaned_content = "\n".join(cleaned_lines)

    # Remove JSON objects embedded in the text
    pattern = r'\{(?:[^{}]|"[^"]*")*\}'
    cleaned_content = re.sub(pattern, "", cleaned_content)

    # Clean up any double spaces and preserve line breaks
    cleaned_content = re.sub(r" +", " ", cleaned_content)

    # Remove trailing spaces at the end of each line and leading spaces at the beginning
    # of each line
    cleaned_content = "\n".join(line.strip() for line in cleaned_content.split("\n"))

    return cleaned_content.strip()


def clean_json_response(response_content: str) -> str:
    """
    Clean JSON responses by extracting the JSON content from various formats.

    Args:
        response_content (str): The original JSON response potentially containing
                               code blocks, markdown formatting, or other text.

    Returns:
        str: The extracted JSON content as a string.
    """
    # Remove initial think tags before processing for JSON
    _, response_content_after_thinking = _extract_initial_think_tags(response_content)
    response_content = response_content_after_thinking.lstrip()

    # Special case for the format: ```json\n{...}\n```
    start = response_content.strip().startswith("```json")
    end = response_content.strip().endswith("```")
    if start and end:
        start_marker = "```json\n"
        if start_marker in response_content:
            start_idx = response_content.find(start_marker) + len(start_marker)
            end_idx = response_content.rfind("\n```")
            if end_idx != -1 and end_idx > start_idx:
                result = response_content[start_idx:end_idx].strip()
                if result.endswith("}"):
                    return result

    # Check if the entire content is already valid JSON
    try:
        if response_content.strip().startswith("{") and response_content.strip().endswith("}"):
            json.loads(response_content.strip())
            return response_content.strip()
    except json.JSONDecodeError:
        pass

    # Always search for JSON in code blocks regardless of leading text
    json_block_marker = "```json\n"
    if json_block_marker in response_content:
        start_index = response_content.find(json_block_marker) + len(json_block_marker)
        end_marker = "\n```"
        end_index = response_content.find(end_marker, start_index)

        if end_index != -1:
            json_content = response_content[start_index:end_index].strip()

            # Check for a complete JSON object
            if json_content.startswith("{") and json_content.endswith("}"):
                try:
                    json.loads(json_content)
                    return json_content
                except json.JSONDecodeError:
                    pass

            # If full content isn't parseable, try to extract the JSON object
            first_brace = json_content.find("{")
            last_brace = json_content.rfind("}")

            if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                extracted_json = json_content[first_brace : last_brace + 1]
                try:
                    json.loads(extracted_json)
                    return extracted_json
                except json.JSONDecodeError:
                    pass

    # Check for JSON code block format with triple backticks
    is_json_start = response_content.strip().startswith("```json")
    is_json_end = response_content.strip().endswith("```")
    if is_json_start and is_json_end:
        # Extract content between the first ```json and the last ```
        content = response_content.strip()
        start_index = content.find("```json") + len("```json")
        end_index = content.rfind("```")
        if start_index < end_index:
            extracted_content = content[start_index:end_index].strip()
            # Make sure we don't have trailing backticks in the extracted content
            if extracted_content.endswith("```"):
                extracted_content = extracted_content[:-3].strip()
            try:
                json.loads(extracted_content)
                return extracted_content
            except json.JSONDecodeError:
                pass

    # Check for JSON code block format with triple backticks
    json_block_patterns = ["```json\n", "```\n"]

    for pattern in json_block_patterns:
        if pattern in response_content and not is_marker_inside_json(response_content, pattern):
            start_index = response_content.find(pattern)
            content_after_marker = response_content[start_index + len(pattern) :]

            # Find the closing backticks that are not inside a JSON structure
            end_index = content_after_marker.find("```")  # Initial find

            while end_index != -1 and is_marker_inside_json(
                content_after_marker[: end_index + 3], "```"  # Check based on original slice
            ):
                # Search *after* the found marker in the original slice
                search_start = end_index + 3
                next_end = content_after_marker.find("```", search_start)
                if next_end == -1:
                    end_index = -1  # No more markers found
                    break
                end_index = next_end  # Update end_index to the new position

            if end_index != -1:
                extracted_content = content_after_marker[:end_index].strip()

                # Special handling for nested JSON with code blocks
                if "```json{" in extracted_content:
                    # Find the last complete JSON object
                    first_brace = extracted_content.find("{")
                    last_brace = extracted_content.rfind("}")

                    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                        json_content = extracted_content[first_brace : last_brace + 1].strip()
                        # Remove any trailing backticks that aren't part of the JSON string
                        if json_content.endswith("```"):
                            json_content = json_content[:-3].strip()
                        try:
                            json.loads(json_content)
                            return json_content
                        except json.JSONDecodeError:
                            pass

                # If the content has trailing backticks or newlines (followed by
                # backticks), clean them up
                if "\n```" in extracted_content:
                    extracted_content = extracted_content.split("\n```")[0].strip()
                elif extracted_content.endswith("```"):
                    extracted_content = extracted_content[:-3].strip()

                # Try to parse the entire extracted content first
                try:
                    json.loads(extracted_content)
                    return extracted_content
                except json.JSONDecodeError:
                    # If that fails, look for the last complete JSON object
                    first_brace = extracted_content.find("{")
                    last_brace = extracted_content.rfind("}")

                    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                        json_content = extracted_content[first_brace : last_brace + 1].strip()
                        # Remove any trailing backticks that aren't part of the JSON string
                        if json_content.endswith("```"):
                            json_content = json_content[:-3].strip()
                        try:
                            json.loads(json_content)
                            return json_content
                        except json.JSONDecodeError:
                            # If still not valid, return the extracted content as-is
                            pass

                # If we couldn't find valid JSON but have a clean content, return it
                return extracted_content

    # If no specific markers found, try to extract JSON object directly
    # Look for the first { and the last }
    first_brace = response_content.find("{")
    last_brace = response_content.rfind("}")

    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
        extracted_json = response_content[first_brace : last_brace + 1].strip()
        try:
            json.loads(extracted_json)
            # Return the validated JSON if parsing succeeds
            return extracted_json
        except json.JSONDecodeError:
            # If not valid JSON, continue to the final return
            pass

    # Special case for the test with leading text and json code block
    if "```json\n" in response_content and "\n```" in response_content:
        # Get content between ```json\n and \n```
        start_idx = response_content.find("```json\n") + len("```json\n")
        end_idx = response_content.find("\n```", start_idx)
        if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
            json_content = response_content[start_idx:end_idx].strip()
            if json_content.startswith("{") and json_content.endswith("}"):
                return json_content

    # If we couldn't extract valid JSON, return the original content
    return response_content.strip()


def process_json_response(response_str: str) -> ResponseJsonSchema:
    """Process and validate a JSON response string from the language model.

    Args:
        response_str (str): Raw response string from the model, which may be wrapped in
            markdown-style JSON code block delimiters (```json) or provided as a plain JSON object.

    Returns:
        ResponseJsonSchema: Validated response object containing the model's output.
            See ResponseJsonSchema class for the expected schema.

    Raises:
        ValidationError: If the JSON response does not match the expected schema.
        ValueError: If no valid JSON object can be extracted from the response.
    """
    response_content = clean_json_response(response_str)

    # Validate the JSON response
    response_json = ResponseJsonSchema.model_validate_json(response_content)

    return response_json


def is_marker_inside_json(text: str, marker: str) -> bool:
    """
    Check if a marker is inside a JSON structure by analyzing the string.

    Args:
        text (str): The text to analyze
        marker (str): The marker to check

    Returns:
        bool: True if the marker appears to be inside a JSON structure, False otherwise
    """
    marker_pos = text.find(marker)
    if marker_pos == -1:
        return False

    # Count opening and closing braces before the marker
    open_braces = text[:marker_pos].count("{")
    close_braces = text[:marker_pos].count("}")

    # If we have more opening braces than closing ones before the marker,
    # the marker is likely inside a JSON structure
    return open_braces > close_braces


def _extract_tag_content(xml_string: str, tag_name: str) -> Tuple[str, int]:
    """Extracts content from the first occurrence of a simple XML tag."""
    start_tag = f"<{tag_name}>"
    end_tag = f"</{tag_name}>"
    content = ""
    next_search_start_index = 0

    start_index = xml_string.find(start_tag)
    if start_index != -1:
        end_index = xml_string.find(end_tag, start_index + len(start_tag))
        if end_index != -1:
            content = xml_string[start_index + len(start_tag) : end_index].strip()
            next_search_start_index = end_index + len(end_tag)
        else:
            # Tag started but didn't end, search from after start_tag
            next_search_start_index = start_index + len(start_tag)
    else:
        # Tag not found, search from beginning
        next_search_start_index = 0

    return content, next_search_start_index


def parse_replacements(replacements_str: str) -> List[Dict[str, str]]:
    """
    Parses the content of a <replacements> tag in diff notation, supporting nested SEARCH blocks.

    Args:
        replacements_str (str): The string content inside the <replacements> tag.

    Returns:
        List[Dict[str, str]]: A list of dictionaries, each with 'find' and 'replace' keys.

    Raises:
        ValueError: If replacements_str is not a string.
    """
    if not replacements_str.strip():
        return []

    lines = replacements_str.strip().splitlines()
    parsed_replacements: List[Dict[str, str]] = []
    i = 0
    n = len(lines)

    while i < n:
        current_line = lines[i].strip()
        # Detect start of a replacement block marker, e.g. <<<<<<< SEARCH
        if current_line.startswith("<") and current_line.endswith("SEARCH"):
            block_start = i
            nesting = 1
            search_sep = None
            replace_end = None
            j = i + 1
            while j < n:
                ln = lines[j].strip()
                # Nested SEARCH block
                if ln.startswith("<") and ln.endswith("SEARCH"):
                    nesting += 1
                # Replacement block end marker
                elif ln.startswith(">") and ln.endswith("REPLACE"):
                    nesting -= 1
                    if nesting == 0:
                        replace_end = j
                        break
                # Separator between find and replace in top-level block
                elif nesting == 1 and search_sep is None and ln and ln.replace("=", "") == "":
                    search_sep = j
                j += 1
            # Only add well-formed blocks
            if search_sep is not None and replace_end is not None:
                find_lines = lines[block_start + 1 : search_sep]
                replace_lines = lines[search_sep + 1 : replace_end]
                find_content = "\n".join(find_lines).strip()
                replace_content = "\n".join(replace_lines).strip()
                parsed_replacements.append({"find": find_content, "replace": replace_content})
                i = replace_end + 1
            else:
                # Malformed block; skip start marker
                i += 1
        else:
            i += 1

    return parsed_replacements


def parse_agent_action_xml(xml_string: str) -> Dict[str, Any]:
    """
    Parses an XML-like string containing agent action details.

    Args:
        xml_string (str): The raw string response from the agent.

    Returns:
        Dict[str, Any]: A dictionary representing the parsed action.
                        Expected keys match ResponseJsonSchema.
    """
    parsed_data = {
        "action": "",
        "learnings": "",
        "response": "",
        "code": "",
        "content": "",
        "file_path": "",
        "replacements": [],
        "agent": "",
        "message": "",
        "mentioned_files": [],
        "thinking": "",  # Added thinking field
    }

    # Extract initial thinking tags first
    thinking_content, text_after_thinking = _extract_initial_think_tags(xml_string)
    if thinking_content:
        parsed_data["thinking"] = thinking_content

    raw_input_string = text_after_thinking.lstrip()  # Process the rest of the string
    xml_content_to_parse = raw_input_string.strip()

    text_before_outer_fence = ""
    text_after_outer_fence = ""
    is_explicitly_xml_fenced = False

    # Define potential fences
    xml_specific_fence_start = "```xml\n"
    generic_fence_start_options = ["```\n", "```"]  # ``` at very start of string
    # End fences usually are preceded by a newline, or are at the very end
    fence_end_options = ["\n```", "```"]

    # Initialize variables to avoid "possibly unbound" errors
    idx_generic_fence_start = -1

    # 1. Check for ```xml\n fence
    idx_xml_fence_start = raw_input_string.find(xml_specific_fence_start)
    if idx_xml_fence_start != -1:
        is_explicitly_xml_fenced = True
        text_before_outer_fence = raw_input_string[:idx_xml_fence_start].strip()

        search_from = idx_xml_fence_start + len(xml_specific_fence_start)
        # Find the corresponding \n```
        idx_xml_fence_end = raw_input_string.find(fence_end_options[0], search_from)  # prefer \n```
        if idx_xml_fence_end != -1:
            xml_content_to_parse = raw_input_string[search_from:idx_xml_fence_end].strip()
            text_after_outer_fence = raw_input_string[
                idx_xml_fence_end + len(fence_end_options[0]) :
            ].strip()
        else:  # No \n```, check for ``` at the very end of the string
            if raw_input_string.endswith(fence_end_options[1]):
                temp_content = raw_input_string[search_from:]
                xml_content_to_parse = temp_content[: -len(fence_end_options[1])].strip()
                # text_after_outer_fence remains ""
            else:  # Start fence but no clear end fence, assume rest is content
                xml_content_to_parse = raw_input_string[search_from:].strip()
    else:
        # 2. Check for generic ``` fence if no ```xml fence
        # Try matching generic_fence_start_options
        idx_generic_fence_start = -1
        used_generic_start_marker = ""

        for marker in generic_fence_start_options:
            if raw_input_string.strip().startswith(marker):  # Check strip() for "```" at start
                # find original index without strip
                idx_generic_fence_start = raw_input_string.find(marker)
                used_generic_start_marker = marker
                break

        if idx_generic_fence_start != -1:
            text_before_outer_fence = raw_input_string[
                :idx_generic_fence_start
            ].strip()  # Should be empty if startswith
            search_from = idx_generic_fence_start + len(used_generic_start_marker)

            idx_generic_fence_end = -1
            used_generic_end_marker = ""

            # Find corresponding end fence (prefer \n```)
            if raw_input_string.find(fence_end_options[0], search_from) != -1:
                idx_generic_fence_end = raw_input_string.find(fence_end_options[0], search_from)
                used_generic_end_marker = fence_end_options[0]
            elif raw_input_string.endswith(fence_end_options[1]):  # Check ``` at very end
                # Ensure this "```" is after the start fence
                temp_idx = raw_input_string.rfind(fence_end_options[1])
                if temp_idx >= search_from:  # Check if this rfind is actually the end
                    idx_generic_fence_end = temp_idx
                    used_generic_end_marker = fence_end_options[1]

            if idx_generic_fence_end != -1:
                xml_content_to_parse = raw_input_string[search_from:idx_generic_fence_end].strip()
                text_after_outer_fence = raw_input_string[
                    idx_generic_fence_end + len(used_generic_end_marker) :
                ].strip()
            else:  # Start fence but no clear end fence
                xml_content_to_parse = raw_input_string[search_from:].strip()

    # --- Extract all tags from xml_content_to_parse ---
    parsed_data["action"], _ = _extract_tag_content(xml_content_to_parse, "action")
    parsed_data["learnings"], _ = _extract_tag_content(xml_content_to_parse, "learnings")
    internal_response_content, _ = _extract_tag_content(xml_content_to_parse, "response")
    parsed_data["code"], _ = _extract_tag_content(xml_content_to_parse, "code")
    parsed_data["content"], _ = _extract_tag_content(xml_content_to_parse, "content")
    parsed_data["file_path"], _ = _extract_tag_content(xml_content_to_parse, "file_path")
    parsed_data["agent"], _ = _extract_tag_content(xml_content_to_parse, "agent")
    parsed_data["message"], _ = _extract_tag_content(xml_content_to_parse, "message")

    replacements_str, _ = _extract_tag_content(xml_content_to_parse, "replacements")
    if replacements_str:
        parsed_data["replacements"] = parse_replacements(replacements_str)

    mentioned_files_str, _ = _extract_tag_content(xml_content_to_parse, "mentioned_files")
    if mentioned_files_str:
        parsed_data["mentioned_files"] = [
            line.strip() for line in mentioned_files_str.split("\n") if line.strip()
        ]

    if is_explicitly_xml_fenced:
        final_response_parts = []
        if text_before_outer_fence:
            final_response_parts.append(text_before_outer_fence)
        if text_after_outer_fence:
            final_response_parts.append(text_after_outer_fence)
        parsed_data["response"] = " ".join(final_response_parts).strip()
    else:
        if internal_response_content:
            parsed_data["response"] = internal_response_content
        else:

            outer_parts = []
            if idx_generic_fence_start != -1:  # Was generic fenced
                if text_before_outer_fence:
                    outer_parts.append(text_before_outer_fence)
                if text_after_outer_fence:
                    outer_parts.append(text_after_outer_fence)
            else:
                first_tag_s = xml_content_to_parse.find("<")
                last_tag_e = xml_content_to_parse.rfind(">")
                if first_tag_s != -1 and last_tag_e != -1 and last_tag_e > first_tag_s:
                    pre = xml_content_to_parse[:first_tag_s].strip()
                    post = xml_content_to_parse[last_tag_e + 1 :].strip()
                    if pre:
                        outer_parts.append(pre)
                    if post:
                        outer_parts.append(post)
                elif first_tag_s == -1:  # No tags at all in xml_content_to_parse
                    outer_parts.append(xml_content_to_parse)

            parsed_data["response"] = " ".join(outer_parts).strip()

    return parsed_data


def _extract_initial_think_tags(text: str) -> Tuple[str, str]:
    """
    Extracts content from the first <think> or <thinking> tag at the beginning of the text.

    Args:
        text (str): The input text.

    Returns:
        Tuple[str, str]: (thinking_content, remaining_text)
                         thinking_content is the extracted content from the think tag.
                         remaining_text is the text after the think tag.
                         If no think tag is found at the beginning, thinking_content is ""
                         and remaining_text is the original text.
    """
    think_tags_map = {
        "<think>": "</think>",
        "<thinking>": "</thinking>",
    }

    stripped_text = text.lstrip()  # Handle leading whitespace

    for open_tag, close_tag in think_tags_map.items():
        if stripped_text.startswith(open_tag):
            # Find the corresponding closing tag, searching after the open tag
            # This ensures that if open_tag and close_tag are identical
            # (e.g. for empty tags like <think></think>)
            # we correctly identify the closing tag.
            end_tag_idx_in_stripped = stripped_text.find(close_tag, len(open_tag))

            if end_tag_idx_in_stripped != -1:  # Closing tag found
                # Content is between open_tag and end_tag_idx_in_stripped
                thinking_content = stripped_text[len(open_tag) : end_tag_idx_in_stripped].strip()

                # Calculate where the remaining text starts in the *original* text
                # Find the start of the open_tag in the original text
                original_open_tag_start_idx = text.find(open_tag)
                if original_open_tag_start_idx != -1:
                    # Find the end of the close_tag in the original text,
                    # searching after the open_tag
                    original_close_tag_end_idx = text.find(
                        close_tag, original_open_tag_start_idx + len(open_tag)
                    )
                    if original_close_tag_end_idx != -1:
                        remaining_text_start_pos = original_close_tag_end_idx + len(close_tag)
                        return thinking_content, text[remaining_text_start_pos:]

    return "", text  # No initial think tag found or tag was malformed


# --- HEIC/HEIF Conversion Helpers ---


def convert_heic_to_png_data_url(file_path: Union[str, Path]) -> Tuple[str, str]:
    """Convert HEIC/HEIF file to PNG format in memory and return as data URL.

    Args:
        file_path: Path to the HEIC/HEIF file

    Returns:
        Tuple[str, str]: (data_url, mime_type) where data_url is the PNG data URL
        and mime_type is "image/png"

    Raises:
        Exception: If HEIF support is not available or conversion fails
    """
    if not HEIF_SUPPORT or Image is None:
        raise Exception("HEIF support not available. Please install pillow-heif.")

    try:
        # Open and convert HEIC/HEIF to PNG in memory
        with Image.open(file_path) as img:
            # Convert to RGB if necessary (HEIF can have different color modes)
            if img.mode != "RGB":
                img = img.convert("RGB")

            # Save as PNG to memory buffer
            png_buffer = io.BytesIO()
            img.save(png_buffer, format="PNG")
            png_buffer.seek(0)

            # Encode to base64
            png_data = base64.b64encode(png_buffer.getvalue()).decode("utf-8")
            data_url = f"data:image/png;base64,{png_data}"

            return data_url, "image/png"

    except Exception as e:
        raise Exception(f"Failed to convert HEIC/HEIF file to PNG: {str(e)}")


def convert_heic_to_png_file(heic_path: Union[str, Path]) -> Path:
    """Convert a HEIC/HEIF file to PNG format and save to a temporary file.

    Args:
        heic_path: Path to the HEIC/HEIF file

    Returns:
        Path: Path to the converted PNG file in a temporary directory

    Raises:
        Exception: If conversion fails or HEIF support is not available
    """
    if not HEIF_SUPPORT or Image is None:
        raise Exception("HEIF support not available. Please install pillow-heif.")

    heic_path = Path(heic_path)

    try:
        # Open the HEIC/HEIF file
        with Image.open(heic_path) as img:
            # Convert to RGB if necessary (HEIC can have different color modes)
            if img.mode != "RGB":
                img = img.convert("RGB")

            # Create a temporary file for the PNG
            temp_dir = tempfile.gettempdir()
            temp_filename = f"converted_{heic_path.stem}.png"
            temp_path = Path(temp_dir) / temp_filename

            # Save as PNG
            img.save(temp_path, "PNG", optimize=True)

            return temp_path

    except Exception as e:
        logger.exception(f"Failed to convert HEIC/HEIF file {heic_path}: {e}")
        raise Exception(f"Failed to convert HEIC/HEIF file: {str(e)}")


# --- Environment Setup ---


def get_windows_registry_path() -> str | None:
    """
    Retrieves the effective PATH from the Windows Registry (User and System).
    Combines User and System PATHs, prioritizing User entries.

    Returns:
        str | None: The combined PATH string or None if an error occurs or not on Windows.
    """
    if platform.system() != "Windows":
        logger.debug("Not on Windows, skipping registry PATH retrieval.")
        return None

    try:
        # winreg is only available on Windows
        import winreg

        user_path = ""
        system_path = ""

        # Read User PATH from HKEY_CURRENT_USER\Environment
        try:
            # Open the key for reading
            with winreg.OpenKey(  # type: ignore
                winreg.HKEY_CURRENT_USER, "Environment", 0, winreg.KEY_READ  # type: ignore
            ) as user_key:
                # Query the 'Path' value
                user_path, _ = winreg.QueryValueEx(user_key, "Path")  # type: ignore
                logger.info(f"Retrieved User PATH from registry: {user_path}")
        except FileNotFoundError:
            # It's normal for the Path value or even the Environment key to not exist for a user
            logger.warning("User PATH not found in registry (this might be normal).")
            user_path = ""
        except Exception as e:
            logger.error(f"Error reading User PATH from registry: {e}")
            return None  # Return None on error

        # Read System PATH from HKEY_LOCAL_MACHINE\...
        try:
            # Open the key for reading
            with winreg.OpenKey(  # type: ignore
                winreg.HKEY_LOCAL_MACHINE,  # type: ignore
                r"SYSTEM\CurrentControlSet\Control\Session Manager\Environment",
                0,
                winreg.KEY_READ,  # type: ignore
            ) as system_key:
                # Query the 'Path' value
                system_path, _ = winreg.QueryValueEx(system_key, "Path")  # type: ignore
                logger.info(f"Retrieved System PATH from registry: {system_path}")
        except FileNotFoundError:
            logger.warning("System PATH not found in registry (this is unusual).")
            system_path = ""
        except Exception as e:
            logger.error(f"Error reading System PATH from registry: {e}")
            return None  # Return None on error

        # Combine User and System PATHs, prioritizing User entries
        # Use os.pathsep for platform compatibility (';' on Windows, ':' on POSIX)
        combined_paths = []
        if user_path:
            combined_paths.extend(user_path.split(os.pathsep))
        if system_path:
            combined_paths.extend(system_path.split(os.pathsep))

        # Remove duplicates while preserving order (simple approach)
        seen = set()
        effective_path_list = []
        for path_entry in combined_paths:
            # Normalize path separators for comparison if needed, though
            # usually not critical for set membership
            # Ensure path_entry is not empty before adding
            if path_entry and path_entry not in seen:
                effective_path_list.append(path_entry)
                seen.add(path_entry)

        effective_path = os.pathsep.join(effective_path_list)
        logger.info(
            "Effective PATH constructed from Windows registry: %s", effective_path
        )  # Use % formatting to help with line length
        return effective_path

    except ImportError:
        # This error occurs if trying to import winreg on non-Windows OS
        logger.error("The 'winreg' module is not available on this platform.")
        return None
    except Exception as e:
        # Catch any other unexpected errors during registry access
        logger.error(f"An unexpected error occurred while getting Windows registry PATH: {e}")
        return None


def get_posix_shell_path() -> str | None:
    """
    Retrieves the user's PATH environment variable from their default login shell on macOS/Linux.
    On Linux, also explicitly checks for and adds ~/.local/bin if it exists and is not in PATH.

    Returns:
        str | None: The PATH string from the login shell, or None if an error occurs.
    """
    if platform.system() not in ["Darwin", "Linux"]:
        logger.debug("Not on POSIX system, skipping shell PATH retrieval.")
        return None

    shell_path = None
    command = None
    try:
        # Determine the default shell, preferring SHELL env var if set
        # Default to /bin/zsh on Darwin (macOS), /bin/bash otherwise
        default_shell = "/bin/bash"
        if platform.system() == "Darwin":
            default_shell = "/bin/zsh"
        shell_path = os.environ.get("SHELL", default_shell)

        logger.debug(f"Using shell: {shell_path}")

        # Construct the command to echo PATH from a login shell
        # Use list format for subprocess.run when shell=False is preferred,
        # but here shell=True is needed for the login shell behavior (-l).
        # Ensure shell_path is quoted if it contains spaces (though unlikely for standard shells)
        command = (
            f"'{shell_path}' -l -c 'echo \"$PATH\"'"  # Use double quotes inside for robustness
        )

        # Run the command. shell=True is necessary here for the '-l' flag to work correctly
        # by invoking the shell itself to interpret the command string.
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            check=True,
            shell=True,
            executable=shell_path,
        )

        full_path = result.stdout.strip()
        if full_path:
            logger.debug(f"Successfully retrieved PATH from login shell: {full_path}")
        else:
            # If the shell command succeeded but returned empty, log a warning
            # and use current PATH as fallback
            logger.warning(
                "Login shell command executed but returned an empty PATH. "
                "Falling back to current os.environ['PATH']."
            )
            full_path = os.environ.get("PATH", "")

        # On Linux, explicitly add ~/.local/bin if it exists and is not already in PATH
        if platform.system() == "Linux":
            local_bin = os.path.expanduser("~/.local/bin")
            if os.path.isdir(local_bin):
                # Check if local_bin is already effectively in the path
                path_list = full_path.split(os.pathsep)
                if local_bin not in path_list:
                    # Prepend ~/.local/bin for higher priority
                    full_path = local_bin + os.pathsep + full_path
                    logger.debug(f"Prepended {local_bin} to PATH.")

        return full_path

    except FileNotFoundError:
        # This occurs if the specified shell_path does not exist
        logger.error(
            "Shell executable not found at '%s'. Cannot get PATH from login shell.",
            shell_path if shell_path is not None else "<unknown>",
        )
        return None
    except subprocess.CalledProcessError as e:
        # This occurs if the shell command returns a non-zero exit code
        logger.error(
            "Failed to get PATH from login shell. Command "
            f"'{command if command is not None else '<unknown>'}' "
            f"failed with error code {e.returncode}."
        )
        logger.error(f"Stderr: {e.stderr.strip()}")
        return None  # Indicate failure
    except Exception as e:
        # Catch any other unexpected errors
        logger.error(f"An unexpected error occurred while getting POSIX shell PATH: {e}")
        return None


def setup_cross_platform_environment():
    """
    Updates the current process's PATH environment variable based on the OS.
    Call this function early in your application's startup.
    """
    logger.debug(f"Setting up subprocess environment for OS: {platform.system()}...")

    original_path = os.environ.get("PATH", "")
    logger.debug(f"Initial PATH: {original_path}")

    user_effective_path_str = None

    # Determine the OS and call the appropriate function
    os_name = platform.system()
    if os_name == "Windows":
        user_effective_path_str = get_windows_registry_path()
    elif os_name in ["Darwin", "Linux"]:
        user_effective_path_str = get_posix_shell_path()
    else:
        logger.warning(f"Unsupported OS: {os_name}. Cannot automatically retrieve effective PATH.")
        return

    # Ensure user_effective_path_str is not None before proceeding
    if user_effective_path_str is None:
        user_effective_path_str = original_path  # Fallback to original if retrieval failed

    # Convert string path to list for easier manipulation
    user_effective_path_list = user_effective_path_str.split(os.pathsep)
    # Remove empty strings that might result from split
    user_effective_path_list = [p for p in user_effective_path_list if p]

    # Define potential Electron AppData "Local Operator/bin" subdirectories
    electron_app_data_bin_dirs = []
    if os_name == "Windows":
        electron_app_data_bin_dirs = [
            os.path.join(os.path.expanduser("~\\AppData\\Local"), "Local Operator", "bin"),
            os.path.join(os.path.expanduser("~\\AppData\\Roaming"), "Local Operator", "bin"),
        ]
    elif os_name == "Darwin":  # macOS
        electron_app_data_bin_dirs = [
            os.path.join(
                os.path.expanduser("~/Library/Application Support"), "Local Operator", "bin"
            )
        ]
    elif os_name == "Linux":
        electron_app_data_bin_dirs = [
            os.path.join(os.path.expanduser("~/.config"), "Local Operator", "bin")
        ]

    # Add Electron AppData "Local Operator/bin" directories to the
    # path if they exist and are not already present
    added_electron_bin_paths = False
    for electron_bin_dir in electron_app_data_bin_dirs:
        if os.path.isdir(electron_bin_dir):
            # Normalize paths for comparison to avoid duplicates due to case or slashes
            normalized_electron_bin_dir = os.path.normcase(os.path.normpath(electron_bin_dir))
            path_exists = any(
                os.path.normcase(os.path.normpath(p)) == normalized_electron_bin_dir
                for p in user_effective_path_list
            )
            if not path_exists:
                logger.debug(
                    f"Prepending Electron AppData bin directory to PATH: {electron_bin_dir}"
                )
                user_effective_path_list.insert(0, electron_bin_dir)  # Prepend for priority
                added_electron_bin_paths = True
        else:
            logger.debug(
                f"Electron AppData bin directory not found or not a directory: {electron_bin_dir}"
            )

    # Reconstruct the path string
    if added_electron_bin_paths:
        user_effective_path_str = os.pathsep.join(user_effective_path_list)

    # Update os.environ['PATH'] if a valid, different path was retrieved or modified
    if user_effective_path_str and user_effective_path_str != original_path:
        logger.debug(f"Updating os.environ['PATH'] to: {user_effective_path_str}")
        os.environ["PATH"] = user_effective_path_str
    elif not user_effective_path_str and original_path:  # Path became empty, revert
        logger.warning("Effective PATH became empty, reverting to original PATH.")
        os.environ["PATH"] = original_path
    elif user_effective_path_str == original_path:
        logger.debug("Effective PATH is the same as the initial PATH. No update needed.")
    else:  # user_effective_path_str is None or empty, and original_path was also empty/None
        logger.warning(
            "Could not retrieve or construct a valid effective PATH. "
            "Subprocess calls will use the initial (possibly empty) PATH."
        )

    # Optional: Verification step (example)
    # Try to find a common command expected to be in the user's path
    test_command = None
    if os_name == "Darwin":
        test_command = "brew"
    elif os_name == "Linux":
        test_command = "ls"  # Use a very common command
    elif os_name == "Windows":
        test_command = "choco"

    if test_command:
        which_cmd = None
        try:
            which_cmd = "where" if os_name == "Windows" else "which"
            logger.debug(
                f"Verifying PATH: Attempting to find '{test_command}' using '{which_cmd}'..."
            )
            # Use check=False as the command might legitimately not be installed
            result = subprocess.run(
                [which_cmd, test_command], capture_output=True, text=True, check=False
            )
            if result.returncode == 0 and result.stdout.strip():
                # On Windows, 'where' can return multiple paths, just log the first line
                found_path = result.stdout.strip().splitlines()[0]
                logger.debug(f"Verification successful: Found '{test_command}' at: {found_path}")
            else:
                logger.warning(
                    f"Verification: Could not find '{test_command}' using '{which_cmd}'. "
                    "PATH might be incomplete or command not installed."
                )
                if result.stderr:
                    logger.warning(f"'{which_cmd}' stderr: {result.stderr.strip()}")
        except FileNotFoundError:
            # This happens if 'which' or 'where' itself is not found (highly unlikely)
            logger.warning(
                f"'{which_cmd if which_cmd is not None else '<unknown>'}' command not found. "
                "Cannot verify test command location."
            )
        except Exception as e:
            logger.error(f"Error during verification step trying to find '{test_command}': {e}")
