{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Provider Agent Example\n",
    "\n",
    "Run an agent server that dispatches to multiple providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubiya_workflow_sdk.server import WorkflowServer\n",
    "from kubiya_workflow_sdk import workflow\n",
    "import os\n",
    "\n",
    "# Example of multi-provider configuration\n",
    "print(\"ðŸš€ Multi-Provider Agent Server Example\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# In production, you would configure multiple providers:\n",
    "providers_config = {\n",
    "    \"openai\": {\n",
    "        \"type\": \"adk\",\n",
    "        \"model_provider\": \"openai\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\", \"sk-...\"),\n",
    "        \"model\": \"gpt-4\"\n",
    "    },\n",
    "    \"anthropic\": {\n",
    "        \"type\": \"adk\", \n",
    "        \"model_provider\": \"anthropic\",\n",
    "        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\", \"sk-...\"),\n",
    "        \"model\": \"claude-3-opus\"\n",
    "    },\n",
    "    \"local\": {\n",
    "        \"type\": \"local\",\n",
    "        \"description\": \"Local execution without AI\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Available providers:\")\n",
    "for name, config in providers_config.items():\n",
    "    print(f\"  - {name}: {config['type']} ({config.get('model_provider', 'N/A')})\")\n",
    "\n",
    "# Example workflows that would use different providers\n",
    "ai_workflow = (\n",
    "    workflow(\"ai-analysis\")\n",
    "    .description(\"Use AI to analyze logs\")\n",
    "    .params(log_file=\"app.log\")\n",
    "    .step(\"analyze\", \"cat ${log_file} | head -100\")\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Multi-provider configuration example complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of provider routing\n",
    "print(\"\\nðŸ”€ Provider Routing Example:\")\n",
    "print(\"\"\"\n",
    "Different endpoints would route to different providers:\n",
    "\n",
    "POST /providers/openai/generate\n",
    "  â†’ Uses OpenAI GPT-4 for workflow generation\n",
    "\n",
    "POST /providers/anthropic/generate  \n",
    "  â†’ Uses Claude for workflow generation\n",
    "\n",
    "POST /providers/local/execute\n",
    "  â†’ Direct workflow execution without AI\n",
    "\n",
    "Example request:\n",
    "curl -X POST http://localhost:8080/providers/openai/generate \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{\n",
    "    \"prompt\": \"Create a workflow to monitor system health\",\n",
    "    \"context\": {\"servers\": [\"web1\", \"web2\", \"db1\"]}\n",
    "  }'\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Benefits of multi-provider setup:\")\n",
    "print(\"- Failover: Switch providers if one is down\")\n",
    "print(\"- Cost optimization: Use cheaper providers for simple tasks\")\n",
    "print(\"- Specialization: Use best provider for specific tasks\")\n",
    "print(\"- Testing: Compare outputs across providers\")\n",
    "\n",
    "print(\"\\nâœ… Multi-provider agent example complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
