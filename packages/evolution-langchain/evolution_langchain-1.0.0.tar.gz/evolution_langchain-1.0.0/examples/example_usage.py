#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è EvolutionInference LLM
"""

import os

from evolution_langchain import EvolutionInference


def main():
    print("üöÄ –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è EvolutionInference LLM")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    has_credentials = all(
        [
            os.getenv("EVOLUTION_KEY_ID")
            and os.getenv("EVOLUTION_KEY_ID") != "your_key_id_here",
            os.getenv("EVOLUTION_SECRET")
            and os.getenv("EVOLUTION_SECRET") != "your_secret_here",
            os.getenv("EVOLUTION_BASE_URL")
            and os.getenv("EVOLUTION_BASE_URL")
            != "https://your-endpoint.cloud.ru/v1",
        ]
    )

    if not has_credentials:
        print("‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–µ–º–æ-–∑–Ω–∞—á–µ–Ω–∏—è")
        print("üí° –ü—Ä–∏–º–µ—Ä –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ")
        print()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    llm = EvolutionInference(
        model="your-model-name",  # –£–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        key_id=os.getenv("EVOLUTION_KEY_ID", "your-key-id"),
        secret=os.getenv("EVOLUTION_SECRET", "your-secret"),
        base_url=os.getenv(
            "EVOLUTION_BASE_URL", "https://your-api-endpoint.com/v1"
        ),
        max_tokens=1000,
        temperature=0.7,
        top_p=0.9,
    )

    print("‚úÖ LLM —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    print(f"üìù –ú–æ–¥–µ–ª—å: {llm.model}")
    print(f"üåê Base URL: {llm.base_url}")
    print(f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {llm.temperature}")
    print(f"üéØ Max tokens: {llm.max_tokens}")
    print()

    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
    print("üí¨ –ü—Ä–∏–º–µ—Ä –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:")
    prompt = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
    print(f"–ó–∞–ø—Ä–æ—Å: {prompt}")

    if has_credentials:
        try:
            response = llm.invoke(prompt)
            print("–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:", response)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API")
    else:
        print("‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω (–¥–µ–º–æ-—Ä–µ–∂–∏–º)")
        print("üí° –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    print()

    # –ü–∞–∫–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    print("üì¶ –ü—Ä–∏–º–µ—Ä –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:")
    prompts = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        "–û–±—ä—è—Å–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π",
        "–ö–∞–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —É Python –¥–ª—è ML?",
    ]

    for i, prompt in enumerate(prompts, 1):
        print(f"{i}. {prompt}")

    if has_credentials:
        try:
            print("\n–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...")
            responses = llm.generate(prompts)
            for i, response in enumerate(responses.generations):
                print(f"–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å {i + 1}: {response[0].text}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    else:
        print("\n‚ö†Ô∏è –ü–∞–∫–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω (–¥–µ–º–æ-—Ä–µ–∂–∏–º)")
        print("üí° –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")

    print("\nüéâ –ü—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("üìö –°–º. –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")


if __name__ == "__main__":
    main()
