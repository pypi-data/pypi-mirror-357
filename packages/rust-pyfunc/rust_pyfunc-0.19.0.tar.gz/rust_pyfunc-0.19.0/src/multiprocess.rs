use pyo3::prelude::*;
use pyo3::types::{PyList, PyDict};
use std::process::{Command, Stdio, Child};
use std::io::{Write, BufRead, BufReader};
use std::sync::mpsc::{channel,Receiver};
use std::thread;
use std::time::{SystemTime, UNIX_EPOCH, Instant};
use serde::{Serialize, Deserialize};
use crate::backup::BackupManager;

/// ä»»åŠ¡æ•°æ®ç»“æ„
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Task {
    pub date: i32,
    pub code: String,
}

/// å‘é€ç»™å·¥ä½œè¿›ç¨‹çš„æŒ‡ä»¤
#[derive(Serialize, Deserialize, Debug)]
pub enum WorkerCommand {
    Task(Task),
    GoClass(String),
    FunctionCode(String),
    Execute {},
    Ping {},
    Exit {},
}

/// å·¥ä½œè¿›ç¨‹è¯·æ±‚
#[derive(Serialize, Deserialize, Debug)]
pub struct WorkerRequest {
    pub tasks: Vec<Task>,
    pub function_code: String,
    pub go_class_serialized: Option<String>,
}

/// å·¥ä½œè¿›ç¨‹å“åº”
#[derive(Serialize, Deserialize, Debug)]
pub struct WorkerResponse {
    pub results: Vec<Vec<f64>>,
    pub errors: Vec<String>,
    pub task_count: usize,
}

/// Ping å“åº”
#[derive(Serialize, Deserialize, Debug)]
pub struct PingResponse {
    pub status: String,
}

/// è®¡ç®—ç»“æœ
#[derive(Clone, Debug, serde::Serialize, serde::Deserialize)]
pub struct ProcessResult {
    pub date: i32,
    pub code: String,
    pub timestamp: i64,
    pub facs: Vec<f64>,
}

/// è¿”å›ç»“æœï¼ˆä¸å«timestampï¼‰
#[derive(Clone, Debug)]
pub struct ReturnResult {
    pub date: i32,
    pub code: String,
    pub facs: Vec<f64>,
}

impl ProcessResult {
    pub fn to_return_result(&self) -> ReturnResult {
        ReturnResult {
            date: self.date,
            code: self.code.clone(),
            facs: self.facs.clone(),
        }
    }
}

/// å·¥ä½œè¿›ç¨‹ç®¡ç†å™¨
pub struct WorkerProcess {
    child: Child,
    stdin: std::process::ChildStdin,
    stdout_reader: BufReader<std::process::ChildStdout>,
    id: usize,
}

impl WorkerProcess {
    /// åˆ›å»ºæ–°çš„å·¥ä½œè¿›ç¨‹
    pub fn new(id: usize, python_path: &str) -> PyResult<Self> {
        // è·å–å·¥ä½œè„šæœ¬è·¯å¾„ - ä½¿ç”¨ç»å¯¹è·¯å¾„é¿å…å½“å‰ç›®å½•é—®é¢˜
        // let script_path = std::path::PathBuf::from("/home/chenzongwei/rust_pyfunc/python/worker_process.py");
        let mut script_path = std::path::PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        script_path.push("python");
        script_path.push("worker_process.py");
        println!("script_path: {}", script_path.display());
        
        // æ£€æŸ¥è„šæœ¬æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !script_path.exists() {
            return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
                format!("å·¥ä½œè¿›ç¨‹è„šæœ¬ä¸å­˜åœ¨: {:?}", script_path)
            ));
        }
            
        // åˆ›å»ºPythonå·¥ä½œè¿›ç¨‹
        let mut child = Command::new(python_path)
            .arg(script_path)
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .spawn()
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                format!("å¯åŠ¨å·¥ä½œè¿›ç¨‹å¤±è´¥: {}", e)
            ))?;

        let stdin = child.stdin.take().ok_or_else(|| {
            PyErr::new::<pyo3::exceptions::PyRuntimeError, _>("æ— æ³•è·å–è¿›ç¨‹stdin")
        })?;

        let stdout = child.stdout.take().ok_or_else(|| {
            PyErr::new::<pyo3::exceptions::PyRuntimeError, _>("æ— æ³•è·å–è¿›ç¨‹stdout")
        })?;

        let stdout_reader = BufReader::new(stdout);

        let worker = WorkerProcess {
            child,
            stdin,
            stdout_reader,
            id,
        };

        // ç»™å·¥ä½œè¿›ç¨‹ä¸€äº›æ—¶é—´å¯åŠ¨
        std::thread::sleep(std::time::Duration::from_millis(100));

        Ok(worker)
    }

    /// å‘å·¥ä½œè¿›ç¨‹å‘é€æŒ‡ä»¤
    pub fn send_command(&mut self, command: &WorkerCommand) -> PyResult<()> {
        match self.child.try_wait() {
            Ok(Some(status)) => {
                return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                    format!("å·¥ä½œè¿›ç¨‹å·²é€€å‡ºï¼ŒçŠ¶æ€ç : {:?}", status)
                ));
            }
            Ok(None) => {
                // è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œç»§ç»­
            }
            Err(e) => {
                return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                    format!("æ£€æŸ¥è¿›ç¨‹çŠ¶æ€å¤±è´¥: {}", e)
                ));
            }
        }

        let json_command = serde_json::to_string(command)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                format!("åºåˆ—åŒ–æŒ‡ä»¤å¤±è´¥: {}", e)
            ))?;

        if let Err(e) = writeln!(self.stdin, "{}", json_command) {
            // å°è¯•è·å–è¿›ç¨‹çš„stderrä¿¡æ¯
            let mut stderr_output = String::new();
            if let Some(ref mut stderr) = self.child.stderr.as_mut() {
                use std::io::Read;
                let _ = stderr.read_to_string(&mut stderr_output);
            }
            
            return Err(PyErr::new::<pyo3::exceptions::PyIOError, _>(
                format!("å‘å·¥ä½œè¿›ç¨‹ {} å†™å…¥å¤±è´¥: {}. Stderr: {}", self.id, e, stderr_output)
            ));
        }
        Ok(())
    }

    /// ä»å·¥ä½œè¿›ç¨‹æ¥æ”¶é€šç”¨å“åº”
    fn receive_response<T: for<'de> serde::Deserialize<'de>>(&mut self) -> PyResult<T> {
        let mut line = String::new();
        // è®¾ç½®è¯»å–è¶…æ—¶
        // self.stdout_reader.get_mut().set_read_timeout(Some(std::time::Duration::from_secs(60)))
        //     .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("è®¾ç½®è¯»å–è¶…æ—¶å¤±è´¥: {}", e)))?;

        self.stdout_reader.read_line(&mut line)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(
                format!("ä»å·¥ä½œè¿›ç¨‹ {} è¯»å–å¤±è´¥: {}", self.id, e)
            ))?;
        
        if line.is_empty() {
            return Err(PyErr::new::<pyo3::exceptions::PyIOError, _>(
                format!("ä»å·¥ä½œè¿›ç¨‹ {} è¯»å–åˆ°ç©ºè¡Œï¼Œå¯èƒ½å·²é€€å‡º", self.id)
            ));
        }
        
        serde_json::from_str(&line.trim())
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                format!("ååºåˆ—åŒ–æ¥è‡ªå·¥ä½œè¿›ç¨‹ {} çš„å“åº”å¤±è´¥: {}. å“åº”å†…å®¹: '{}'", self.id, e, line.trim())
            ))
    }

    /// ä»å·¥ä½œè¿›ç¨‹æ¥æ”¶ç»“æœ
    pub fn receive_result(&mut self) -> PyResult<WorkerResponse> {
        self.receive_response::<WorkerResponse>()
    }

    /// pingå·¥ä½œè¿›ç¨‹
    pub fn ping(&mut self) -> PyResult<()> {
        self.send_command(&WorkerCommand::Ping {})?;
        let response: PingResponse = self.receive_response::<PingResponse>()?;
        if response.status == "pong" {
            Ok(())
        } else {
            Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                "Ping å¤±è´¥ï¼Œæ”¶åˆ°æœªçŸ¥å“åº”"
            ))
        }
    }

    /// ç»ˆæ­¢å·¥ä½œè¿›ç¨‹
    pub fn terminate(&mut self) -> PyResult<()> {
        // é¦–å…ˆå°è¯•ä¼˜é›…å…³é—­ï¼Œå¿½ç•¥å‘é€é”™è¯¯ï¼ˆå› ä¸ºè¿›ç¨‹å¯èƒ½å·²ç»å…³é—­ï¼‰
        let _ = self.send_command(&WorkerCommand::Exit {});
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©è¿›ç¨‹è‡ªå·±é€€å‡º
        std::thread::sleep(std::time::Duration::from_millis(100));
        
        // å¦‚æœè¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼Œå¼ºåˆ¶æ€æ­»
        match self.child.try_wait() {
            Ok(Some(_)) => {
                // è¿›ç¨‹å·²ç»é€€å‡º
            }
            Ok(None) => {
                // è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œå¼ºåˆ¶æ€æ­»
                let _ = self.child.kill();
                let _ = self.child.wait();
            }
            Err(_) => {
                // æ£€æŸ¥çŠ¶æ€å¤±è´¥ï¼Œç›´æ¥æ€æ­»
                let _ = self.child.kill();
                let _ = self.child.wait();
            }
        }
        
        Ok(())
    }
}

/// å¤šè¿›ç¨‹æ± ç®¡ç†å™¨
pub struct ProcessPool {
    workers: Vec<WorkerProcess>,
    num_processes: usize,
    python_path: String,
}

impl ProcessPool {
    /// åˆ›å»ºæ–°çš„è¿›ç¨‹æ± 
    pub fn new(num_processes: usize, python_path: &str) -> PyResult<Self> {
        let mut workers = Vec::new();
        
        println!("åˆ›å»º {} ä¸ªå·¥ä½œè¿›ç¨‹...", num_processes);
        
        for i in 0..num_processes {
            let worker = WorkerProcess::new(i, python_path)?;
            workers.push(worker);
        }
        
        println!("è¿›ç¨‹æ± åˆ›å»ºå®Œæˆ");
        
        Ok(ProcessPool {
            workers,
            num_processes,
            python_path: python_path.to_string(),
        })
    }

    /// ä¸ºä¸€ä¸ªæ•°æ®å—æ‰§è¡Œä»»åŠ¡
    pub fn execute_tasks_for_chunk(
        &mut self,
        _py: Python,
        function_code: &str,
        tasks: Vec<Task>,
        go_class_serialized: Option<String>,
    ) -> PyResult<Vec<ProcessResult>> {
        let num_tasks = tasks.len();
        if num_tasks == 0 {
            return Ok(Vec::new());
        }

        // 1. å‘é€åˆå§‹åŒ–æŒ‡ä»¤ (FunctionCode, GoClass) å’Œ Ping
        for (i, worker) in &mut self.workers.iter_mut().enumerate() {
            if let Err(e) = worker.ping() {
                 return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                    format!("å·¥ä½œè¿›ç¨‹ {} æ— å“åº”: {}", i, e)
                ));
            }
            worker.send_command(&WorkerCommand::FunctionCode(function_code.to_string()))?;
            if let Some(go_ser) = &go_class_serialized {
                worker.send_command(&WorkerCommand::GoClass(go_ser.clone()))?;
            }
        }

        // 2. åˆ†å‘ä»»åŠ¡
        let mut all_sent_tasks: Vec<Vec<Task>> = vec![Vec::new(); self.num_processes];
        for (task_idx, task) in tasks.into_iter().enumerate() {
            let worker_idx = task_idx % self.num_processes;
            self.workers[worker_idx].send_command(&WorkerCommand::Task(task.clone()))?;
            all_sent_tasks[worker_idx].push(task);
        }

        // 3. å‘é€æ‰§è¡ŒæŒ‡ä»¤
        for (i, worker) in &mut self.workers.iter_mut().enumerate() {
            if !all_sent_tasks[i].is_empty() {
                worker.send_command(&WorkerCommand::Execute {})?;
            }
        }
        
        // 4. å¹¶è¡Œæ”¶é›†ç»“æœ
        let (tx, rx) = channel();
        let num_workers_with_tasks = all_sent_tasks.iter().filter(|t| !t.is_empty()).count();
        let workers_drained: Vec<_> = self.workers.drain(..).collect();

        for (i, mut worker) in workers_drained.into_iter().enumerate() {
            let sent_tasks_for_worker = all_sent_tasks[i].clone();
            if sent_tasks_for_worker.is_empty() {
                continue;
            }
            let tx = tx.clone();

            thread::spawn(move || {
                let result = worker.receive_result();
                tx.send((i, result, sent_tasks_for_worker, worker)).unwrap();
            });
        }
        
        let mut results = Vec::with_capacity(num_tasks);
        let mut dead_workers = std::collections::HashSet::new();

        for _ in 0..num_workers_with_tasks {
            match rx.recv() {
                Ok((worker_id, Ok(response), sent_tasks, mut worker)) => {
                    if !response.errors.is_empty() {
                        for error_msg in response.errors {
                            eprintln!("å·¥ä½œè¿›ç¨‹ {} è¿”å›é”™è¯¯: {}", worker_id, error_msg);
                        }
                    }

                    for (task, facs) in sent_tasks.iter().zip(response.results) {
                        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs() as i64;
                        results.push(ProcessResult {
                            date: task.date,
                            code: task.code.clone(),
                            timestamp: now,
                            facs,
                        });
                    }
                    worker.terminate().ok();
                }
                Ok((worker_id, Err(e), _, mut worker)) => {
                    eprintln!("æ¥æ”¶å·¥ä½œè¿›ç¨‹ {} ç»“æœæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {}", worker_id, e);
                    dead_workers.insert(worker_id);
                    worker.terminate().ok();
                }
                Err(e) => {
                    eprintln!("ä¸€ä¸ªå·¥ä½œçº¿ç¨‹æ‰§è¡Œå¤±è´¥(channel recv error): {}", e);
                }
            }
        }
        
        // é‡å»ºè¿›ç¨‹æ± ï¼Œç¡®ä¿ä¸‹ä¸€å—ä»»åŠ¡ä½¿ç”¨å…¨æ–°çš„è¿›ç¨‹
        self.workers.clear();
        for i in 0..self.num_processes {
            let new_worker = WorkerProcess::new(i, &self.python_path)?;
            self.workers.push(new_worker);
        }

        Ok(results)
    }
}

impl Drop for ProcessPool {
    fn drop(&mut self) {
        // ç»ˆæ­¢æ‰€æœ‰å·¥ä½œè¿›ç¨‹
        for worker in &mut self.workers {
            let _ = worker.terminate();
        }
    }
}

/// å¤šè¿›ç¨‹æ‰§è¡Œé…ç½®
#[derive(Clone)]
pub struct MultiProcessConfig {
    pub num_processes: Option<usize>,
    pub backup_batch_size: usize,
    pub backup_file: Option<String>,
    pub storage_format: String,
    pub resume_from_backup: bool,
    pub python_path: String,
}

impl Default for MultiProcessConfig {
    fn default() -> Self {
        Self {
            num_processes: None,
            backup_batch_size: 1000,
            backup_file: None,
            storage_format: "binary".to_string(),
            resume_from_backup: false,
            python_path: "/home/chenzongwei/.conda/envs/chenzongwei311/bin/python".to_string(),
        }
    }
}

/// å¤šè¿›ç¨‹æ‰§è¡Œå™¨
pub struct MultiProcessExecutor {
    config: MultiProcessConfig,
    backup_manager: Option<BackupManager>,
}

impl MultiProcessExecutor {
    pub fn new(config: MultiProcessConfig) -> PyResult<Self> {
        let backup_manager = if let Some(backup_file) = &config.backup_file {
            Some(BackupManager::new(backup_file, &config.storage_format)?)
        } else {
            None
        };

        Ok(Self {
            config,
            backup_manager,
        })
    }

    /// æå–å‡½æ•°ä»£ç 
    fn extract_function_code(&self, py: Python, func: &PyAny) -> PyResult<String> {
        println!("æ­£åœ¨æå–å‡½æ•°ä»£ç ...");
        
        let inspect = py.import("inspect")?;
        
        match inspect.call_method1("getsource", (func,)) {
            Ok(source) => {
                let source_str: String = source.extract()?;
                println!("âœ… æˆåŠŸè·å–å‡½æ•°æºä»£ç ï¼Œé•¿åº¦: {} å­—ç¬¦", source_str.len());
                
                if source_str.trim().is_empty() {
                    return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                        "å‡½æ•°æºä»£ç ä¸ºç©º"
                    ));
                }
                
                Ok(source_str)
            }
            Err(e) => {
                println!("âš ï¸ æ— æ³•è·å–å‡½æ•°æºä»£ç : {}", e);
                
                let func_name = func.getattr("__name__")
                    .and_then(|name| name.extract::<String>())
                    .unwrap_or_else(|_| "user_function".to_string());
                
                println!("ğŸ“ åˆ›å»ºå‡½æ•°åŒ…è£…ï¼Œå‡½æ•°å: {}", func_name);
                
                match py.import("dill") {
                    Ok(dill) => {
                        let serialized = dill.call_method1("dumps", (func,))?;
                        let bytes: Vec<u8> = serialized.extract()?;
                        use base64::Engine;
                        let encoded = base64::engine::general_purpose::STANDARD.encode(bytes);
                        println!("âœ… æˆåŠŸä½¿ç”¨dillåºåˆ—åŒ–ï¼Œé•¿åº¦: {} å­—ç¬¦", encoded.len());
                        Ok(encoded)
                    }
                    Err(_) => {
                        Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                            format!("æ— æ³•åºåˆ—åŒ–å‡½æ•° '{}'ï¼Œè¯·ç¡®ä¿å‡½æ•°æ˜¯å…¨å±€å®šä¹‰çš„æˆ–å®‰è£…dillåº“", func_name)
                        ))
                    }
                }
            }
        }
    }

    /// ä¸»è¦çš„å¤šè¿›ç¨‹æ‰§è¡Œå‡½æ•°
    pub fn run_multiprocess(
        &mut self,
        py: Python,
        func: &PyAny,
        args: Vec<(i32, String)>,
        go_class: Option<&PyAny>,
        progress_callback: Option<&PyAny>,
        chunk_size: Option<usize>,
    ) -> PyResult<Vec<ReturnResult>> {
        let total_tasks = args.len();
        println!("å¼€å§‹å¤šè¿›ç¨‹æ‰§è¡Œï¼Œæ€»ä»»åŠ¡æ•°: {}", total_tasks);

        // å°†å‚æ•°è½¬æ¢ä¸ºTaskç»“æ„
        let tasks: Vec<Task> = args.into_iter().map(|(date, code)| Task { date, code }).collect();

        // æ£€æŸ¥æ˜¯å¦éœ€è¦ä»å¤‡ä»½æ¢å¤
        let (remaining_tasks, existing_results) = if self.config.resume_from_backup {
            self.load_existing_results(&tasks)?
        } else {
            (tasks, Vec::new())
        };

        let remaining_count = remaining_tasks.len();
        println!("éœ€è¦è®¡ç®—çš„ä»»åŠ¡æ•°: {}", remaining_count);

        if remaining_count == 0 {
            return Ok(existing_results.into_iter().map(|r| r.to_return_result()).collect());
        }

        // å¤‡ä»½çº¿ç¨‹è®¾ç½®
        let (backup_sender, backup_receiver) = if self.backup_manager.is_some() {
            let (tx, rx) = channel::<ProcessResult>();
            (Some(tx), Some(rx))
        } else {
            (None, None)
        };

        let backup_handle = if let Some(receiver) = backup_receiver {
            if let Some(backup_manager) = self.backup_manager.take() {
                let batch_size = self.config.backup_batch_size;
                Some(thread::spawn(move || {
                    Self::backup_worker(backup_manager, receiver, batch_size);
                }))
            } else { None }
        } else { None };

        // åˆ›å»ºè¿›ç¨‹æ± 
        let num_processes = self.config.num_processes.unwrap_or_else(|| {
            std::thread::available_parallelism().map(|n| n.get()).unwrap_or(4)
        });
        let mut process_pool = ProcessPool::new(num_processes, &self.config.python_path)?;

        // æå–å’Œåºåˆ—åŒ–ä»£ç /å¯¹è±¡
        let function_code = self.extract_function_code(py, func)?;
        let go_class_serialized = if let Some(go_class) = go_class {
            py.import("dill").ok().and_then(|dill| {
                dill.call_method1("dumps", (go_class,)).ok().and_then(|s| {
                    s.extract::<Vec<u8>>().ok().map(|bytes| {
                        use base64::Engine;
                        base64::engine::general_purpose::STANDARD.encode(bytes)
                    })
                })
            })
        } else { None };
        
        // åˆ†å—æ‰§è¡Œ
        let start_time = Instant::now();
        
        let chunk_size = chunk_size.unwrap_or(50000);
        let mut all_results = existing_results;

        let chunks: Vec<_> = remaining_tasks.chunks(chunk_size).collect();
        let total_chunks = chunks.len();
        let mut completed_chunks = 0;

        // å¦‚æœæœ‰å›è°ƒï¼Œåˆ™åœ¨Pythonç«¯åˆå§‹åŒ–å®ƒ
        if let Some(cb) = progress_callback {
            Python::with_gil(|_py| {
                if let Err(_e) = cb.call_method1("set_chunk_info", (chunk_size,)) {
                    // è¿™æ˜¯ä¸€ä¸ªå¯é€‰æ–¹æ³•ï¼Œå¦‚æœä¸å­˜åœ¨ä¹Ÿä¸ç®—é”™è¯¯
                    // eprintln!("è°ƒç”¨ set_chunk_info å¤±è´¥: {}", e);
                }
            });
        }

        for task_chunk in chunks {
            let chunk_results = match process_pool.execute_tasks_for_chunk(
                py,
                &function_code,
                task_chunk.to_vec(),
                go_class_serialized.clone(),
            ) {
                Ok(res) => res,
                Err(e) => {
                    if let Some(cb) = progress_callback {
                        Python::with_gil(|_py| {
                            let _ = cb.call_method1("set_error", (e.to_string(),));
                        });
                    }
                    return Err(e);
                }
            };
            
            completed_chunks += 1;

            // å‘é€åˆ°å¤‡ä»½çº¿ç¨‹
            if let Some(sender) = &backup_sender {
                for res in &chunk_results {
                    sender.send(res.clone()).ok();
                }
            }

            // è°ƒç”¨Pythonå›è°ƒ
            if let Some(cb) = progress_callback {
                 Python::with_gil(|py| {
                    // 1. è°ƒç”¨ update
                    let elapsed = start_time.elapsed().as_secs_f64();
                    let remaining = if completed_chunks > 0 {
                        (elapsed / completed_chunks as f64) * (total_chunks - completed_chunks) as f64
                    } else { 0.0 };

                    let progress_info: Vec<PyObject> = vec![
                       completed_chunks.to_object(py),
                       total_chunks.to_object(py),
                       remaining.to_object(py),
                       elapsed.to_object(py),
                   ];
                   if let Err(e) = cb.call_method1("update", (progress_info,)) {
                       eprintln!("è°ƒç”¨ progress_callback.update å¤±è´¥: {}", e);
                   }

                   // 2. è°ƒç”¨ _update_table_data
                   let py_results = PyList::empty(py);
                   for res in &chunk_results {
                       let dict = PyDict::new(py);
                       dict.set_item("date", res.date).unwrap();
                       dict.set_item("code", &res.code).unwrap();
                       dict.set_item("timestamp", res.timestamp).unwrap();
                       dict.set_item("facs", &res.facs).unwrap();
                       py_results.append(dict).unwrap();
                   }
                   
                   if let Err(e) = cb.call_method1("_update_table_data", (py_results,)) {
                       eprintln!("è°ƒç”¨ progress_callback._update_table_data å¤±è´¥: {}", e);
                   }
                });
            }

            all_results.extend(chunk_results);
        }

        // æ ‡è®°ä»»åŠ¡å®Œæˆ
        if let Some(cb) = progress_callback {
            Python::with_gil(|_py| {
                let _ = cb.call_method0("finish");
            });
        }

        // ç­‰å¾…å¤‡ä»½å®Œæˆ
        if let Some(sender) = backup_sender {
            drop(sender);
        }
        if let Some(handle) = backup_handle {
            let _ = handle.join();
        }

        println!("å¤šè¿›ç¨‹æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {:.2}ç§’", start_time.elapsed().as_secs_f64());

        Ok(all_results.into_iter().map(|r| r.to_return_result()).collect())
    }

    /// å¤‡ä»½å·¥ä½œçº¿ç¨‹
    fn backup_worker(
        mut backup_manager: BackupManager,
        receiver: Receiver<ProcessResult>,
        batch_size: usize,
    ) {
        let mut batch = Vec::with_capacity(batch_size);
        
        loop {
            match receiver.recv() {
                Ok(result) => {
                    // è½¬æ¢ä¸ºComputeResult
                    let compute_result = crate::parallel::ComputeResult {
                        date: result.date,
                        code: result.code,
                        timestamp: result.timestamp,
                        facs: result.facs,
                    };
                    batch.push(compute_result);
                    
                    if batch.len() >= batch_size {
                        if let Err(e) = backup_manager.save_batch(&batch) {
                            eprintln!("å¤‡ä»½å¤±è´¥: {}", e);
                        }
                        batch.clear();
                    }
                }
                Err(_) => {
                    // é€šé“å…³é—­ï¼Œä¿å­˜å‰©ä½™æ•°æ®
                    if !batch.is_empty() {
                        if let Err(e) = backup_manager.save_batch(&batch) {
                            eprintln!("æœ€ç»ˆå¤‡ä»½å¤±è´¥: {}", e);
                        }
                    }
                    break;
                }
            }
        }
    }

    /// åŠ è½½å·²æœ‰ç»“æœ
    fn load_existing_results(
        &self,
        tasks: &[Task],
    ) -> PyResult<(Vec<Task>, Vec<ProcessResult>)> {
        if let Some(backup_manager) = &self.backup_manager {
            // è½¬æ¢ä¸º(i32, String)æ ¼å¼ä»¥å…¼å®¹ç°æœ‰çš„å¤‡ä»½ç®¡ç†å™¨
            let args: Vec<(i32, String)> = tasks.iter()
                .map(|task| (task.date, task.code.clone()))
                .collect();
                
            let existing = backup_manager.load_existing_results(&args)?;
            let existing_keys: std::collections::HashSet<(i32, String)> = 
                existing.iter().map(|r| (r.date, r.code.clone())).collect();
            
            let remaining: Vec<Task> = tasks
                .iter()
                .filter(|task| !existing_keys.contains(&(task.date, task.code.clone())))
                .cloned()
                .collect();

            // è¾“å‡ºå¤‡ä»½ä¿¡æ¯
            if !existing.is_empty() && !remaining.is_empty() {
                let latest_backup_date = existing.iter().map(|r| r.date).max().unwrap_or(0);
                let earliest_remaining_date = remaining.iter().map(|t| t.date).min().unwrap_or(0);
                println!("å¤‡ä»½ä¸­æœ€æ™šæ—¥æœŸä¸º{}ï¼Œå³å°†ä»{}æ—¥æœŸå¼€å§‹è®¡ç®—", latest_backup_date, earliest_remaining_date);
            }

            // è½¬æ¢ä¸ºProcessResult
            let process_results: Vec<ProcessResult> = existing.into_iter()
                .map(|r| ProcessResult {
                    date: r.date,
                    code: r.code,
                    timestamp: r.timestamp,
                    facs: r.facs,
                })
                .collect();

            Ok((remaining, process_results))
        } else {
            Ok((tasks.to_vec(), Vec::new()))
        }
    }
}