#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åŸºå‡†æµ‹è¯• - å±•ç¤ºå¹¶è¡Œå¤„ç†å’Œä¼˜åŒ–æ•ˆæœ
"""

import sys
import time
import tempfile
import statistics
import multiprocessing
sys.path.append('/home/chenzongwei/rust_pyfunc/python')

import rust_pyfunc


def cpu_intensive_function(date, code):
    """CPUå¯†é›†å‹æµ‹è¯•å‡½æ•°"""
    # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—å¯†é›†çš„æ“ä½œ
    result = 0
    for i in range(1000):
        result += hash(f"{date}_{code}_{i}") % 100
    
    # è¿”å›è®¡ç®—ç»“æœ
    return [
        float(date % 10000),
        float(len(code)),
        float(result % 1000)
    ]


def io_simulation_function(date, code):
    """IOå¯†é›†å‹æµ‹è¯•å‡½æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # æ¨¡æ‹ŸIOç­‰å¾…
    time.sleep(0.001)  # 1mså»¶è¿Ÿ
    return [
        float(date % 1000),
        float(len(code)),
        hash(f"{date}_{code}") % 100
    ]


def simple_function(date, code):
    """ç®€å•å¿«é€Ÿå‡½æ•°"""
    return [
        float(date % 1000),
        float(len(code)),
        1.0
    ]


def benchmark_function(func, args, test_name, **kwargs):
    """åŸºå‡†æµ‹è¯•å‡½æ•°"""
    print(f"\n--- {test_name} ---")
    print(f"ä»»åŠ¡æ•°é‡: {len(args)}")
    
    start_time = time.time()
    result = rust_pyfunc.run_pools(func, args, **kwargs)
    end_time = time.time()
    
    elapsed = end_time - start_time
    speed = len(args) / elapsed if elapsed > 0 else float('inf')
    
    print(f"æ‰§è¡Œæ—¶é—´: {elapsed:.3f} ç§’")
    print(f"å¤„ç†é€Ÿåº¦: {speed:.0f} ä»»åŠ¡/ç§’")
    print(f"ç»“æœæ•°é‡: {len(result)}")
    
    return elapsed, speed, len(result)


def test_multiprocessing_vs_serial():
    """æµ‹è¯•multiprocessing vs ä¸²è¡Œå¤„ç†"""
    print("=== Multiprocessing vs ä¸²è¡Œå¤„ç†å¯¹æ¯” ===")
    
    # åˆ›å»ºå¯ä»¥pickleçš„å‡½æ•°
    def picklable_function(date, code):
        return cpu_intensive_function(date, code)
    
    args = [[20220101 + i, f"{j:06d}"] for i in range(5) for j in range(1, 21)]  # 100ä¸ªä»»åŠ¡
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        backup_file = f.name
    
    try:
        # æµ‹è¯•multiprocessingï¼ˆå¦‚æœæ”¯æŒï¼‰
        print(f"\næµ‹è¯•æ”¯æŒmultiprocessingçš„å‡½æ•°ï¼š")
        elapsed_mp, speed_mp, count_mp = benchmark_function(
            picklable_function,
            args,
            "Multiprocessingå¤„ç†",
            backup_file=backup_file + "_mp",
            storage_format="json",
            num_threads=multiprocessing.cpu_count()
        )
        
        # æµ‹è¯•ä¸²è¡Œå¤„ç†ï¼ˆä¸å¯pickleçš„å‡½æ•°ï¼‰
        print(f"\næµ‹è¯•ä¸æ”¯æŒmultiprocessingçš„å‡½æ•°ï¼š")
        elapsed_serial, speed_serial, count_serial = benchmark_function(
            cpu_intensive_function,  # è¿™ä¸ªå‡½æ•°ä¸èƒ½pickle
            args,
            "ä¼˜åŒ–ä¸²è¡Œå¤„ç†",
            backup_file=backup_file + "_serial",
            storage_format="json",
            num_threads=multiprocessing.cpu_count()
        )
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\næ€§èƒ½å¯¹æ¯”ï¼š")
        if speed_mp > speed_serial:
            speedup = speed_mp / speed_serial
            print(f"âœ… Multiprocessingæ¯”ä¸²è¡Œå¤„ç†å¿« {speedup:.1f}x")
        else:
            print(f"âš ï¸  ä¸²è¡Œå¤„ç†åœ¨è¿™ç§æƒ…å†µä¸‹æ›´å¿«ï¼ˆå¯èƒ½æ˜¯ä»»åŠ¡å¤ªå°ï¼‰")
            
        print(f"Multiprocessing: {speed_mp:.0f} ä»»åŠ¡/ç§’")
        print(f"ä¼˜åŒ–ä¸²è¡Œ: {speed_serial:.0f} ä»»åŠ¡/ç§’")
        
    finally:
        import os
        for suffix in ["_mp", "_serial"]:
            if os.path.exists(backup_file + suffix):
                os.unlink(backup_file + suffix)


def test_batch_size_optimization():
    """æµ‹è¯•æ‰¹æ¬¡å¤§å°ä¼˜åŒ–"""
    print("\n=== æ‰¹æ¬¡å¤§å°ä¼˜åŒ–æµ‹è¯• ===")
    
    args = [[20220101, f"{i:06d}"] for i in range(1, 101)]  # 100ä¸ªç®€å•ä»»åŠ¡
    
    batch_configs = [
        {"num_threads": 1, "name": "å•çº¿ç¨‹"},
        {"num_threads": 2, "name": "2çº¿ç¨‹"},
        {"num_threads": 4, "name": "4çº¿ç¨‹"},
        {"num_threads": 8, "name": "8çº¿ç¨‹"},
        {"num_threads": multiprocessing.cpu_count(), "name": f"{multiprocessing.cpu_count()}çº¿ç¨‹ï¼ˆCPUæ•°ï¼‰"},
    ]
    
    results = []
    
    for config in batch_configs:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            backup_file = f.name
        
        try:
            elapsed, speed, count = benchmark_function(
                simple_function,
                args,
                config["name"],
                backup_file=backup_file,
                storage_format="json",
                num_threads=config["num_threads"]
            )
            results.append((config["name"], elapsed, speed))
            
        finally:
            import os
            if os.path.exists(backup_file):
                os.unlink(backup_file)
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    best_config = max(results, key=lambda x: x[2])
    print(f"\næœ€ä½³é…ç½®: {best_config[0]} ({best_config[2]:.0f} ä»»åŠ¡/ç§’)")


def test_storage_format_performance():
    """æµ‹è¯•ä¸åŒå­˜å‚¨æ ¼å¼çš„æ€§èƒ½"""
    print("\n=== å­˜å‚¨æ ¼å¼æ€§èƒ½æµ‹è¯• ===")
    
    args = [[20220101, f"{i:06d}"] for i in range(1, 201)]  # 200ä¸ªä»»åŠ¡
    
    formats = [
        ("json", ".json"),
        ("binary", ".bin"),
        ("memory_map", ".bin")
    ]
    
    results = []
    
    for storage_format, suffix in formats:
        with tempfile.NamedTemporaryFile(mode='w', suffix=suffix, delete=False) as f:
            backup_file = f.name
        
        try:
            elapsed, speed, count = benchmark_function(
                simple_function,
                args,
                f"{storage_format.upper()} æ ¼å¼",
                backup_file=backup_file,
                storage_format=storage_format,
                backup_batch_size=50,
                num_threads=4
            )
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            import os
            file_size = os.path.getsize(backup_file) if os.path.exists(backup_file) else 0
            results.append((storage_format, elapsed, speed, file_size))
            
        finally:
            import os
            if os.path.exists(backup_file):
                os.unlink(backup_file)
    
    # æ€§èƒ½å¯¹æ¯”
    print(f"\nå­˜å‚¨æ ¼å¼å¯¹æ¯”ï¼š")
    for format_name, elapsed, speed, file_size in results:
        print(f"{format_name:12}: {speed:8.0f} ä»»åŠ¡/ç§’, æ–‡ä»¶å¤§å°: {file_size:8d} å­—èŠ‚")
    
    fastest_format = max(results, key=lambda x: x[2])
    smallest_format = min(results, key=lambda x: x[3])
    print(f"\næœ€å¿«æ ¼å¼: {fastest_format[0]}")
    print(f"æœ€å°æ–‡ä»¶: {smallest_format[0]}")


def test_resume_performance():
    """æµ‹è¯•å¤‡ä»½æ¢å¤æ€§èƒ½"""
    print("\n=== å¤‡ä»½æ¢å¤æ€§èƒ½æµ‹è¯• ===")
    
    # åˆ›å»ºå¤§æ•°æ®é›†
    full_args = [[20220101 + i//100, f"{i%100:06d}"] for i in range(1000)]  # 1000ä¸ªä»»åŠ¡
    partial_args = full_args[:500]  # å‰500ä¸ª
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        backup_file = f.name
    
    try:
        # ç¬¬ä¸€æ¬¡è¿è¡Œï¼šåˆ›å»ºéƒ¨åˆ†å¤‡ä»½
        print(f"ç¬¬ä¸€æ¬¡è¿è¡Œï¼šåˆ›å»º {len(partial_args)} ä¸ªä»»åŠ¡çš„å¤‡ä»½")
        elapsed1, speed1, count1 = benchmark_function(
            simple_function,
            partial_args,
            "åˆ›å»ºå¤‡ä»½",
            backup_file=backup_file,
            storage_format="binary",
            backup_batch_size=100,
            num_threads=4
        )
        
        # ç¬¬äºŒæ¬¡è¿è¡Œï¼šæ¢å¤å¹¶å®Œæˆ
        print(f"ç¬¬äºŒæ¬¡è¿è¡Œï¼šæ¢å¤å¤‡ä»½å¹¶å¤„ç†å‰©ä½™ {len(full_args) - len(partial_args)} ä¸ªä»»åŠ¡")
        elapsed2, speed2, count2 = benchmark_function(
            simple_function,
            full_args,
            "æ¢å¤å¤‡ä»½",
            backup_file=backup_file,
            resume_from_backup=True,
            storage_format="binary",
            backup_batch_size=100,
            num_threads=4
        )
        
        # è®¡ç®—æ€»ä½“æ€§èƒ½
        total_unique_tasks = len(full_args)
        total_time = elapsed1 + elapsed2
        overall_speed = total_unique_tasks / total_time
        
        print(f"\næ¢å¤æ€§èƒ½åˆ†æï¼š")
        print(f"æ€»ä»»åŠ¡æ•°: {total_unique_tasks}")
        print(f"æ€»æ—¶é—´: {total_time:.3f} ç§’") 
        print(f"æ•´ä½“é€Ÿåº¦: {overall_speed:.0f} ä»»åŠ¡/ç§’")
        print(f"å¤‡ä»½æ¢å¤æ•ˆç‡: {(len(full_args) - len(partial_args)) / elapsed2:.0f} æ–°ä»»åŠ¡/ç§’")
        
    finally:
        import os
        if os.path.exists(backup_file):
            os.unlink(backup_file)


if __name__ == "__main__":
    print("å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    print(f"ç³»ç»Ÿä¿¡æ¯ï¼š")
    print(f"  CPUæ ¸å¿ƒæ•°: {multiprocessing.cpu_count()}")
    print(f"  Pythonç‰ˆæœ¬: {sys.version}")
    
    try:
        test_multiprocessing_vs_serial()
        test_batch_size_optimization() 
        test_storage_format_performance()
        test_resume_performance()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        print("\næ€§èƒ½ä¼˜åŒ–æ€»ç»“ï¼š")
        print("1. ğŸš€ å®ç°äº†æ™ºèƒ½å¹¶è¡Œå¤„ç†ï¼ˆmultiprocessing + ä¼˜åŒ–ä¸²è¡Œï¼‰")
        print("2. âš¡ æ‰¹é‡ä»»åŠ¡åˆ†å‘å‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€")
        print("3. ğŸ’¾ å¤šç§å­˜å‚¨æ ¼å¼ä¼˜åŒ–ï¼ˆJSON/Binary/MemoryMapï¼‰")
        print("4. ğŸ”„ é«˜æ•ˆçš„å¤‡ä»½æ¢å¤æœºåˆ¶")
        print("5. ğŸŒ Webç®¡ç†ç•Œé¢æ”¯æŒè‡ªåŠ¨ç«¯å£é€‰æ‹©")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)