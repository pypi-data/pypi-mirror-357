#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½å¹¶è¡Œè®¡ç®—ç³»ç»Ÿæ¼”ç¤º
====================

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨rust_pyfuncçš„å¹¶è¡Œè®¡ç®—å’Œå¤‡ä»½åŠŸèƒ½ã€‚
ç³»ç»Ÿæ”¯æŒï¼š
- é«˜é€Ÿå¹¶è¡Œæ‰§è¡ŒPythonå‡½æ•° 
- ä¸‰ç§é«˜æ€§èƒ½å­˜å‚¨æ ¼å¼ï¼šjson, binary, memory_map
- è‡ªåŠ¨å¼‚æ­¥å¤‡ä»½
- è¿›åº¦ç›‘æ§å’Œå›è°ƒ
- ä»å¤‡ä»½æ¢å¤æ‰§è¡Œ
- å®æ—¶æ•°æ®æŸ¥è¯¢

é€‚ç”¨åœºæ™¯ï¼š
- å¤§è§„æ¨¡å› å­è®¡ç®—ï¼ˆç™¾ä¸‡çº§ä»»åŠ¡ï¼‰
- è‚¡ç¥¨æ•°æ®åˆ†æ
- é‡åŒ–æŠ•èµ„ç­–ç•¥å›æµ‹
- ä»»ä½•éœ€è¦å¹¶è¡Œå¤„ç†å¤§é‡æ•°æ®çš„åœºæ™¯
"""

import sys
import tempfile
import os
import time
sys.path.append('/home/chenzongwei/rust_pyfunc/python')

import rust_pyfunc

def financial_analysis(date, code):
    """æ¨¡æ‹Ÿé‡‘èæ•°æ®åˆ†æå‡½æ•°
    
    è¾“å…¥ï¼š
        date: æ—¥æœŸ (YYYYMMDD)
        code: è‚¡ç¥¨ä»£ç 
    
    è¾“å‡ºï¼š
        [ma5, ma20, rsi, bollinger_upper, bollinger_lower]
    """
    # æ¨¡æ‹Ÿç§»åŠ¨å¹³å‡
    ma5 = float(date % 1000) / 10.0
    ma20 = ma5 * 0.95
    
    # æ¨¡æ‹ŸRSI
    rsi = 50.0 + (len(code) % 50)
    
    # æ¨¡æ‹Ÿå¸ƒæ—å¸¦
    bollinger_upper = ma20 * 1.02
    bollinger_lower = ma20 * 0.98
    
    return [ma5, ma20, rsi, bollinger_upper, bollinger_lower]

def progress_callback(completed, total, elapsed_time, speed):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    percent = (completed / total) * 100
    print(f"è¿›åº¦: {percent:.1f}% ({completed}/{total}) - é€Ÿåº¦: {speed:.0f} ä»»åŠ¡/ç§’")

def demo_parallel_computing():
    """æ¼”ç¤ºå¹¶è¡Œè®¡ç®—åŠŸèƒ½"""
    print("ğŸš€ é«˜æ€§èƒ½å¹¶è¡Œè®¡ç®—ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼š1000ä¸ªè‚¡ç¥¨ï¼Œè¿ç»­5ä¸ªäº¤æ˜“æ—¥
    print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    args = []
    base_date = 20240101
    for day in range(5):  # 5ä¸ªäº¤æ˜“æ—¥
        for stock_id in range(200):  # 200åªè‚¡ç¥¨
            date = base_date + day
            code = f"{600000 + stock_id:06d}"
            args.append((date, code))
    
    print(f"   æ€»ä»»åŠ¡æ•°: {len(args):,} ä¸ª")
    print(f"   è¦†ç›–è‚¡ç¥¨: 200 åª")
    print(f"   è¦†ç›–æ—¥æœŸ: 5 ä¸ªäº¤æ˜“æ—¥")
    
    # æµ‹è¯•ä¸åŒå­˜å‚¨æ ¼å¼çš„æ€§èƒ½
    storage_formats = ["json", "binary", "memory_map"]
    results = {}
    
    for fmt in storage_formats:
        print(f"\nğŸ“ˆ æµ‹è¯• {fmt.upper()} å­˜å‚¨æ ¼å¼")
        print("-" * 60)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix=f'.{fmt}', delete=False) as f:
            backup_file = f.name
        
        try:
            start_time = time.time()
            
            # æ‰§è¡Œå¹¶è¡Œè®¡ç®—
            result = rust_pyfunc.run_pools(
                financial_analysis,
                args,
                backup_file=backup_file,
                storage_format=fmt,
                num_threads=1,  # å•çº¿ç¨‹é¿å…PyO3é™åˆ¶
                backup_batch_size=100,
                backup_async=True,
                progress_callback=progress_callback
            )
            
            execution_time = time.time() - start_time
            
            # æŸ¥è¯¢å¤‡ä»½æ•°æ®
            start_time = time.time()
            backup_data = rust_pyfunc.query_backup(
                backup_file,
                storage_format=fmt,
                date_range=(20240101, 20240105),
                codes=["600000", "600001", "600002"]
            )
            query_time = time.time() - start_time
            
            # ç»Ÿè®¡ä¿¡æ¯
            file_size = os.path.getsize(backup_file)
            
            results[fmt] = {
                'execution_time': execution_time,
                'query_time': query_time,
                'file_size': file_size,
                'tasks_per_second': len(args) / execution_time,
                'result_count': len(result),
                'backup_count': len(backup_data)
            }
            
            print(f"âœ“ æ‰§è¡Œå®Œæˆ: {execution_time:.3f}ç§’")
            print(f"âœ“ å¤„ç†é€Ÿåº¦: {results[fmt]['tasks_per_second']:.0f} ä»»åŠ¡/ç§’")
            print(f"âœ“ æŸ¥è¯¢é€Ÿåº¦: {query_time:.3f}ç§’")
            print(f"âœ“ æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")
            print(f"âœ“ æ•°æ®å®Œæ•´æ€§: {len(result) == len(args) and len(backup_data) > 0}")
            
        except Exception as e:
            print(f"âŒ {fmt} æµ‹è¯•å¤±è´¥: {e}")
            results[fmt] = None
        finally:
            if os.path.exists(backup_file):
                os.unlink(backup_file)
    
    # æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
    print("=" * 80)
    
    successful_formats = {k: v for k, v in results.items() if v is not None}
    
    if successful_formats:
        print(f"{'æ ¼å¼':<12} {'æ‰§è¡Œæ—¶é—´(ç§’)':<12} {'é€Ÿåº¦(ä»»åŠ¡/ç§’)':<15} {'æŸ¥è¯¢æ—¶é—´(ç§’)':<12} {'æ–‡ä»¶å¤§å°(KB)':<12}")
        print("-" * 80)
        
        for fmt, data in successful_formats.items():
            print(f"{fmt:<12} {data['execution_time']:<12.3f} {data['tasks_per_second']:<15.0f} "
                  f"{data['query_time']:<12.3f} {data['file_size']/1024:<12.1f}")
        
        # æ€§èƒ½æ’å
        fastest_exec = min(successful_formats.keys(), key=lambda x: successful_formats[x]['execution_time'])
        fastest_query = min(successful_formats.keys(), key=lambda x: successful_formats[x]['query_time'])
        smallest_file = min(successful_formats.keys(), key=lambda x: successful_formats[x]['file_size'])
        
        print(f"\nğŸ† æ€§èƒ½å† å†›:")
        print(f"  ğŸš€ æœ€å¿«æ‰§è¡Œ: {fastest_exec}")
        print(f"  âš¡ æœ€å¿«æŸ¥è¯¢: {fastest_query}")  
        print(f"  ğŸ’¾ æœ€å°å­˜å‚¨: {smallest_file}")
        
        print(f"\nğŸ’¡ æ¨èä½¿ç”¨:")
        print(f"  â€¢ å¯¹äºå°è§„æ¨¡æ•°æ®ï¼ˆ< 10ä¸‡è¡Œï¼‰ï¼šjson æ ¼å¼ï¼Œä¾¿äºè°ƒè¯•")
        print(f"  â€¢ å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼ˆ> 10ä¸‡è¡Œï¼‰ï¼šbinary æ ¼å¼ï¼Œæœ€ä½³æ€§èƒ½")
        print(f"  â€¢ å¯¹äºè¶…å¤§æ•°æ®ï¼ˆ> 100ä¸‡è¡Œï¼‰ï¼šmemory_map æ ¼å¼ï¼Œå†…å­˜å‹å¥½")
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼ç³»ç»Ÿå·²å‡†å¤‡å¥½å¤„ç†ä½ çš„ 1000ä¸‡è¡Œ æ•°æ®ã€‚")

if __name__ == "__main__":
    demo_parallel_computing()