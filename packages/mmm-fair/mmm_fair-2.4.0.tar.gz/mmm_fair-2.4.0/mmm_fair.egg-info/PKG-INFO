Metadata-Version: 2.4
Name: mmm-fair
Version: 2.4.0
Summary: A multi-objective multi-fairness boosting classifier
Author-email: Arjun Roy <arjunroyihrpa@gmail.com>, Swati Swati <swati17293@gmail.com>, Emmanouil Panagiotou <panagiotouemm@gmail.com>
License:                                  Apache License
                                   Version 2.0, January 2004
                                http://www.apache.org/licenses/
        
        TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
        
        1. Definitions.
        
           "License" shall mean the terms and conditions for use, reproduction,
           and distribution as defined by Sections 1 through 9 of this document.
        
           "Licensor" shall mean the copyright owner or entity authorized by
           the copyright owner that is granting the License.
        
           "Legal Entity" shall mean the union of the acting entity and all
           other entities that control, are controlled by, or are under common
           control with that entity. For the purposes of this definition,
           "control" means (i) the power, direct or indirect, to cause the
           direction or management of such entity, whether by contract or
           otherwise, or (ii) ownership of fifty percent (50%) or more of the
           outstanding shares, or (iii) beneficial ownership of such entity.
        
           "You" (or "Your") shall mean an individual or Legal Entity
           exercising permissions granted by this License.
        
           "Source" form shall mean the preferred form for making modifications,
           including but not limited to software source code, documentation
           source, and configuration files.
        
           "Object" form shall mean any form resulting from mechanical
           transformation or translation of a Source form, including but
           not limited to compiled object code, generated documentation,
           and conversions to other media types.
        
           "Work" shall mean the work of authorship, whether in Source or
           Object form, made available under the License, as indicated by a
           copyright notice that is included in or attached to the work
           (an example is provided in the Appendix below).
        
           "Derivative Works" shall mean any work, whether in Source or Object
           form, that is based on (or derived from) the Work and for which the
           editorial revisions, annotations, elaborations, or other modifications
           represent, as a whole, an original work of authorship. For the purposes
           of this License, Derivative Works shall not include works that remain
           separable from, or merely link (or bind by name) to the interfaces of,
           the Work and Derivative Works thereof.
        
           "Contribution" shall mean any work of authorship, including
           the original version of the Work and any modifications or additions
           to that Work or Derivative Works thereof, that is intentionally
           submitted to Licensor for inclusion in the Work by the copyright
           owner or by an individual or Legal Entity authorized to submit on
           behalf of the copyright owner. For the purposes of this definition,
           "submitted" means any form of electronic, verbal, or written
           communication sent to the Licensor or its representatives, including
           but not limited to communication on electronic mailing lists, source
           code control systems, and issue tracking systems that are managed by,
           or on behalf of, the Licensor for the purpose of discussing and
           improving the Work, but excluding communication that is conspicuously
           marked or otherwise designated in writing by the copyright owner
           as "Not a Contribution."
        
           "Contributor" shall mean Licensor and any individual or Legal Entity
           on behalf of whom a Contribution has been received by Licensor and
           subsequently incorporated within the Work.
        
        2. Grant of Copyright License. Subject to the terms and conditions of
           this License, each Contributor hereby grants to You a perpetual,
           worldwide, non-exclusive, no-charge, royalty-free, irrevocable
           copyright license to reproduce, prepare Derivative Works of,
           publicly display, publicly perform, sublicense, and distribute the
           Work and such Derivative Works in Source or Object form.
        
        3. Grant of Patent License. Subject to the terms and conditions of
           this License, each Contributor hereby grants to You a perpetual,
           worldwide, non-exclusive, no-charge, royalty-free, irrevocable
           (except as stated in this section) patent license to make, have made,
           use, offer to sell, sell, import, and otherwise transfer the Work,
           where such license applies only to those patent claims licensable
           by such Contributor that are necessarily infringed by their
           Contribution(s) alone or by combination of their Contribution(s)
           with the Work to which such Contribution(s) was submitted. If You
           institute patent litigation against any entity (including a
           cross-claim or counterclaim in a lawsuit) alleging that the Work
           or a Contribution incorporated within the Work constitutes direct
           or contributory patent infringement, then any patent licenses
           granted to You under this License for that Work shall terminate
           as of the date such litigation is filed.
        
        4. Redistribution. You may reproduce and distribute copies of the
           Work or Derivative Works thereof in any medium, with or without
           modifications, and in Source or Object form, provided that You
           meet the following conditions:
        
           (a) You must give any other recipients of the Work or
               Derivative Works a copy of this License; and
        
           (b) You must cause any modified files to carry prominent notices
               stating that You changed the files; and
        
           (c) You must retain, in the Source form of any Derivative Works
               that You distribute, all copyright, patent, trademark, and
               attribution notices from the Source form of the Work,
               excluding those notices that do not pertain to any part of
               the Derivative Works; and
        
           (d) If the Work includes a "NOTICE" text file as part of its
               distribution, then any Derivative Works that You distribute must
               include a readable copy of the attribution notices contained
               within such NOTICE file, excluding those notices that do not
               pertain to any part of the Derivative Works, in at least one
               of the following places: within a NOTICE text file distributed
               as part of the Derivative Works; within the Source form or
               documentation, if provided along with the Derivative Works; or,
               within a display generated by the Derivative Works, if and
               wherever such third-party notices normally appear. The contents
               of the NOTICE file are for informational purposes only and
               do not modify the License. You may add Your own attribution
               notices within Derivative Works that You distribute, alongside
               or as an addendum to the NOTICE text from the Work, provided
               that such additional attribution notices cannot be construed
               as modifying the License.
        
           You may add Your own copyright statement to Your modifications
           and may provide additional or different license terms and conditions
           for use, reproduction, or distribution of Your modifications, or
           for any such Derivative Works as a whole, provided Your use,
           reproduction, and distribution of the Work otherwise complies with
           the conditions stated in this License.
        
        5. Submission of Contributions. Unless You explicitly state otherwise,
           any Contribution intentionally submitted for inclusion in the Work
           by You to the Licensor shall be under the terms and conditions of
           this License, without any additional terms or conditions.
           Notwithstanding the above, nothing herein shall supersede or modify
           the terms of any separate license agreement you may have executed
           with Licensor regarding such Contributions.
        
        6. Trademarks. This License does not grant permission to use the trade
           names, trademarks, service marks, or product names of the Licensor,
           except as required for reasonable and customary use in describing the
           origin of the Work and reproducing the content of the NOTICE file.
        
        7. Disclaimer of Warranty. Unless required by applicable law or
           agreed to in writing, Licensor provides the Work (and each
           Contributor provides its Contributions) on an "AS IS" BASIS,
           WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
           implied, including, without limitation, any warranties or conditions
           of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
           PARTICULAR PURPOSE. You are solely responsible for determining the
           appropriateness of using or redistributing the Work and assume any
           risks associated with Your exercise of permissions under this License.
        
        8. Limitation of Liability. In no event and under no legal theory,
           whether in tort (including negligence), contract, or otherwise,
           unless required by applicable law (such as deliberate and grossly
           negligent acts) or agreed to in writing, shall any Contributor be
           liable to You for damages, including any direct, indirect, special,
           incidental, or consequential damages of any character arising as a
           result of this License or out of the use or inability to use the
           Work (including but not limited to damages for loss of goodwill,
           work stoppage, computer failure or malfunction, or any and all
           other commercial damages or losses), even if such Contributor
           has been advised of the possibility of such damages.
        
        9. Accepting Warranty or Additional Liability. While redistributing
           the Work or Derivative Works thereof, You may choose to offer,
           and charge a fee for, acceptance of support, warranty, indemnity,
           or other liability obligations and/or rights consistent with this
           License. However, in accepting such obligations, You may act only
           on Your own behalf and on Your sole responsibility, not on behalf
           of any other Contributor, and only if You agree to indemnify,
           defend, and hold each Contributor harmless for any liability
           incurred by, or claims asserted against, such Contributor by reason
           of your accepting any such warranty or additional liability.
        
        END OF TERMS AND CONDITIONS
        
        APPENDIX: How to apply the Apache License to your work.
        
           To apply the Apache License to your work, attach the following
           boilerplate notice, with the fields enclosed by brackets "[]"
           replaced with your own identifying information. (Don't include
           the brackets!)  The text should be enclosed in the appropriate
           comment syntax for the file format. We also recommend that a
           file or class name and description of purpose be included on the
           same "printed page" as the copyright notice for easier
           identification within third-party archives.
        
        Copyright (c) 2025, Arjun Roy
        
        Licensed under the Apache License, Version 2.0 (the "License"); you
        may not use this file except in compliance with the License. You
        may obtain a copy of the License at
        
            http://www.apache.org/licenses/LICENSE-2.0
        
        Unless required by applicable law or agreed to in writing, software
        distributed under the License is distributed on an "AS IS" BASIS,
        WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
        See the License for the specific language governing permissions and
        limitations under the License.
Project-URL: Homepage, https://github.com/arjunroyihrpa/MMM_fair
Project-URL: Bug Tracker, https://github.com/arjunroyihrpa/MMM_fair/issues
Keywords: fairness,boosting,classification,machine-learning
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.26.4
Requires-Dist: six>=1.16.0
Requires-Dist: pymoo>=0.6.1.3
Requires-Dist: scikit-learn>=1.5.2
Requires-Dist: ucimlrepo
Requires-Dist: pandas>=2.2.3
Requires-Dist: fairbench
Requires-Dist: skl2onnx==1.17.0
Requires-Dist: tqdm
Requires-Dist: plotly
Requires-Dist: onnxruntime
Requires-Dist: fairlearn
Requires-Dist: rich
Requires-Dist: Flask
Requires-Dist: Flask-Session
Provides-Extra: llm-gpt
Requires-Dist: openai; extra == "llm-gpt"
Requires-Dist: langchain>=0.1.14; extra == "llm-gpt"
Requires-Dist: langchain-community; extra == "llm-gpt"
Requires-Dist: bs4; extra == "llm-gpt"
Requires-Dist: python-dotenv; extra == "llm-gpt"
Provides-Extra: llm-groq
Requires-Dist: langchain-groq; extra == "llm-groq"
Requires-Dist: langchain>=0.1.14; extra == "llm-groq"
Requires-Dist: langchain-community; extra == "llm-groq"
Requires-Dist: bs4; extra == "llm-groq"
Requires-Dist: python-dotenv; extra == "llm-groq"
Provides-Extra: llm-together
Requires-Dist: langchain-together; extra == "llm-together"
Requires-Dist: langchain>=0.1.14; extra == "llm-together"
Requires-Dist: langchain-community; extra == "llm-together"
Requires-Dist: bs4; extra == "llm-together"
Requires-Dist: python-dotenv; extra == "llm-together"
Dynamic: license-file

[![PyPI](https://img.shields.io/pypi/v/mmm-fair)](https://pypi.org/project/mmm-fair/)

[![MMM-Fair Logo](https://raw.githubusercontent.com/arjunroyihrpa/MMM_fair/main/images/mmm-fair.png)](https://github.com/arjunroyihrpa/MMM_fair)

## üß† What is MMM-Fair?

MMM-Fair is a fairness-aware machine learning framework designed to support high-stakes AI decision-making under competing fairness and accuracy demands. The three M‚Äôs stand for:
	‚Ä¢	Multi-Objective: Optimizes across classification accuracy, balanced accuracy, and fairness (specifically, maximum group-level discrimination).
	‚Ä¢	Multi-Attribute: Supports multiple protected groups (e.g., race, gender, age) simultaneously, analyzing group-specific disparities.
	‚Ä¢	Multi-Definition: Evaluates and compares fairness under multiple definitions‚ÄîDemographic Parity (DP), Equal Opportunity (EP), and Equalized Odds (EO).

MMM-Fair enables developers, researchers, and decision-makers to explore the full spectrum of possible trade-offs and select the model configuration that aligns with their social or organizational goals.

To Learn more about fairness-aware AI/ML please refer to the following materials:

    1. Tutorial of Beginner's introduction to fair-ML: https://www.arjunroy.info/tutorials
    2. Fair-ML Book: https://fairmlbook.org/pdf/fairmlbook.pdf

---

#### üí¨ No coding required:
MMM-Fair comes with an intuitive chat-based web UI (mmm-fair-chat) that guides users step by step‚Äîjust like a human assistant would. You don‚Äôt need to write a single line of code. Simply upload your dataset (or use a built-in UCI dataset), select your fairness preferences, and explore trade-offs through automatically generated visual reports and summaries. 



#### üßæ LLM-Powered Chart Explanations (New!)

Starting from v2.0.0, MMM-Fair supports automatic explanation of performance and fairness trade-off plots using LLMs ([GPT](https://platform.openai.com/docs/overview), [Groq](https://console.groq.com/home), [TogetherAI](https://www.together.ai))

#### MMM-Fair is not just for developers, but also for policymakers, fairness auditors, and non-technical users.
---
#

## Installation
```bash
pip install mmm-fair
```
Requires Python 3.11+.

Dependencies: numpy, scikit-learn, tqdm, pymoo, pandas, ucimlrepo, skl2onnx, etc.

#### Optional Installation for LLM enabled explanation

To enable this feature, install with extras (MMM-Fair currently supports only [OpenAI (chatgpt)](https://platform.openai.com/docs/overview), [GroqAI](https://console.groq.com/home), and [TogetherAI](https://www.together.ai) but in future we plan to add more):
```bash
# OpenAI support
pip install "mmm-fair[llm-gpt]"

# Or for Groq
pip install "mmm-fair[llm-groq]"

# Or for Together.ai
pip install "mmm-fair[llm-together]"

#Or install all of them and later decide which one to use
pip install "mmm-fair[llm-gpt,llm-groq,llm-together]"
```
**we do not provide any API keys for these models and to use the llm-explanation one needs to get their own api keys from the respective llm provider.**

---

#### Two Approaches: AdaBoost-Style vs. Gradient-Boosted Trees
We provide two main classifiers:

1.	MMM_Fair (Original Adaptive Boosting version)
2.	MMM_Fair_GradientBoostedClassifier or MMM_Fair_GBT (Histogram-based Gradient Boosting approach) \[recommended\]

Both handle multi-objective, multi-attribute, and multi-type fairness constraints (DP, EP, EO) but differ in how they perform the boosting internally. You can choose via the command line argument --classifier MMM_Fair or --classifier MMM_Fair_GBT.

---


## Usage Overview 
The mmm-fair package provides two different usage possibilities. One is a chat based on a web-based UI (specially tailored new user, with even non-technical abckground), and the other is command line based (for ML scientist, engineers, etc.)

### Chat-Based

Right now the launch of the chat app is still terminal dependent (soon will release a destop app). So after installing the mmm-fair package one needs to bash in commandline:
```bash
mmm-fair-chat
```
and then in any browser copy paste:
```bash
http://127.0.0.1:5000
```
Then start chating with the interactive web app to get your MMM-Fair AI model.

**(Optional) If you have installed MMM-Fair with LLM support and provide your API key during the session, the assistant can explain trade-off plots in natural language.**

### AdaBoost-Style

You can import and use MMM-Fair (original version):
```python
from mmm_fair import MMM_Fair 
from sklearn.tree import DecisionTreeClassifier
```

### Suppose you have X (features), y (labels)
### 
```python
mmm = MMM_Fair(
estimator=DecisionTreeClassifier(max_depth=5),
constraints="EO",        # or "DP", "EP"
n_estimators=1000,      # or max_iter=1000
saIndex=...,            # shape (n_samples, n_protected)
saValue=...,            # dictionary {'prot_att_column_name': prot value}
random_state=42,
# other parameters, e.g. gamma, saIndex, saValue...
)

mmm.fit(X, y)
preds = mmm.predict(X_test)
```
### Fairness Constraints

‚Ä¢	constraints="DP" ‚Üí Demographic Parity

‚Ä¢	constraints="EP" ‚Üí Equal Opportunity

‚Ä¢	constraints="EO" ‚Üí Equalized Odds

###

In all cases, pass the relevant saIndex (sensitive attribute array) and saValue (dictionary of protected group mappings) to MMM_Fair if you want it to track fairness for different protected attributes.

---

### Gradient-Boosted Style (recommended)

We also provide MMM_Fair_GradientBoostedClassifier. This uses a histogram-based gradient boosting approach (similar to HistGradientBoostingClassifier) but includes a custom fairness loss to train and then multi-objective post-processing step to select the best pareto-optimal ensemble round. Example:

```python
from mmm_fair import MMM_Fair_GradientBoostedClassifier

clf = MMM_Fair_GradientBoostedClassifier(
    constraint="EO",        # or "DP", "EP"
    alpha=0.1,              # fairness weight
    saIndex=...,            # shape (n_samples, n_protected)
    saValue=...,            # dictionary or None
    max_iter=100,
    random_state=42,
    ## any other arguments that the HistGradientBoostingClassifier from sklearn can handle
)
clf.fit(X, y)
preds = clf.predict(X_test)
```

## üì• In-built Data Loader for UCI Datasets

MMM-Fair includes utility functions to seamlessly work with datasets from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/datasets).

### üîß Load a UCI dataset (e.g. Adult dataset)
```python
from mmm_fair import data_uci
from mmm_fair import build_sensitives

# Load dataset with target column
data = data_uci(dataset_name="Adult", target="income")
```
### üõ°Ô∏è Define Sensitive Attributes
```python
saIndex, saValue = build_sensitives(
    data.data,
    protected_cols=["race", "sex"],
    non_protected_vals=["White", "Male"]
)
```

### üîÄ Optional: Use with Train/Test Split
```python
from sklearn.model_selection import train_test_split
import numpy as np

X = data.to_pred(sensitive=["race", "sex"])
y = data.labels["label"].to_numpy()
indices = np.arange(len(X))

X_train, X_test, y_train, y_test, id_train, id_test = train_test_split(
    X, y, indices, test_size=0.3, random_state=42, stratify=y
)

# Rebuild fairness attributes for the split sets
saIndex_train, saValue_train = build_sensitives(
    data.data.iloc[id_train], ["race", "sex"], ["White", "Male"]
)
saIndex_test, _ = build_sensitives(
    data.data.iloc[id_test], ["race", "sex"], ["White", "Male"]
)
```

#### ‚úÖ saIndex is a binary matrix (0 = protected, 1 = non-protected)
#### ‚úÖ saValue is a dictionary indicating protected status, e.g., {"race": 0, "sex": 0}
---

## Train & Deploy Script

This package provides a train_and_deploy.py script. It:
1.	Loads data (from a known UCI dataset or a local CSV).
2.	Specifies fairness constraints, protected attributes, and base learner.
3.	Selects either the original MMM_Fair or the new MMM_Fair_GradientBoostedClassifier via --classifier MMM_Fair or --classifier MMM_Fair_GBT.
4.	Trains with your chosen hyperparameters.
5.	Optionally deploys the model in ONNX or pickle format.

### Key Arguments
	‚Ä¢	--classifier: MMM_Fair (original boosting) or MMM_Fair_GBT (gradient-based).
	‚Ä¢	--constraint: e.g., DP, EP, EO.
	‚Ä¢	--n_learners: Number of estimators (for either version).
	‚Ä¢	--pos_Class: Specify the positive class label if needed.
	‚Ä¢	--early_stop: True or False, relevant for the GBT approach to enable scikit-learn‚Äôs early stopping.
	‚Ä¢	--base_learner: E.g. tree, lr, logistic, etc. (for the original MMM_Fair).
	‚Ä¢	--deploy: 'onnx' or 'pickle'.
	‚Ä¢	--moo_vis True: Optionally visualize multi-objective (3D) plots (accuracy, class-imbalance, multi-fairness) after training, opening a local HTML page with interactive charts.


### Example command:
#### 1. Original AdaBoost MMM_Fair:
[using UCI library](https://archive.ics.uci.edu)
```bash
python -m mmm_fair.train_and_deploy \
  --dataset Adult \
  --prots race sex \
  --nprotgs White Male \
  --constraint EO \
  --base_learner Logistic \
  --deploy onnx \
  --moo_vis True
```
[using local "csv" data](https://docs.python.org/3/library/csv.html)
```bash
python -m mmm_fair.train_and_deploy \
  --dataset mydata.csv \
  --target label_col \
  --prots prot_1 prot_2 prot_3 \
  --nprotgs npg1 npg2 npg3 \
  --constraint EO \
  --base_learner tree \
  --deploy onnx
```
#### 2. Gradient-Boosted MMM_Fair_GBT:
```bash
python -m mmm_fair.train_and_deploy \
  --classifier MMM_Fair_GBT \
  --dataset mydata.csv \
  --target label_col \
  --prots prot_1 prot_2 \
  --nprotgs npg1 npg2 \
  --constraint DP \
  --alpha 0.5 \
  --early_stop True \
  --n_learners 100 \
  --deploy pickle \
  --moo_vis True
```

#### Note: 
1. Setting --moo_vis True triggers an interactive local HTML page for exploring the multi-objective trade-offs in 3D plots (accuracy vs. class-imbalance vs. fairness, etc.).
2. Currently the fairness intervention only implemented for categorical groups. So if protected attribute is numerical e.g. "age" then for non-protected value i.e. --nprotgs provide a range like 30_60 as argument. 

---

### Additional options

If you want to select the best theta from only the Pareto optimal ensembles set (default is False and selects applies the post-processing to all set of solutions):   

    --pareto True

If you want to provide test data:  

    --test 'your_test_file.csv'
    
Or just test split:  

    --test 0.3
    
If you want change style (default is table, choose from {table, console}) of report displayed ([Check FairBench Library for more details](https://fairbench.readthedocs.io/material/visualization/)):

    --report_type Console


**When deploying with 'onnx'**, we change the models to ONNX file(s), and store additional parameters in a model_params.npy. This gets zipped into a .zip archive for distribution/analysis.

---

### MAMMOth Toolkit Integration

For the bias exploration using [MAMMOth](https://mammoth-ai.eu) pipeline it is really important to select 'onnx' as the '--deploy' argument. The [ONNX](https://onnxruntime.ai) model accelerator and model_params.npy are used to integrate with the [MAMMOth-toolkit](https://github.com/mammoth-eu/mammoth-toolkit-releases) or the demonstrator app from the [mammoth-commons](https://github.com/mammoth-eu/mammoth-toolkit-releases) project.


### By providing the .zip archive, you can:

    ‚Ä¢	Upload it to MAMMOth,
    
    ‚Ä¢	Examine bias and performance metrics across subgroups,
    
    ‚Ä¢	Compare fairness trade-offs with a user-friendly interface.

---

### Example Workflow
1.	**Choose** Fairness Constraint: e.g., DP, EO, or EP.
2.	**Define** sensitive attributes in saIndex and the protected-group condition in saValue.
3.	**Pick** base learner (e.g., DecisionTreeClassifier(max_depth=5)) or gradient-based approach.
4.	**Train** with a large number of estimators (n_estimators=300 or max_iter=300).
5.	**Optionally** do partial ensemble selection with update_theta(criteria="all") or update_theta(criteria="fairness") .
6.	**Export** to ONNX or pickle for downstream usage.
7.  **Use** --moo_vis True to open local multi-objective 3D plots for deeper analysis.
8.  **Upload** the .zip file (if exported to onnx) to MAMMOth for bias exploration.

---

### References

‚Äú[Multi-Fairness Under Class-Imbalance](https://link.springer.com/chapter/10.1007/978-3-031-18840-4_21),‚Äù  Roy, Arjun, Vasileios Iosifidis, and Eirini Ntoutsi. International Conference on Discovery Science. Cham: Springer Nature Switzerland, 2022.

#### Maintainer: Arjun Roy (arjunroyihrpa@gmail.com)

#### Contributors: Swati Swati (swati17293@gmail.com), Emmanoui Panagiotou (panagiotouemm@gmail.com)

### üèõÔ∏è Funding

MMM-Fair is a research-driven project supported by several public funding initiatives. We gratefully acknowledge the generous support of:

<p align="center">
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://bias-project.org/wp-content/themes/wp-bootstrap-starter/images/Bias_Logo.svg" alt="bias-logo" width="120" />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <img src="https://mammoth-ai.eu/wp-content/uploads/2022/09/mammoth.svg" alt="mammoth-logo" width="150" style="margin: 0 20px"/>
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src="https://stelar-project.eu/wp-content/uploads/2022/08/cropped-stelar-sq.png" alt="stelar-logo" width="100" />
</p>

<p align="center">
  <a href="https://bias-project.org"><strong>Volkswagen Foundation ‚Äì BIAS</strong></a> &nbsp;&nbsp;&nbsp;
  <a href="https://mammoth-ai.eu"><strong>EU Horizon ‚Äì MAMMOth</strong></a> &nbsp;&nbsp;&nbsp;
  <a href="https://stelar-project.eu"><strong>EU Horizon ‚Äì STELAR</strong></a>
</p>


### License & Contributing

This project is released under [Apache License Version 2.0].
Contributions are welcome‚Äîplease open an issue or pull request on GitHub.

### Contact

For questions or collaborations, please contact [arjun.roy@unibw.de](mailto:arjun.roy@unibw.de) 
Check out the source code at: [GITHUB](https://github.com/arjunroyihrpa/MMM_fair).
