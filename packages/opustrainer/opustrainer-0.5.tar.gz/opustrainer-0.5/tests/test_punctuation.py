import unittest

from parameterized import parameterized

from opustrainer.modifiers.punctuation import RemoveEndPunctuationModifier


class TestMerge(unittest.TestCase):

    @parameterized.expand([
        ('.', 'ã€‚'),
        ('?', 'ï¼Ÿ'),
        ('!', '!'),
        (',', 'ã€'),
        (':', 'ï¼š'),
        (';', 'ï¹”'),
        ('â€¦', 'ï¸™'),
    ])
    def test_remove_end_punct(self, src_punct, trg_punct):
        ex = '\t'.join([
            f'This â– is â– a â– simple â– test â– statement â– ğŸ¤£ {src_punct}',
            f'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â– {trg_punct}',
            '0-0 2-1 4-2 6-3 6-4 8-5 10-6 10-7 12-9 13-11',
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        src, trg, aln = out.split('\t')
        self.assertEqual(src, 'This â– is â– a â– simple â– test â– statement â– ğŸ¤£')
        self.assertEqual(trg, 'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â–')
        self.assertEqual(aln, '0-0 2-1 4-2 6-3 6-4 8-5 10-6 10-7 12-9')

    def test_remove_end_punct_untokenized(self):
        ex = '\t'.join([
            f'This is a simple test statement ğŸ¤£.',
            f'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯­å¥ğŸ¤£ã€‚',
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        src, trg = out.split('\t')
        self.assertEqual(src, 'This is a simple test statement ğŸ¤£')
        self.assertEqual(trg, 'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯­å¥ğŸ¤£')

    def test_remove_end_punct_no_alignment(self):
        ex = '\t'.join([
            'This â– is â– a â– simple â– test â– statement â– ğŸ¤£ .',
            'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â– ã€‚'
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        src, trg = out.split('\t')
        self.assertEqual(src, 'This â– is â– a â– simple â– test â– statement â– ğŸ¤£')
        self.assertEqual(trg, 'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â–')

    def test_do_not_remove_end_punct_if_different(self):
        ex = '\t'.join([
            'This â– is â– a â– simple â– test â– statement â– ğŸ¤£ â– ?',
            'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â– ã€‚',
            '0-0 2-1 4-2 6-3 6-4 8-5 10-6 10-7 12-9 13-11',
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        self.assertEqual(out, ex)

    def test_do_not_remove_ascii_ellipsis(self):
        ex = '\t'.join([
            'This â– is â– a â– simple â– test â– statement â– ğŸ¤£ â– . . .',
            'è¿™ æ˜¯ ä¸€ä¸ª ç®€å• çš„ æµ‹è¯• è¯­ å¥ â– ğŸ¤£ â– .',
            '0-0 2-1 4-2 6-3 6-4 8-5 10-6 10-7 12-9 13-11 14-11 15-11',
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        self.assertEqual(out, ex)

    def test_do_not_remove_ascii_ellipsis_untokenized(self):
        ex = '\t'.join([
            'This is a simple test statementğŸ¤£...',
            'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯­å¥ğŸ¤£.',
        ])
        mod = RemoveEndPunctuationModifier(1.0)
        out = list(mod([ex]))[0]
        self.assertEqual(out, ex)
