# Copyright 2024 GLM-4-9B Model Team @ Zhipu AI
# Copyright 2024 ByteDance and/or its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""PyTorch ChatGLM model."""

import os

from flash_attn import flash_attn_func

from ...ops.streaming_llm_attention import streaming_llm_attention


def glm_streaming_llm_attention_forward(
    self, query_states, key_states, value_states, attention_mask
):
    query_states = query_states.transpose(1, 2)
    key_states = key_states.transpose(1, 2)
    value_states = value_states.transpose(1, 2)
    batch_size, query_length = query_states.shape[:2]

    if query_states.shape[1] > 1:
        attn_output = streaming_llm_attention(
            query_states,
            key_states,
            value_states,
            global_window=self.config.global_window,
            local_window=self.config.local_window,
        )
    else:
        attn_output = flash_attn_func(query_states, key_states, value_states)

    attn_output = attn_output.reshape(
        batch_size, query_length, self.hidden_size_per_partition
    ).contiguous()
    return attn_output
