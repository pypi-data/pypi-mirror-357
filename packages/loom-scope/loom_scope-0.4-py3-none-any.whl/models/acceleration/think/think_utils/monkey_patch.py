import functools
import types

import transformers
from transformers.models.llama.modeling_llama import (
    LlamaMLP,
)

from .llama_model import (
    llama_attn_forward_SnapKV_ThinK,
    llama_flash_attn2_forward_SnapKV_think,
    llama_model_forward,
    prepare_inputs_for_generation_llama_new,
)


def replace_llama():
    print("Using Think!")
    transformers.models.llama.modeling_llama.LlamaForCausalLM.prepare_inputs_for_generation = prepare_inputs_for_generation_llama_new
    transformers.models.llama.modeling_llama.LlamaModel.forward = llama_model_forward
    transformers.models.llama.modeling_llama.LlamaAttention.forward = (
        llama_attn_forward_SnapKV_ThinK
    )
    transformers.models.llama.modeling_llama.LlamaFlashAttention2.forward = (
        llama_flash_attn2_forward_SnapKV_think
    )
