import json
import os
import time
import threading
import multiprocessing as mp
import fcntl
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Union
from loguru import logger
import uuid
import atexit


class ThreadSafePredictionBuffer:
    
    def __init__(
        self,
        save_strategy: str = "immediate",
        save_interval: int = 10,
        buffer_size: int = 100,
        time_interval: int = 60,
        auto_flush: bool = True,
        encoding: str = "utf-8",
        process_id: Optional[str] = None
    ):
        self.save_strategy = save_strategy.lower()
        self.save_interval = save_interval
        self.buffer_size = buffer_size
        self.time_interval = time_interval
        self.auto_flush = auto_flush
        self.encoding = encoding
        
        self.process_id = process_id or f"{os.getpid()}_{threading.get_ident()}_{uuid.uuid4().hex[:8]}"
        
        self._buffers: Dict[str, List] = {}
        self._step_counters: Dict[str, int] = {}
        self._last_save_time: Dict[str, float] = {}
        
        self._lock = threading.RLock()

        self._temp_dir = Path(tempfile.gettempdir()) / "prediction_buffers" / self.process_id
        self._temp_dir.mkdir(parents=True, exist_ok=True)
        
        self._validate_strategy()

        atexit.register(self._cleanup)
    
    def _validate_strategy(self):
        valid_strategies = ['immediate', 'step', 'buffer', 'time']
        if self.save_strategy not in valid_strategies:
            raise ValueError(f"Invalid save_strategy: {self.save_strategy}. Must be one of {valid_strategies}")
        
        if self.save_strategy == 'step' and self.save_interval <= 0:
            raise ValueError("save_interval must be positive when using 'step' strategy")
        
        if self.save_strategy == 'buffer' and self.buffer_size <= 0:
            raise ValueError("buffer_size must be positive when using 'buffer' strategy")
        
        if self.save_strategy == 'time' and self.time_interval <= 0:
            raise ValueError("time_interval must be positive when using 'time' strategy")
    
    def add_prediction(self, file_path: str, prediction_data: Dict) -> bool:
        with self._lock:
            if file_path not in self._buffers:
                self._buffers[file_path] = []
                self._step_counters[file_path] = 0
                self._last_save_time[file_path] = time.time()

            self._buffers[file_path].append(prediction_data)
            self._step_counters[file_path] += 1

            return self._check_and_save(file_path)
    
    def _check_and_save(self, file_path: str) -> bool:
        should_save = False
        
        if self.save_strategy == 'immediate':
            should_save = True
        elif self.save_strategy == 'step':
            should_save = (self._step_counters[file_path] % self.save_interval == 0)
        elif self.save_strategy == 'buffer':
            should_save = (len(self._buffers[file_path]) >= self.buffer_size)
        elif self.save_strategy == 'time':
            current_time = time.time()
            should_save = (current_time - self._last_save_time[file_path] >= self.time_interval)
        
        if should_save:
            return self._flush_buffer_safe(file_path)
        
        return False
    
    def _flush_buffer_safe(self, file_path: str) -> bool:
        if not self._buffers.get(file_path):
            return False
        
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)

            with self._file_lock_context(file_path):
                with open(file_path, "a", encoding=self.encoding) as f:
                    for data in self._buffers[file_path]:
                        json.dump(data, f, ensure_ascii=False)
                        f.write('\n')

            count = len(self._buffers[file_path])
            self._buffers[file_path].clear()
            self._last_save_time[file_path] = time.time()
            
            logger.debug(f"Process {self.process_id}: Flushed {count} predictions to {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"Process {self.process_id}: Error flushing buffer to {file_path}: {str(e)}")
            return False
    
    def _file_lock_context(self, file_path: str):
        class FileLockContext:
            def __init__(self, file_path: str):
                self.file_path = file_path
                self.lock_file = None
                
            def __enter__(self):
                lock_path = f"{self.file_path}.lock"
                self.lock_file = open(lock_path, 'w')
                
                max_retries = 10
                for i in range(max_retries):
                    try:
                        fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                        return self
                    except IOError:
                        if i == max_retries - 1:
                            raise
                        time.sleep(0.1)
                return self
                
            def __exit__(self, exc_type, exc_val, exc_tb):
                if self.lock_file:
                    try:
                        fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                        self.lock_file.close()
                        try:
                            os.remove(f"{self.file_path}.lock")
                        except:
                            pass
                    except:
                        pass
        
        return FileLockContext(file_path)
    
    def flush_all(self) -> Dict[str, bool]:
        results = {}
        with self._lock:
            for file_path in list(self._buffers.keys()):
                results[file_path] = self._flush_buffer_safe(file_path)
        return results
    
    def flush_file(self, file_path: str) -> bool:
        with self._lock:
            return self._flush_buffer_safe(file_path)
    
    def get_buffer_status(self) -> Dict[str, Dict]:
        with self._lock:
            status = {}
            for file_path in self._buffers:
                status[file_path] = {
                    'buffer_count': len(self._buffers[file_path]),
                    'step_count': self._step_counters[file_path],
                    'last_save_time': self._last_save_time[file_path],
                    'strategy': self.save_strategy,
                    'process_id': self.process_id
                }
            return status
    
    def _cleanup(self):
        try:
            if self.auto_flush:
                self.flush_all()
            if self._temp_dir.exists():
                import shutil
                shutil.rmtree(self._temp_dir, ignore_errors=True)
        except:
            pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self._cleanup()


class ThreadSafePredictionManager:
    
    def __init__(self, **buffer_kwargs):
        self.buffer = ThreadSafePredictionBuffer(**buffer_kwargs)
        self._lock = threading.RLock()
    
    def store_prediction(self, file_path: str, raw_output, rag_method=None) -> bool:
        with self._lock:
            try:
                pred_data = raw_output
                if pred_data:
                    return self.buffer.add_prediction(file_path, pred_data)
                return False
            except Exception as e:
                logger.error(f"Error storing prediction: {str(e)}")
                return False
    
    def flush_all(self):
        return self.buffer.flush_all()
    
    def get_status(self):
        return self.buffer.get_buffer_status()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.buffer.__exit__(exc_type, exc_val, exc_tb)


_thread_local = threading.local()


def get_prediction_manager(**kwargs) -> ThreadSafePredictionManager:
    if not hasattr(_thread_local, 'prediction_manager'):
        _thread_local.prediction_manager = ThreadSafePredictionManager(**kwargs)
    return _thread_local.prediction_manager


def create_prediction_manager_from_args(args) -> ThreadSafePredictionManager:
    save_strategy = getattr(args, 'save_strategy', 'immediate')
    save_interval = getattr(args, 'save_interval', 10)
    buffer_size = getattr(args, 'buffer_size', 100)
    time_interval = getattr(args, 'time_interval', 60)
    auto_flush = getattr(args, 'auto_flush', True)
    
    process_id = f"proc_{os.getpid()}_thread_{threading.get_ident()}"
    
    return ThreadSafePredictionManager(
        save_strategy=save_strategy,
        save_interval=save_interval,
        buffer_size=buffer_size,
        time_interval=time_interval,
        auto_flush=auto_flush,
        process_id=process_id
    )

PredictionBuffer = ThreadSafePredictionBuffer
PredictionManager = ThreadSafePredictionManager